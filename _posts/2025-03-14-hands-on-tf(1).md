---
title: "12장 텐서플로를 사용한 사용자 정의 모델과 훈련"
excerpt: "텐서플로/사용자 정의 모델/훈련 알고리즘/"

categories:
  - 핸즈온 머신러닝
tags:
  - [hands-on]

permalink: /hands-on/tf-1/

toc: true
toc_sticky: true
math: true

date: 2025-03-14
last_modified_at: 2025-03-15
---


# 12.1 텐서플로 훑어보기

텐서플로는 강력한 수치 계산용 라이브러리이다. 특히 대규모 머신러닝에 잘 맞도록 튜닝되어 있다.
- 핵심 구조는 넘파이와 매우 비슷하지만 GPU를 지원한다.
- 분산 컴퓨팅을 지원한다.
- 일종의 JIT 컴파일러를 포함한다. 속도를 높이고 메모리 사용량을 줄이기 위해 계산을 최적화한다. 이를 위해 파이썬 함수에서 계산 그래프를 추출한 다음 최적화하고 효율적으로 실행한다.
- 계산 그래프는 플랫폼에 중립적인 포맷으로 내보낼 수 있다.
- 텐서플로는 자동 미분 기능과 RMSProp, Nadam 같은 고성능 옵티마이저를 제공하므로 모든 종류의 손실 함수를 최소화할 수 있다.

`tf.keras`가 가장 많이 쓰이고 중요하며 데이터 적재와 전처리 연산(`tf.data`, `tf.io` 등). 이미지 처리 연산(`tf.image`), 신호 처리 연산(`tf.signal`)과 그 외 많은 기능을 가지고 있다.

<img src="https://user-images.githubusercontent.com/78655692/147628860-2c554246-f350-4f40-aa42-6ae149cebb0c.png">

- 가장 저수준의 텐서플로 연산은 매우 효율적인 C++ 코드로 구현되어 있다.
- 많은 연산은 **커널**이라 부르는 여러 구현을 가진다.
- 각 커널은 CPU, GPU 또는 TPU(**텐서 연산 장치**)와 특정 장치에 맞추어 만들어졌다.
  - GPU는 계산을 작은 단위로 나누어 여러 GPU 쓰레드에서 병렬로 실행하므로 속도를 극적으로 향상한다.
  - TPU는 딥러닝 연산을 위해 특별하게 설계된 ASIC 칩이다.

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbbgnt5%2FbtrsaRCLi5P%2FoV7mLnUBGANmOjO45YP6xk%2Fimg.png">

- 텐서플로의 코드는 고수준 API를 사용하지만 더 높은 자유도가 필요한 경우에는 저수준 파이썬 API를 사용하여 텐서를 직접 다룬다.
- 윈도우, 리눅스, 맥OS뿐만 아니라 iOS와 안드로이드 같은 모바일 장치에서도 실행된다.
- **TensorFlow.js**라는 자바스크립트로 구현되어 브라우저에서 직접 모델을 실행할 수 있다.
- **텐서플로 허브**를 사용하여 사전훈련된 신경망을 손쉽게 다운로드하여 재사용할 수 있다.


# 12.2 넘파이처럼 텐서플로 사용하기

텐서플로 API는 텐서를 순환시킨다.
- 텐서는 한 연산에서 다른 연산으로 흐르므로 텐서플로라고 부른다.
- 텐서는 넘파이 `ndarray`와 매우 비슷하다. 즉, 일반적으로 다차원 배열이다.
  - 스칼라 값도 가질 수 있다.


## 12.2.1 텐서와 연산

`tf.constant()` 함수로 텐서를 만들 수 있다.

```python
from tensorflow as tf

tf.constant([[1., 2., 3.], [4., 5., 6.]]) # 행렬
# <tf.Tensor: shape=(2, 3), dtype=float32, numpy=
# array([[1., 2., 3.],
#        [4., 5., 6.]], dtype=float32)>
tf.constant(42) # 스칼라
# <tf.Tensor: shape=(), dtype=int32, numpy=42>
```

`tf.Tensor`는 크기와 데이터 타입을 가진다.

```python
t = tf.constant([[1., 2., 3.], [4., 5., 6.]])
t.shape
# TensorShape([2, 3])
t.dtype
# tf.float32
```

인덱스 참조도 넘파이와 매우 비슷하게 작동한다.

```python
t[:, 1:]
# <tf.Tensor: shape=(2, 2), dtype=float32, numpy=
# array([[2., 3.],
#        [5., 6.]], dtype=float32)>

t[..., 1, tf.newaxis]
# <tf.Tensor: shape=(2, 1), dtype=float32, numpy=
# array([[2.],
#        [5.]], dtype=float32)>
```

모든 종류의 연산이 가능하다. 

```python
t + 10
# <tf.Tensor: shape=(2, 3), dtype=float32, numpy=
# array([[11., 12., 13.],
#        [14., 15., 16.]], dtype=float32)>

tf.sqare(t) # 제곱
# <tf.Tensor: shape=(2, 3), dtype=float32, numpy=
# array([[ 1.,  4.,  9.],
#        [16., 25., 36.]], dtype=float32)>

t @ tf.transpose(t) # transpose는 행렬 변환
# <tf.Tensor: shape=(2, 2), dtype=float32, numpy=
# array([[14., 32.],
#        [32., 77.]], dtype=float32)>
```

- `t +10`이라고 쓰는 것은 `tf.add(t, 10)`을 호출하는 것과 같다.
- `@` 연산은 행렬 곱셈이며 `tf.matmul()` 함수를 호출하는 것과 동일하다.

## 12.2.2 텐서와 넘파이

텐서는 넘파이와 함께 사용하기 편리하다. 
- 넘파이 배열로 텐서를 만들 수 있고 그 반대도 가능하다. 
- 넘파이 배열에 텐서플로 연산을 적용할 수 있고 텐서에 넘파이 연산을 적용할 수 있다.

```python
a = np.array([2., 4., 5.])
tf.constant(a)
# <tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>
np.array(t)
# array([[1., 2., 3.],
#        [4., 5., 6.]], dtype=float32)
tf.square(a)
# <tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>
np.square(t)
# array([[ 1.,  4.,  9.],
#        [16., 25., 36.]], dtype=float32)
```

> 넘파이는 기본으로 64비트 정밀도를 사용하지만 텐서플로는 32비트 정밀도를 사용한다. 일반적으로 신경망은 32비트 정밀도를 충분하고 더 빠르고 메모리도 적게 사용하기 때문이다. 넘파이 배열로 텐서를 만들 때 `dtype=tf.float32`로 지정해야한다.

## 12.2.3 타입 변환

타입 변환은 성능을 크게 감소시킬 수 있기 떄문에 텐서플로는 어떤 타입 변환도 자동으로 수행하지 않는다. 호환되지 않는 타입의 텐서로 연산을 실행하면 예와가 발생한다.

```python
tf.constant(2.) + tf.constant(40)
# Traceback[...]InvalidArgumentError[...]expected to be a float[...]
tf.constant(2.) + tf.constant(40, dtype=tf.float64)
# Traceback[...]InvalidArgumentError[...]expected to be a double[...]
```

하지만, 타입 변환이 필요할 때는 `tf.cast()` 함수를 사용할 수 있다.

```python
t2 = tf.constant(40., dtype=tf.float64)
tf.constant(2.0) + tf.cast(t2, tf.float32)
# <tf.Tensor: shape=(), dtype=float32, numpy=42.0>
```

## 12.2.4 변수

`tf.Tensor`는 변경이 불가능한 객체다. 
- 일반적인 텐서로는 역전파로 변경되어야 하는 신경망의 가중치를 구현할 수 있다.
- 시간에 따라 변경되어야 할 다른 파라미터도 있다.(ex. 모멘텀 옵티마이저)

`tf.Variable`은 텐서의 내용을 바꿀 수 있다.
- 변수의 값을 증가시키거나 원소의 값을 바꾸면 새로운 텐서가 만들어진다.
- 텐서와 마찬가지로 동일한 방식으로 연산 수행이 가능하며 넘파이와도 잘 호환된다.

```python
v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])
v
# <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=
# array([[1., 2., 3.],
#        [4., 5., 6.]], dtype=float32)>
```

- `assign()` 메서드를 사용하여 변수값을 바꿀 수 있다.
  - `assign_add()`나 `assign_sub()` 메서드를 사용하면 주어진 값만큼 변수를 증가시키거나 감소시킬 수 있다.
- 원소의 `assign()` 메서드나 `scatter_update()`, `scatter_nd_update()` 메서드를 사용하여 개별 원소(또는 슬라이스)를 수정할 수 있다.

```python
v.assign(2 * v)
# <tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=
# array([[ 2.,  4.,  6.],
#        [ 8., 10., 12.]], dtype=float32)>
v[0, 1].assgin(42)
# <tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=
# array([[ 2., 42.,  6.],
#        [ 8., 10., 12.]], dtype=float32)>
v[:, 2].assign([0., 1.])
# <tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=
# array([[ 2., 42.,  0.],
#        [ 8., 10.,  1.]], dtype=float32)>
v.scatter_nd_update(indices=[[0, 0], [1, 2]], updated=[100., 200.])
# <tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=
# array([[100.,  42.,   0.],
#        [  8.,  10., 200.]], dtype=float32)>
```

> 케라스는 `add_weight()` 메서드로 변수 생성을 대신 처리해주기 때문에 실전에서 변수를 만드는 일은 매우 드물며, 모델 파라미터는 일반적으로 옵티마이저가 업데이트하므로 수동으로 변수를 업데이트하는 일은 드물다.

## 12.2.5 다른 데이터 구조

- **희소 텐서**(tf.SparseTensor)
  - 대부분 0으로 채워진 텐서를 효율적으로 나타낸다.
- **텐서 배열**(tf.TensorArray)
  - 텐서의 리스트이다. 
  - 기본적으로 고정된 길이를 가지지만 동적으로 바꿀 수 있다.
- **래그드 텐서**(tf.RaggedTensor)
  - 리스트의 리스트를 나타낸다. 
  - 텐서에 포함된 값은 동일한 데이터 타입을 가져야 하지만 리스트의 길이는 다를 수 있다.
- **문자열 텐서**
  - tf.string 타입의 텐서
- **집합**
  - 일반적인 텐서(또는 희소 텐서)로 나타낸다.
- **큐**
  - 큐는 단계별로 텐서를 저장한다.

# 12.3 사용자 정의 모델과 훈련 알고리즘

## 12.3.1 사용자 정의 손실 함수

희귀 모델을 훈련하는 데 훈련 세트에 잡음 데이터가 조금 있는 경우에는 후버(Huber) 손실을 사용하면 좋다.

- 후버 손실 정의하기

```python
def huber_fn(y_true, y_pred):
  error = y_true - y_pred
  is_small_error = tf.abs(error) < 1
  squared_loss = tf.square(error) / 2
  linear_loss = tf.abs(error) - 0.5
  return tf.where(is_small_error, squared_loss, linear_loss)
```
> 성능을 위해서는 벡터화하여 구현해야 하며 텐서플로 그래프의 장점을 활용하려면 텐서플로 연산만 사용해야 한다.

- 전체 손실의 평균이 아니라 샘플마다 하나의 손실을 담은 텐서를 반환하는 것이 좋다.
  - 케라스가 클래스 가중치나 샘플 가중치를 적용할 수 있다.

이 손실을 사용해 케라스 모델의 컴파일 메서드를 호출하고 모델을 훈련할 수 있다.

```python
model.compile(loss=huber_fn, optimizer="nadam")
model.fit(X_train, y_train, [...])
```

- 훈련하는 동안 케라스가 `huber_fn()` 함수를 호출하여 손실을 계산하고 이를 사용해 경사 하강법을 수행한다.
- 에포크 시작부터 전체 손실을 기로하여 평균 손실을 출력한다.

## 12.3.2 사용자 정의 요소를 가진 모델을 저장하고 로드하기

모델을 로드할 때는 함수 이름과 실제 함수를 매핑한 딕셔너리를 전달해야 한다. 좀 더 일반적으로 사용자 정의 객체를 포함한 모델을 로드할 때는 그 이름과 객체를 매핑해야 한다.

```python
from tensorflow.keras.models import load_model

model = load_model("my_model_with_a_custom_loss.h5",
                   custom_objects={"huber_fn": huber_fn})

```
- 매개변수를 받을 수 있는 함수 만들기

```python
def create_huber(threshold=1.0):
  def huber_fn(y_true, y_pred):
    error = y_true - y_pred
    is_small_error = tf.abs(error) < threshold
    squared_loss = tf.square(error) / 2
    linear_loss = threshold * tf.abs(error) - threshold**2 / 2
    return tf.where(is_small_error, squared_loss, linear_loss)
  return huber_fn

model.compile(loss=create_huber(2.0), optimizer="nadam")
```
모델을 저장할 때 이 threshold 값은 저장되지 않는다.
- 모델을 저장할 때 threshold 값을 지정해야 한다.
- `keras.losses.Loss` 클래스를 상속하고 `get_config()` 메서드를 구현하여 해결할 수 있다.

```python
# threshold 값 지정 방법
model = keras.models.load_model("my_model_with_a_custom_loss_threshold_2.h5",
                                custom_objects={"huber_fn": create_huber(2.0)})
```

```python
from tensorflow.keras.losses import Loss

class HuberLoss(Loss):
  def __init__(self, threshold=1.0, **kwargs):
    self.threshold = threshold
    super().__init__(**kwargs)
  def call(self, y_true, y_pred):
    error = y_true - y_pred
    is_small_error = tf.abs(error) < self.threshold
    squared_loss = tf.square(error) / 2
    linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2
    return tf.where(is_small_error, squared_loss, linear_loss)
  def get_config(self):
    base_config = super().get_config()
    return {**base_config, "threshold": self.threshold}
```

- 생성자는 기본적인 하이퍼파라미터를 `**kwargs`로 받은 매개변수 값을 부모 클래스의 생성자에게 전달한다.
- `call()` 메서드는 레이블과 예측을 받고 모든 샘플의 손실을 계산하여 반환한다.
- `get_config()` 메서드는 하이퍼파라미터 이름과 같이 매핑된 딕셔너리를 반환한다.
  - 부모 클래스의 `get_config()` 메서드를 호출한다.
  - 그다음 반환된 딕셔너리에 새로운 하이퍼파라미터를 추가한다.

모델을 컴파일할 때 이 클래스의 인스턴스를 사용할 수 있다.
```python
model.compile(loss=HuberLoss(2.), optimizer="nadam")  # threshold 별도로 전달할 필요 x
```

모델을 저장할 때 임계값도 함께 저장된다. 모델을 로드할 때 클래스 이름과 클래스 자체를 매핑해주어야 한다.

```python
model = keras.models.load_model("my_model_with_a_custom_loss_class.h5",
                                custom_objects={"HuberLoss": HuberLoss})
```

- 모델을 저장할 때 케라스는 손실 객체의 `get_config()` 메서드를 호출하여 반환된 설정을 HDF5 파일에 JSON 형태로 저장한다.
- 모델을 로드하면 HuberLoss 클래스의 `from_config()` 클래스 메서드를 호출한다.
- 이 메서드는 기본 손실 클래스(Loss)에 구현되어 있고 생성자에게 `**config` 매개변수를 전달해 클래스의 인스턴스를 만든다.

## 12.3.3 활성화 함수, 초기화, 규제, 제한을 커스터마이징하기

- 사용자 정의 활성화 함수(`keras.activations.softplus()`)

```python
def my_softplus(z):
  return tf.math.log(tf.exp(z) + 1.0)
```

- 사용자 정의 글로럿 초기화(`keras.initializers.glorot_normal()`)

```python
def my_glorot_initializer(shape, dtype=tf.float32):
  stddev = tf.sqrt(2. / (shape[0] + shape[1]))
  return tf.random.normal(shape, stddev=stddev, dtype=dtype)
```

- 사용자 정의 $l_1$ 규제(`keras.regularizers.l1(0.01)`)

```python
def my_l1_regularizer(weights):
  return tf.reduce_sum(tf.abs(0.01 * weights))
```

- 양수인 가중치만 남기는 사용자 정의 제한(`keras.constraints.nonneg()`)

```python
def my_positive_weights(weights):
  return tf.where(weights < 0., tf.zeros_like(weights), weights)
```
매개변수는 사용자 정의하려는 함수의 종류에 따라 다르며 만들어진 사용자 정의 함수는 보통 함수와 동일하게 사용할 수 있다.

```python
from tensorflow.keras.layers import Dense

layer = Dense(30, activation=my_softplus,
              kernel_initializer=my_glorot_initializer,
              kernel_regularizer=my_l1_regularizer,
              kernel_constraint=my_positive_weights)
```

- 이 활성화 함수는 Dense 층의 출력에 적용되고 다음 층에 그 결과가 전달된다.
- 층의 가중치는 초기화 함수에서 반환된 값으로 초기화된다.
- 훈련 스텝마다 가중치가 규제 함수에 전달되어 규제 손실을 계산하고 전체 손실에 추가되어 훈련을 위한 최종 손실을 만든다.
- 제한 함수가 훈련 스텝마다 호출되어 층의 가중치를 제한한 가중치 값으로 바뀐다.

## 12.3.4 사용자 정의 지표

- 손실은 모델을 훈련하기 위해 경사 하강법에서 사용하므로 미분 가능해야 하고 그레이디언트가 모든 곳에서 0이 아니어야 한다.
- 지표는 모델을 평가할 때 사용한다.
  - 미분이 가능하지 않거나 모든 곳에서 그레이디언트가 0이어도 괜찮다.

대부분의 경우 사용자 지표 함수를 만드는 것은 사용자 손실 함수를 만드는 것과 동일하다.

```python
model.compile(loss="mse", optimizer="nadam", metrics=[create_huber(2.0)])
```

훈련하는 동안 각 배치에 대해 케라스는 지표를 계산하고 에포크가 시작할 때부터 평균을 기록한다.

**스트리밍 지표**는 배치마다 점진적으로 업데이트되는 지표를 말한다. 이런 지표를 만들 때는 `keras.metrics.Metric` 클래스를 상속한다.

```python
from tensorflow.keras.metrics import Metric
import tensorflow as tf
# 전체 후버 손실과 지금까지 처리한 샘플 수 기록하는 클래스

class HuberMetric(keras.metrics.Metric):
  def __init__(self, threshold=1.0, **kwargs):
    # add_weight() 메서드를 사용해 여러 배치에 걸쳐 지표의 상태를 기록하기 위한 변수를 생성
    super().__init__(**kwargs)
    self.threshold = threshold
    self.huber_fn = create_huber(threshold)
    self.total = self.add_weight("total", initializer="zeros")
    self.count = self.add_weight("count", initializer="zeros")

  # 이 클래스를 함수처럼 사용할 때 호출되며 배치의 레이블과 예측을 바탕으로 변수를 업데이트
  def update_state(self, y_true, y_pred):
    metric = self.huber_fn(y_true, y_pred)
    self.total.assign_add(tf.reduce_sum(metric))
    self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))

  # 최종 결과를 계산하고 반환
  def result(self):
    return self.total / self.count

  # threshold 변수를 모델과 함께 저장
  def get_config(self):
    base_config = super().get_config()
    return {**base_config, "threshold": self.threshold}
```


## 12.3.5 사용자 정의 층

텐서플로에는 없는 특이한 층을 가진 네트워크를 만들어야 할 때가 있다. 이런 경우 사용자 정의 층을 만든다. 
- `keras.layers.Flatten`나 `keras.layers.ReLU`와 같은 층은 가중치가 없다. 이런 경우 사용자 정의 층을 만드는 방법은 `keras.layers.Lambda` 층으로 감싼다.

```python
exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))
```

이런 사용자 정의 층을 시퀀셜 API나 함수형 API, 서브클래싱 API에서 보통의 층과 동일하게 사용할 수 있다. 또는 활성화 함수로 사용할 수 있다.

```python
from tensorflow.keras.layers import Layer

class MyDense(Layer):
  def __init__(self, units, activation=None, **kwargs):
    # 모든 하이퍼파라미터를 매개변수로 받는다.
    # **kwargs 매개변수를 추가하면 부모 생성자를 호출할 때 전달되며 이를 통해 input_shape, trainable, name과 같은 기본 매개변수들을 처리할 수 있다.
    # 그 다음 하이퍼파라미터를 속성으로 저장하고 activation 매개변수를 keras.activations.get() 함수를 사용해 적절한 활성화 함수를 바꾼다.
    super().__init__(**kwargs)
    self.units = units
    self.activation = tf.keras.activations.get(activation)
  
  # 가중치마다 add_weight() 메서드를 호출하여 층의 변수를 만든다. 
  # build() 메서드는 층이 처음 사용될 때 호출되며 이 시점이 되면 케라스가 층의 입력 크기를 알고 있을 것이므로 build() 메서드의 입력으로 크기를 전달한다.
  def build(self, batch_input_shape):
    self.kernel = self.add_weight(
      name='kernel', shape=[batch_input_shape[-1], self.units],
      initializer='glorot_normal')
    self.bias = self.add_weight(
      name='bias', shape=[self.units], initializer="zero")
    super().build(batch_input_shape)

  # 층에 필요한 연산을 수행
  def call(self, X):
    return self.activation(X @ self.kernel + self.bias)

  # 층의 출력 크기를 반환
  def compute_output_shape(self, batch_input_shape):
    return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])

  # keras.activations.serialize()를 사용하여 활성화 함수의 전체 설정을 저장
  def get_config(self):
    base_config = super().get_config()
    return {**base_config, "units": self.units,
            "activation": keras.activations.serialize(self.activation)}
```

**두 개의 입력과 세 개의 출력을 만드는 층 만들기**

```python
class MyMultiLayer(tf.keras.layers.Layer):
  def call(self, X):
    X1, X2 = X
    return [X1 + X2, X1 * X2, X1 / X2]
  def compute_output_shape(self, batch_input_shape):
    b1, b2 = batch_input_shape
    return [b1, b1, b1]
```

- 훈련과 테스트에서 다르게 동작하는 층이 필요하다면 `call()` 메서드에 training 매개변수를 추가하여 훈련인지 테스트인지를 결정해야 한다.

훈련하는 동안(규제 목적으로) 가우스 잡음을 추가하고 테스트 시에는 아무것도 하지 않는 층을 만들기

```python
class MyGaussianNoise(tf.keras.layers.Layer):
  def __init__(self, stddev, **kwargs):
    super().__init__(**kwargs)
    self.stdd ev = stddev

  def call(self, X, training=None):
    if training:
      noise = tf.random.normal(tf.shape(X), stddev=self.stddev)
      return X + noise
  
  def compute_output_shape(self, batch_input_shape):
    return batch_input_shape
```

## 12.3.6 사용자 정의 모델

사용자 정의 모델: 스킵 연결이 있는 사용자 정의 **잔차 블록**(ResidualBlock) 층을 가진 모델

<img src="https://user-images.githubusercontent.com/78655692/147800280-3206b109-7c98-4c60-a4aa-47fdb223458e.png" height="500px" width="600px">


- 사용자 정의 모델은 `keras.Model` 클래스를 상속하여 생성자에서 층과 변수를 만들고 모델이 해야 할 작업을 `call()` 메서드에 구현한다.
- 입력이 첫 번째 완전 연결 층을 통과하여 두 개의 완전 연결 층과 스킵 연결로 구성된 `잔차 블록`(residual block)으로 전달된다.
- 동일한 잔차 블록에 세 번 더 통과시킨다.
- 그 다음 두 번째 `잔차 블록`을 지나 마지막 출력이 완전 연결된 출력 층에 전달된다.

```python
import tensorflow as tf

# 케라스가 알아서 추적해야 할 객체가 담긴 hidden 속성을 감지하고 필요한 변수를 자동으로 이 층의 변수 리스트에 추가
class ResidualBlock(keras.layers.Layer):
  def __init__(self, n_layers, n_neurons, **kwargs):
    super().__init__(**kwargs)
    self.hidden = [keras.layers.Dense(n_neurons, activation="elu",
                                      kernel_initializer="he_normal")
                  for _ in range(n_layers)]
  
  def call(self, input):
    Z = inputs
    for layer in self.hidden:
      Z = layer(Z)
    return inputs + Z
```

**서브클래싱 API를 사용해 이 모델을 정의해보기**

```python
class ResidualRegressor(tf.keras.Model):
  def __init__(self, output_dim, **kwargs):
    super().__init__(**kwargs)
    self.hidden1 = tf.keras.layers.Dense(30, activation="elu",
                                        kernel_initializer="he_normal")
    self.block1 = ResidualBlock(2, 30)
    self.block2 = ResidualBlock(2, 30)
    self.out = tf.keras.layers.Dense(output_dim)
  
  def call(self, inputs):
    Z = self.hidden1(inputs)
    for _ in range(1 + 3):
      Z = self.blcok1(Z)
    Z = self.block2(Z)
    return self.out(Z)
```

## 12.3.7 모델 구성 요소에 기반한 손실과 지표

은닉층의 가중치나 활성화 함수 등과 같이 모델의 구성 요소에 기반한 손실을 정의해야 할 때가 있다. 이런 손실은 규제나 모델의 내부 상황을 모니터링할 때 유용하다.

모델 구성 요소에 기반한 손실을 정의하고 계산하여 `add_loss()` 메서드에 그 결과를 전달한다.

**사용자 정의 재구성 손실을 가지는 모델 만들기**<br>
- 맨 위의 은닉층에 보조 출력을 가지며 이 보조 출력에 연결된 손실을 `재구성 손실` 이라고 부른다.
  - 재구성 손실: 재구성과 입력 사이의 평균 제곱 오차
- 재구성 손실을 주 손실에 더하여 회귀 작업에 직접적으로 도움이 되지 않은 정보일지라고 모델이 은닉층을 통과하면서 가능한 많은 정보를 유지하도록 유도한다.
  - 일반화 성능을 향상시킨다.

```python
class ReconstructingRegressor(tf.keras.Model):
  def __init__(self, output_dim, **kwargs):
    # 생성자가 다섯 개의 은닉층과 하나의 출력층으로 구성된 심층 신경망을 만든다.
    super().__init__(**kwargs)
    self.hidden = [tf.keras.layers.Dense(30, activation='selu',
                                        kernel_initializer='lecun_normal')
                  for _ in range(5)]
    self.out = tf.keras.layers.Dense(output_dim)
  
  # 완전 연결 층을 하나 더 추가하여 모델의 입력을 재구성하는 데 사용
  def build(self, batch_input_shape):
    n_inputs = batch_input_shape[-1]
    self.reconstruct = keras.layers.Dense(n_inputs)
    super().build(batch_input_shape)
  
  # 입력이 다섯 개의 은닉층에 모두 통과한다. 그 다음 결과값을 재구성 층에 전달하여 재구성을 만든다.
  # 재구성 손실(재구성과 입력 사이의 평균 제곱 오차)을 계산하고 add_loss() 메서드를 사용해 모델의 손실 리스트에 추가한다.
  # 은닉층의 출력을 출력층에 전달하여 얻은 출력겂을 반환한다.
  def call(self, inputs):
    Z = inputs
    for layer in self.hidden:
      Z = layer(Z)
    reconstruction = self.reconstruct(Z)
    recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))
    self.add_loss(0.05 * recon_loss)
    return self.out(Z)
```

## 12.3.8 자동 미분을 사용하여 그레이디언트 계산하기

```python
def f(w1, w2):
  return 3 * w1 ** 2 + 2 * w1 * w2

w1, w2 = 5, 3; eps = 1e-6
# 각 파리미터가 바뀔 때마다 함수의 출력이 얼마나 변하는지 측정하여 도함수의 근사값을 계산
print((f(w1 + eps, w2) - f(w1, w2)) / eps) # 36.000003007075065
print((f(w1, w2 + eps) - f(w1, w2)) / eps) # 10.000000003174137
```

**자동 미분 사용해보기**

```python
w1, w2 = tf.Variable(5.), tf.Variable(3.)
with tf.GradientTape() as tape:
  z = f(w1, w2)

gradients = tape.gradient(z, [w1, w2])
gradients
# [<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,
#  <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]
```

- `tf.GradientTape()`는 변수와 관련된 모든 연산을 자동으로 기록한다.
- `tape.gradient()`는 변수에 대한 z의 그레이디언트를 요청한다.

`gradient()` 메서드는 두 번 호출하면 예외가 발생하므로 한 번 이상 호출해야 한다면 지속 가능한 테이프를 만들고 사용이 끝난 후 테이프를 삭제하여 리소스를 해제해야 한다.

```python
with tf.GradientTape(persistent=True) as tape:
  z = f(w1, w2)

dz_dw1 = tape.gradient(z, w1)
dz_dw2 = tape.gradient(z, w2)
del tape
```

기본적으로 테이프는 변수가 포함된 연산만 기록하므로 변수가 아닌 다른 객체에 대한 z의 그레이디언트를 계산하면 None이 반환된다.

```python
# tf.constant()는 값을 변경이 불가
c1, c2 = tf.constant(5.), tf.constant(3.)
with tf.GradientTape() as tape:
  z = f(c1, c2)

gradients = tape.gradient(z, [c1, c2]) # [None, None]이 반환
```

하지만 필요한 어떤 텐서라도 감시하여 관련된 모든 연산을 기록하도록 강제할 수 있다.

```python
with tf.GradientTape() as tape:
  tape.watch(c1)
  tape.watch(c2)
  z = f(c1, c2)

gradients = tape.gradient(z, [c1, c2]) [36., 10.] 반환
```

- 입력이 작을 때 변동 폭이 큰 활성화 함수에 대한 규제 손실을 구현하는 경우는 유용하다.
  - 이 손실은 입력에 대한 활성화 함수의 그레이디언트를 기반으로 하며 입력이 변수가 아니므로 테이프에 기록을 명시적으로 알려주어야 한다.

**안전한 그레이디언트 계산**

그레이디언트를 계산할 때 수치적인 이슈가 발생할 수 있다.<br>
ex) 큰 입력에 대한 my_softplus() 함수의 그레이디언트를 계산하면 NaN이 반환된다.

사용자 정의 그레이디언트 `tf.custom_gradient`를 활용하여 안전한 그레이디언트를 계산할 수 있다.

```python
@tf.custom_gradient
def my_better_softplus(z):
  exp = tf.exp(z)
  def my_softplus_gradients(grad):
    return grad / (1 + 1 / exp)
  return tf.math.log(exp + 1), my_softplus_gradients
```







