---
title: "νμ΄ν† μΉ κΈ°μ΄(2)"
excerpt: "λ°μ΄ν„° μ„ΈνΈμ™€ λ°μ΄ν„° λ΅λ” / λ¨λΈ & λ°μ΄ν„°μ„ΈνΈ λ¶„λ¦¬ / λ¨λΈ μ €μ¥ λ° λ¶λ¬μ¤κΈ°"

categories:
  - Pytorch
tags:
  - [Pytorch]

permalink: /pytorch/basic-2/

toc: true
toc_sticky: true

date: 2025-04-30
last_modified_at: 2025-06-14
---

## π¦¥ λ°μ΄ν„°μ„ΈνΈμ™€ λ°μ΄ν„°λ΅λ”

λ°μ΄ν„°μ„ΈνΈ: λ°μ΄ν„°μ μ§‘ν•©μ„ μλ―Έν•λ©°, μ…λ ¥κ°’(X)κ³Ό κ²°κ³Όκ°’(Y)μ— λ€ν• μ •λ³΄λ¥Ό μ κ³µν•κ±°λ‚ μΌλ ¨μ λ°μ΄ν„° λ¬¶μμ„ μ κ³µ
- κµ¬μ΅°: μΌλ°μ μΌλ΅ λ°μ΄ν„°λ² μ΄μ¤(Database)μ ν…μ΄λΈ”(Table)κ³Ό κ°™μ€ ν•νƒ
- λ°μ΄ν„°μ„ΈνΈμ ν• ν¨ν„΄μ„ ν…μ΄λΈ”μ ν–‰(Row)μΌλ΅ κ°„μ£Όν•λ‹¤λ©΄, μ΄ ν–‰μ—μ„ λ°μ΄ν„°λ¥Ό λ¶λ¬μ™€ ν•™μµμ„ μ§„ν–‰

λ°μ΄ν„°μ κµ¬μ΅°λ‚ ν¨ν„΄μ€ λ§¤μ° λ‹¤μ–‘ν•λ©° ν•™μµν•΄μ•Ό ν•λ” λ°μ΄ν„°κ°€ νμΌ κ²½λ΅λ΅ μ κ³µλκ±°λ‚ λ°μ΄ν„°λ¥Ό ν™μ©ν•κΈ° μ„ν•΄μ„ μ „μ²λ¦¬ λ‹¨κ³„κ°€ ν•„μ”ν• κ²½μ°κ°€ μλ‹¤. λν• λ‹¤μ–‘ν• λ°μ΄ν„°κ°€ ν¬ν•¨λ λ°μ΄ν„°μ„ΈνΈμ—μ„λ” νΉμ •ν• ν•„λ“μ κ°’μ„ μ‚¬μ©ν•κ±°λ‚ μ‚¬μ©ν•μ§€ μ•μ„ μ μλ‹¤.

λ°μ΄ν„°λ¥Ό λ³€ν•ν•κ³  λ§¤ν•‘ν•λ” μ½”λ“λ¥Ό ν•™μµ κ³Όμ •μ— μ§μ ‘ λ°μν•λ©΄ **λ¨λ“ν™”(Modularization)**, **μ¬μ‚¬μ©μ„±(Reusable)**, **κ°€λ…μ„±(Readability)** λ“±μ„ λ–¨μ–΄λ¨λ¦¬λ” μ£Όμ” μ›μΈμ΄ λλ‹¤. μ΄λ¬ν• ν„μƒμ„ λ°©μ§€ν•κ³  μ½”λ“λ¥Ό κµ¬μ΅°μ μΌλ΅ μ„¤κ³„ν•  μ μλ„λ΅ λ°μ΄ν„°μ„ΈνΈμ™€ λ°μ΄ν„°λ΅λ”λ¥Ό μ‚¬μ©ν•λ‹¤.

### λ°μ΄ν…μ„ΈνΈ

**λ°μ΄ν„°μ„ΈνΈ(Dataset)**λ” ν•™μµμ— ν•„μ”ν• λ°μ΄ν„° μƒν”μ„ μ •μ ν•κ³  μ •λ‹µμ„ μ €μ¥ν•λ” κΈ°λ¥μ„ μ κ³µν•λ‹¤.
- μ΄κΈ°ν™” λ©”μ„λ“(`__init__`): μ…λ ¥λ λ°μ΄ν„°μ μ „μ²λ¦¬ κ³Όμ •μ„ μν–‰ν•λ” λ©”μ„λ“
  - μƒλ΅μ΄ μΈμ¤ν„΄μ¤κ°€ μƒμ„±λ  λ• ν•™μµμ— μ‚¬μ©λ  λ°μ΄ν„°λ¥Ό μ„ μ–Έν•κ³ , ν•™μµμ— ν•„μ”ν• ν•νƒλ΅ λ³€ν•ν•λ” κ³Όμ •μ„ μ§„ν–‰
- νΈμ¶ λ©”μ„λ“(`__getitem__`): ν•™μµμ„ μ§„ν–‰ν•  λ• μ‚¬μ©λλ” ν•λ‚μ ν–‰μ„ λ¶λ¬μ¤λ” κ³Όμ •
  - μ…λ ¥λ μƒ‰μΈ(index)μ— ν•΄λ‹Ήν•λ” λ°μ΄ν„° μƒν”μ„ λ¶λ¬μ¤κ³  λ°ν™
  - μ΄κΈ°ν™” λ©”μ„λ“μ—μ„ λ³€ν•λκ±°λ‚ κ°μ„ λ λ°μ΄ν„°λ¥Ό κ°€μ Έμ¤λ©°, λ°μ΄ν„° μƒν”κ³Ό μ •λ‹µμ„ λ°ν™
- κΈΈμ΄ λ°ν™ λ©”μ„λ“(`__len__`): ν•™μµμ— μ‚¬μ©λ μ „μ²΄ λ°μ΄ν„°μ„ΈνΈμ κ°μλ¥Ό λ°ν™
  - λ©”μ„λ“λ¥Ό ν†µν•΄ λ‡ κ°μ λ°μ΄ν„°λ΅ ν•™μµμ΄ μ§„ν–‰λλ”μ§€ ν™•μΈν•  μ μμ

```python
# λ°μ΄ν„°μ„ΈνΈ ν΄λμ¤ κΈ°λ³Έν•
class Dataset:

  def __init__(self, data, *arg, **kwargs):
    self.data = data
  
  def __getitem__(self, index):
    return tuple(data[index] for data in data.tensors)
  
  def __len__(self):
    return self.data[0].size(0)

```

λ¨λΈ ν•™μµμ„ μ„ν•΄ μ„μμ λ°μ΄ν„°μ„ΈνΈλ¥Ό κµ¬μ„±ν•  λ• νμ΄ν† μΉμ—μ„ μ§€μ›ν•λ” λ°μ΄ν„°μ„ΈνΈ ν΄λμ¤λ¥Ό μƒμ†λ°›μ•„ μ‚¬μ©ν•λ‹¤. μƒλ΅ μ •μν• λ°μ΄ν„°μ„ΈνΈ ν΄λμ¤λ” ν„μ¬ μ‹μ¤ν…μ— μ ν•©ν• κµ¬μ΅°λ΅ λ°μ΄ν„°λ¥Ό μ „μ²λ¦¬ν•΄ μ‚¬μ©ν•λ‹¤.

### λ°μ΄ν„°λ΅λ”

**λ°μ΄ν„°λ΅λ”(DataLoader)**λ” λ°μ΄ν„°μ„ΈνΈμ— μ €μ¥λ λ°μ΄ν„°λ¥Ό μ–΄λ– ν• λ°©μ‹μΌλ΅ λ¶λ¬μ™€ ν™μ©ν• μ§€ μ •μν•λ‹¤. ν•™μµμ„ μ΅°κΈ λ” μ›ν™ν•κ² μ§„ν–‰ν•  μ μλ„λ΅ μ—¬λ¬ κΈ°λ¥μ„ μ κ³µν•λ‹¤.
- λ°°μΉ ν¬κΈ°(batch_size): ν•™μµμ— μ‚¬μ©λλ” λ°μ΄ν„°μ κ°μκ°€ λ§¤μ° λ§μ•„ ν• λ²μ μ—ν­μ—μ„ λ¨λ“  λ°μ΄ν„°λ¥Ό λ©”λ¨λ¦¬μ— μ¬λ¦΄ μ μ—†μ„ λ• λ°μ΄ν„°λ¥Ό λ‚λ„λ” μ—­ν• μ„ ν•λ‹¤.
  - μ „μ²΄ λ°μ΄ν„°μ„ΈνΈμ—μ„λ°°μΉ ν¬κΈ°λ§νΌ λ°μ΄ν„° μƒν”μ„ λ‚λ„κ³ , λ¨λ“  λ°°μΉλ¥Ό λ€μƒμΌλ΅ ν•™μµμ„ μ™„λ£ν•λ©΄ ν• λ²μ μ—ν­μ΄ μ™„λ£
- λ°μ΄ν„° μμ„ λ³€κ²½(shuffle): λ°μ΄ν„°μ μμ„λ΅ ν•™μµλλ” κ²ƒμ„ λ°©μ§€
- λ°μ΄ν„° λ΅λ“ ν”„λ΅μ„Έμ¤ μ(num_workers): λ°μ΄ν„°λ¥Ό λ¶λ¬μ¬ λ• μ‚¬μ©ν•  ν”„λ΅μ„Έμ¤μ κ°μ

### λ‹¤μ¤‘ μ„ ν•νκ·€

λ°μ΄ν„°μ„ΈνΈμ™€ λ°μ΄ν„°λ΅λ”λ¥Ό ν™μ©ν•΄ λ‹¤μ¤‘ μ„ ν•νκ·€λ¥Ό κµ¬ν„ν•λ©΄ μ•„λμ™€ κ°™μ΄ κµ¬ν„ν•  μ μλ‹¤.

```python
import torch
from torch import nn
from torch import optim
from torch.utils.data import TensorDataset, DataLoader

# κΈ°λ³Έ λ°μ΄ν„° κµ¬μ΅° μ„ μ–Έ
train_x = torch.FloatTensor([
  [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]
])
train_y = torch.FloatTensor([
  [0.1, 1.5], [1, 2.8], [1.9, 4.1], [2.8, 5.4], [3.7, 6.7], [4.6, 8]
])

# λ°μ΄ν„°μ„ΈνΈμ™€ λ°μ΄ν„°λ΅λ”
train_dataset = TensorDataset(train_x, train_y)
train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True)

# λ¨λΈ, μ¤μ°¨ ν•¨μ, μµμ ν™” ν•¨μ μ„ μ–Έ
model = nn.Linear(2, 2, bias=True)
criterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.001)

# λ°μ΄ν„°λ΅λ” μ μ©
for epoch in range(20000):
  cost = 0.0
  for batch in train_dataloader:
    x, y = batch
    output = model(x)

    loss = criterion(output, y)
    loss.backward()
    optimizer.step()

    cost += loss

  cost = cost / len(train_dataloader)

  if (epoch + 1) % 1000 == 0:
    print(f"Epoch: {epoch+1:4d}, Model: {list(model.parameters())}, Cost: {cost:.3f}")
```

μ‹¤μ  ν™κ²½μ—μ„ μ μ©λλ” λ°μ΄ν„°(ν•™μµμ— μ‚¬μ©ν•μ§€ μ•μ€ λ°μ΄ν„°)λ¥Ό ν†µν•΄ μ§€μ†μ μΌλ΅ κ²€μ¦ν•κ³ , μµμ μ λ§¤κ°λ³€μλ¥Ό μ°Ύλ” λ°©λ²•μΌλ΅ λ¨λΈμ„ κµ¬μ„±ν•΄μ•Ό ν•λ‹¤. μ΄ μ΄μ λ΅ λ°μ΄ν„°μ κµ¬μ΅°λ‚ ν•νƒλ” μ§€μ†ν•΄μ„ λ³€κ²½λ  μ μμΌλ―€λ΅ λ°μ΄ν„°μ„ΈνΈμ™€ λ°μ΄ν„°λ΅λ”λ¥Ό ν™μ©ν•΄ μ½”λ“ ν’μ§μ„ λ†’μ΄κ³  λ°λ³µ λ° λ³€κ²½λλ” μ‘μ—…μ— λ€ν•΄ λ” ν¨μ¨μ μΌλ΅ λ€μ²ν•΄μ•Όν•λ‹¤.

## π¦¥ λ¨λΈ/λ°μ΄ν„°μ„ΈνΈ λ¶„λ¦¬

**λ¨λΈ(Model)**μ€ μΈκ³µ μ‹ κ²½λ§ λ¨λ“μ„ ν™μ©ν•΄ κµ¬ν„λλ©° λ°μ΄ν„°μ— λ€ν• μ—°μ‚°μ„ μν–‰ν•λ” κ³„μΈµμ„ μ •μν•κ³ , μλ°©ν–¥ μ—°μ‚°μ„ μν–‰ν•λ‹¤.
- ν΄λμ¤ κµ¬μ΅°λ¥Ό ν™μ©
- μ‹ κ²½λ§ ν¨ν‚¤μ§€μ λ¨λ“(`Module`) ν΄λμ¤λ¥Ό ν™μ©

μƒλ΅μ΄ λ¨λΈ ν΄λμ¤λ¥Ό μƒμ„±ν•λ ¤λ©΄ λ¨λ“ ν΄λμ¤λ¥Ό μƒμ†λ°›μ•„ μ„μμ μ„λΈ ν΄λμ¤λ¥Ό μƒμ„±ν•λ©° μ΄λ” λ‹¤λ¥Έ λ¨λ“ ν΄λμ¤λ¥Ό ν¬ν•¨ν•  μ μμΌλ©° **νΈλ¦¬ κµ¬μ΅°(Tree Structure)**λ΅ μ¤‘μ²©ν•  μ μλ‹¤.

### λ¨λ“ ν΄λμ¤

- μ΄κΈ°ν™” λ©”μ„λ“(`__init__`)μ™€ μλ°©ν–¥ λ©”μ„λ“(`forward`)λ¥Ό μ¬μ •μν•μ—¬ ν™μ©
  - μ΄κΈ°ν™” λ©”μ„λ“λ” μ‹ κ²½λ§μ— μ‚¬μ©λ  κ³„μΈµμ„ μ΄κΈ°ν™”
  - μλ°©ν–¥ λ©”μ„λ“μ—μ„λ” λ¨λΈμ΄ μ–΄λ–¤ κµ¬μ΅°λ¥Ό κ°–κ² λ μ§€λ¥Ό μ •μ
- λ¨λΈ κ°μ²΄λ¥Ό νΈμ¶ν•λ” μκ°„ μλ°©ν–¥ λ©”μ„λ“κ°€ μ •μν• μμ„λ€λ΅ ν•™μµμ„ μ§„ν–‰

```python
# λ¨λ“ ν΄λμ¤ κΈ°λ³Έν•
class Model(nn.Module):
  def __init__(self):
    super().__init__()
    self.conv1 = nn.Conv2d(1, 20, 5)
    self.conv2 = nn.Conv2d(20, 20, 5)
  
  def forward(self, x):
    x = F.relu(self.conv1(x))
    x = F.relu(self.conv2(x))
    return x
```

- μ΄κΈ°ν™” λ©”μ„λ“(`__init__`)
  - `super` ν•¨μλ΅ λ¨λ“ ν΄λμ¤μ μ†μ„±μ„ μ΄κΈ°ν™”ν•λ©° μ΄λ¥Ό ν†µν•΄ λ¶€λ¨ ν΄λμ¤λ¥Ό μ΄κΈ°ν™”ν•λ©΄ μ„λΈ ν΄λμ¤μΈ λ¨λΈμ—μ„ λ¶€λ¨ ν΄λμ¤μ μ†μ„±μ„ μ‚¬μ©ν•  μ μμ
  - λ¨λΈ μ΄κΈ°ν™” μ΄ν›„, ν•™μµμ— μ‚¬μ©λλ” κ³„μΈµμ„ μ΄κΈ°ν™” λ©”μ„λ“μ— μ„ μ–Έ
  - λ¨λΈ λ§¤κ°λ³€μ: `self.conv1`μ΄λ‚ `self.conv2`μ™€ κ°™μ€ μΈμ¤ν„΄μ¤
- μλ°©ν–¥ λ©”μ„λ“(`forward`)
  - λ¨λΈ λ§¤κ°λ³€μλ¥Ό μ΄μ©ν•΄ μ‹ κ²½λ§ κµ¬μ΅°λ¥Ό μ„¤κ³„
  - λ¨λΈμ΄ λ°μ΄ν„°(`x`)λ¥Ό μ…λ ¥λ°›μ•„ ν•™μµμ„ μ§„ν–‰ν•λ” κ³Όμ •μ„ μ •μ
  - λ¨λΈμ μΈμ¤ν„΄μ¤λ¥Ό νΈμ¶ν•λ” μκ°„ νΈμ¶ λ©”μ„λ“(`__call__`)κ°€ μλ°©ν–¥ λ©”μ„λ“λ¥Ό μ‹¤ν–‰

μ—­λ°©ν–¥(`backward`) μ—°μ‚°μ€ μ •μν•μ§€ μ•μ•„λ„ λλ‹¤. νμ΄ν† μΉμ μλ™ λ―Έλ¶„ κΈ°λ¥μΈ Autogradμ—μ„ λ¨λΈμ λ§¤κ°λ³€μλ¥Ό μ—­μΌλ΅ μ „νν•΄ μλ™μΌλ΅ κΈ°μΈκΈ° λλ” λ³€ν™”λ„λ¥Ό κ³„μ‚°ν•΄ μ¤€λ‹¤.

### λΉ„μ„ ν• νκ·€

λΉ„μ„ ν• νκ·€λ¥Ό λ¨λ“ ν΄λμ¤λ¥Ό μ μ©ν•΄ λ¨λΈλ΅ κµ¬ν„ν•  μ μλ‹¤.

λ°μ΄ν„° ν•νƒλ” λ‹¤μκ³Ό κ°™λ‹¤.

|x   |y    |
|----|-----|
|-10.0|327.79|
|-9.9|321.39|
|-9.8|314.48|
|-9.7|308.51|
|-9.6|302.86|
|...|...|

x λ°μ΄ν„°μ™€ y λ°μ΄ν„°λ” $y = 3.1x^2 - 1.7x + random(0.01, 0.99)$μ κ΄€κ³„λ¥Ό κ°–λ”λ‹¤. 

```python
# λΌμ΄λΈλ¬λ¦¬ λ° ν”„λ μ„μ›ν¬ μ΄κΈ°ν™”
import torch
import pandas as pd
from torch import nn
from torch import optim
from torch.utils.data import Dataset, DataLoader

# μ‚¬μ©μ μ •μ λ°μ΄ν„° μ„ΈνΈ
class CustomDataset(Dataset):
  def __init__(self, file_path):
    df = pd.read_csv(file_path)
    self.x = df.iloc[:, 0].values
    self.y = df.iloc[:, 1].values
    self.length = len(df)

  def __getitem__(self, index):
    x = torch.FloatTensor([self.x[index] ** 2, self.x[index]])
    y = torch.FloatTensor([self.y[index]])
    return x, y
  
  def __len__(self):
    return self.length
```

λ°μ΄ν„°μ„ΈνΈ ν΄λμ¤λ¥Ό μƒμ†λ°›μ•„ μ‚¬μ©μ μ •μ λ°μ΄ν„°μ„ΈνΈ(`CustomDataset`)λ¥Ό μ •μν•λ‹¤. 
- μ΄κΈ°ν™” λ©”μ„λ“(`__init__`)μ—μ„λ” λ°μ΄ν„°λ¥Ό λ¶λ¬μ¤λ©° κ°’μ„ ν• λ‹Ήν•λ‹¤.
  - `self.x`: x κ°’
  - `self.y`: y κ°’
  - `self.length`: λ°μ΄ν„°μ μ „μ²΄ κΈΈμ΄
- νΈμ¶ λ©”μ„λ“(`__getitem__`)μ—μ„ x κ°’κ³Ό y κ°’μ„ λ°ν™ν•λ‹¤.
  - κ²°κ³Όκ°’μ΄ μ΄μ°¨ λ°©μ •μ‹($y = W_1x^2 + W_2x + b$) x κ°’μ€ [$x^2$, $x$]μ κµ¬μ΅°λ΅ λ°ν™ν•κ³  y κ°’μ€ [$y$] κµ¬μ΅°λ΅ λ°ν™ν•λ‹¤.
- λ°ν™ λ©”μ„λ“(`__len__`)λ΅ μ΄κΈ°ν™” λ©”μ„λ“μ—μ„ μ„ μ–Έν• `self.length`λ¥Ό λ°ν™ν•΄ ν„μ¬ λ°μ΄ν„°μ κΈΈμ΄λ¥Ό μ κ³µν•λ‹¤.

μ‚¬μ©μ μ •μ λ°μ΄ν„°μ„ΈνΈ κµ¬μ„±μ„ μ™„λ£ν–λ‹¤λ©΄ μ‚¬μ©μ μ •μ λ¨λΈμ„ μ„ μ–Έν•λ‹¤.

```python
# μ‚¬μ©μ μ •μ λ¨λΈ
class CustomModel(nn.Module):
  def __init__(self):
    super().__init__()
    self.layer = nn.Linear(2, 1)

  def forward(self, x):
    x = self.layer(x)
    return x
```

λ¨λ“ ν΄λμ¤λ¥Ό μƒμ†λ°›μ•„ μ‚¬μ©μ μ •μ λ¨λΈμ„ μ •μν•λ‹¤.
- `super` ν•¨μλ¥Ό ν†µν•΄ λ¨λ“ ν΄λμ¤μ μ†μ„±μ„ μ΄κΈ°ν™”ν•κ³  λ¨λΈμ—μ„ μ‚¬μ©ν•  κ³„μΈµμ„ μ •μ
- **μ„ ν• λ³€ν™ ν•¨μ**(`nn.Linear`)μ **μ…λ ¥ λ°μ΄ν„° μ°¨μ› ν¬κΈ°(in_features)**λ” μ΄μ°¨ λ‹¤ν•­μ‹μ΄λ―€λ΅ 2λ¥Ό μ…λ ¥ν•κ³ , **μ¶λ ¥ λ°μ΄ν„° μ°¨μ› ν¬κΈ°(out_features)**λ” 1μ„ μ…λ ¥ν•λ‹¤.

λ¨λΈ λ§¤κ°λ³€μ μ„ μ–Έμ„ λ¨λ‘ μ™„λ£ν–λ‹¤λ©΄ μλ°©ν–¥ λ©”μ„λ“μ—μ„ ν•™μµ κ³Όμ •μ„ μ •μν•λ‹¤.
- `forward` μ—μ„ `self.layer` λ³€μμ— μ…λ ¥ λ°μ΄ν„° xλ¥Ό μ „λ‹¬ν•κ³  κ²°κ³Όκ°’μ„ λ°ν™

μ‚¬μ©μ μ •μ ν΄λμ¤λ¥Ό λ¨λ‘ μ„ μ–Έν•λ©΄ μΈμ¤ν„΄μ¤λ¥Ό μƒμ„±ν•λ‹¤.

```python
# μ‚¬μ©μ μ •μ λ°μ΄ν„°μ„ΈνΈμ™€ λ°μ΄ν„°λ΅λ”
train_dataset = CustomDataset("../datasets/non_linear.csv")
train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)
```

`train_dataset` λ³€μμ— `CustomDataset` μΈμ¤ν„΄μ¤λ¥Ό μƒμ„±ν• ν›„ `train_dataloader` λ³€μμ— λ°μ΄ν„°λ΅λ” μΈμ¤ν„΄μ¤λ¥Ό μƒμ„±ν•λ‹¤. **λ°°μΉ ν¬κΈ°(batch_size)**μ™€ **λ°μ΄ν„° μμ„ λ³€κ²½(shuffle)**κ³Ό **λ§μ§€λ§‰ λ°°μΉ μ κ±°(drop_last)**λ¥Ό μ°Έ κ°’μΌλ΅ ν• λ‹Ήν•λ‹¤.

μΈμ¤ν„΄μ¤λ¥Ό μƒμ„±ν• ν›„ λ¨λΈ, μ¤μ°¨ ν•¨μ, μµμ ν™” ν•¨μλ¥Ό μ„ μ–Έν•κ³  GPU μ—°μ‚°μ„ μ μ©ν•λ‹¤.

```python
# GPU μ—°μ‚° μ μ©
device = "cuda" if torch.cuda.is_available() else "cpu"
model = CustomModel().to(device)
criterion = nn.MSELoss().to(device)
optimizer = optim.SGD(model.parameters(), lr=0.0001)
```

- `model` λ³€μμ— μ‚¬μ©μ μ •μ λ¨λΈμ„ μ •μν•κ³  `criterion` λ³€μμ— ν‰κ·  μ κ³± μ¤μ°¨λ¥Ό ν• λ‹Ήν•λ‹¤. 
- `to` λ©”μ„λ“λ¥Ό μ‚¬μ©ν•μ—¬ `CustomModel`κ³Ό `MSELoss` ν΄λμ¤μ ν•™μµ μ¥μΉλ¥Ό μ„¤μ •ν•λ‹¤.
- `optimizer` λ³€μμ— μµμ ν™” ν•¨μλ¥Ό μ •μ

μ΄ν›„ ν•™μµμ„ μ§„ν–‰ν•λ‹¤.

```python
# ν•™μµ μ§„ν–‰
for epoch in range(10000):
  cost = 0.0

  for x, y in train_dataloader:
    x = x.to(device)
    y = y.to(device)

    output = model(x)
    loss = criterion(output, y)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    cost += loss

  cost = cost / len(train_dataloader)

  if (epoch + 1) % 1000 == 0:
    print(f"Epoch : {epoch + 1: 4d}, Model: {list(model.parameters())}, Cost: {cost:.3f}")

############## μ¶λ ¥κ²°κ³Ό ##############
# Epoch: 1000, Model: [
# Parameter containing:  tensor([[3.1034, -1.7008]], device='cuda:0', requires_grad=True), 
# Parameter containing: tensor([0.2861], device='cuda:0', requires_grad=True)],
# Cost : 0.095
```

μ¶λ ¥κ²°κ³Όλ¥Ό μν•λ©΄ κ°€μ¤‘μΉλ” κ°κ° 3.1034($W_1$), -1.7008($W_2$)λ΅ κ³„μ‚°λλ©°, νΈν–¥μ€ 0.4008($b$)μ κ°’μ„ λ°ν™ν•λ‹¤.

### λ¨λΈ ν‰κ°€

ν•™μµμ— μ‚¬μ©ν•μ§€ μ•λ” μ„μμ λ°μ΄ν„°λ¥Ό λ¨λΈμ— μ…λ ¥ν•΄ λ¨λΈμ„ ν‰κ°€ν•λ” μ½”λ“λ” λ‹¤μκ³Ό κ°™λ‹¤.

```python
# λ¨λΈ ν‰κ°€
with torch.no_grad():
  model.eval()
  inputs = torch.FloatTensor(
    [
      [1 ** 2, 1],
      [5 ** 2, 5],
      [11 ** 2, 11]
    ]
  ).to(device)

  outputs = model(inputs)
  print(outputs)
```

ν…μ¤νΈ λ°μ΄ν„°μ„ΈνΈλ‚ μ„μμ κ°’μΌλ΅ λ¨λΈμ„ ν™•μΈν•κ±°λ‚ ν‰κ°€ν•  λ•λ” `torch.no_grad` ν΄λμ¤λ¥Ό ν™μ©ν•λ‹¤.
- `no_grad`: κΈ°μΈκΈ° κ³„μ‚°μ„ λΉ„ν™μ„±ν™”ν•λ” ν΄λμ¤λ΅ μλ™ λ―Έλ¶„ κΈ°λ¥μ„ μ‚¬μ©ν•μ§€ μ•λ„λ΅ μ„¤μ •
- ν…μ¤νΈ λ°μ΄ν„°λ” λ¨λΈμ—μ„ μ”κµ¬ν•λ” μ…λ ¥ μ°¨μ›κ³Ό λ™μΌν• κµ¬μ΅°λ¥Ό κ°€μ Έμ•Ό ν•λ‹¤.

λ§μ•½ λ‹¤μ‹ ν•™μµμ„ μ§„ν–‰ν•λ ¤λ©΄ `train` λ©”μ„λ“λ¥Ό νΈμ¶ν•΄μ„ λ¨λ“λ¥Ό λ³€κ²½ν•΄μ•Όν•λ‹¤.

```python
# λ¨λΈ μ €μ¥
torch.save(
  model, 
  "../models/model.pt"
)

torch.save(
  model.state_dict(),
  "../models/model_state_dict.pt"
)
```
λ¨λΈ νμΌμ„ μ €μ¥ν•λ©΄ λ‚μ¤‘μ— λ‹¤μ‹ ν™μ©ν•  μ μλ‹¤.

### λ°μ΄ν„°μ„ΈνΈ λ¶„λ¦¬

λ¨Έμ‹ λ¬λ‹μ—μ„ μ‚¬μ©λλ” **μ „μ²΄ λ°μ΄ν„°μ„ΈνΈ(Original Dataset)**λ” λ‘ κ°€μ§€ λλ” μ„Έ κ°€μ§€λ΅ λ‚λ μ μλ‹¤.
- ν›λ ¨μ© λ°μ΄ν„°(Training Data): λ¨λΈμ„ ν•™μµν•λ” λ° μ‚¬μ©
- ν…μ¤νΈ λ°μ΄ν„°(Test Data): κ²€μ¦μ© λ°μ΄ν„°λ¥Ό ν†µν•΄ κ²°μ •λ μ„±λ¥μ΄ κ°€μ¥ μ°μν• λ¨λΈμ„ μµμΆ… ν…μ¤νΈν•κΈ° μ„ν• λ©μ μΌλ΅ μ‚¬μ©
- κ²€μ¦μ© λ°μ΄ν„°(Validation Data): ν•™μµμ΄ μ™„λ£λ λ¨λΈμ„ κ²€μ¦ν•κΈ° μ„ν• λ°μ΄ν„°μ„ΈνΈμ΄λ©° μ£Όλ΅ κµ¬μ΅°κ°€ λ‹¤λ¥Έ λ¨λΈμ μ„±λ¥ λΉ„κµλ¥Ό μ„ν•΄ μ‚¬μ©

<img src="https://blog.kakaocdn.net/dn/bTyx0o/btrPB3fQhdD/dPGAowsqF5pdiEC4KV0v30/img.png">

μ¦‰, ν›λ ¨μ© λ°μ΄ν„°λ” λ¨λΈ ν•™μµμ„ μ„ν• λ°μ΄ν„° μ§‘ν•©, κ²€μ¦μ© λ°μ΄ν„°λ” λ¨λΈ μ„ μ •μ„ μ„ν• λ°μ΄ν„° μ§‘ν•©, ν…μ¤νΈ λ°μ΄ν„°λ” μµμΆ… λ¨λΈμ μ„±λ¥μ„ ν‰κ°€ν•κΈ° μ„ν• λ°μ΄ν„° μ§‘ν•©μΌλ΅ λ³Ό μ μμΌλ©° μ£Όλ΅ 6:2:2 λλ” 8:1:1μ λΉ„μ¨λ΅ μ„¤μ •ν•λ‹¤.

```python
# λ°μ΄ν„° λ¶„λ¦¬
import torch
import pandas as pd
from torch import nn
from torch import optim
from torch.utils.data import Dataset, DataLoader, random_split

dataset = CustomDataset("../datasets/non_linear.csv")
dataset_size = len(dataset)
train_size = int(dataset_size * 0.8)
validation_size = int(dataset_size * 0.1)
test_size = dataset_size - train_size - validation_size

train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])

train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)
validation_dataloader = DataLoader(validation_dataset, batch_size=4, shuffle=True, dorp_last=True)
test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)

# μ¤‘λµ

with torch.no_grad():
  model.eval()
  for x, y in validation_dataloader:
    x = x.to(device)
    y = y.to(device)

    outputs = model(x)
```

λ°μ΄ν„°μ„ΈνΈ λ¶„λ¦¬λ¥Ό μ„ν•΄ `torch.utils.data` λ¨λ“μ—μ„ **λ¬΄μ‘μ„ λ¶„λ¦¬(`random_split`) ν•¨μλ¥Ό ν¬ν•¨μ‹ν‚¨λ‹¤.

```python
# λ¬΄μ‘μ„ λ¶„λ¦¬ ν•¨μ¤
subset = torch.utils.data.random_split(
  dataset,
  lengths,
  generator
)
```

λ¬΄μ‘μ„ λ¶„λ¦¬ ν•¨μλ” **λ¶„λ¦¬ κΈΈμ΄(`lengths`)**λ§νΌ **λ°μ΄ν„°μ„ΈνΈ(`dataset`)**μ **μ„λΈμ…‹(`subset`)**μ„ μƒμ„±ν•λ‹¤.
**μƒμ„±μ(`generator`)**λ” μ„λΈμ…‹μ— ν¬ν•¨λ  λ¬΄μ‘μ„ λ°μ΄ν„°λ“¤μ λ‚μ μƒμ„± μ‹λ“λ¥Ό μλ―Έν•λ‹¤.

```python
with torch.no_grad():
  model.eval()
  for x, y in validation_dataloader:
    x = x.to(device)
    y = y.to(device)

    outputs = model(x)
```

λ¨λΈ κ²€μ¦ κ³Όμ •μ—μ„λ” κ²€μ¦μ© λ°μ΄ν„°(validation_dataloader)**λ¥Ό ν™μ©ν•΄ λ¨λΈ μ„±λ¥μ„ ν™•μΈν•λ‹¤. μ΄ν›„ λ¨λΈμ΄ κ²°μ •λλ©΄ μµμΆ… ν‰κ°€λ¥Ό μ„ν•΄ ν…μ¤νΈ λ°μ΄ν„°(`test_dataloader`)λ΅ λ§μ§€λ§‰ μ„±λ¥ κ²€μ¦μ„ μ§„ν–‰ν•λ‹¤.

## π¦¥ λ¨λΈ μ €μ¥ λ° λ¶λ¬μ¤κΈ°