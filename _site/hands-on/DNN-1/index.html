<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.22.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="ko" class="no-js">
  <head>
    <style> 
      ::-webkit-scrollbar{ 
        width: 10px;
        height: 10px;
      }

      ::-webkit-scrollbar-track {
        width: 0px;
        background-color: rgba(224, 224, 224, 0.2);
        /* border-radius: 5px; */
      }

      ::-webkit-scrollbar-thumb {
        width: 0px;
        background-color: rgba(220, 219, 218, 0.6);
        border-radius: 5px;
      }

      ::-webkit-scrollbar-thumb:hover {
        width: 10px;
        height: 20px;
        /* background-color: rgba(190, 190, 190, 0.2); */
        background-color: rgba(193, 192, 191, 0.7);
        border-radius: 5px;
      }

      ::-webkit-scrollbar-track:hover {
        width: 10px;
        /* background-color: rgba(150, 150, 150, 0.1); */
        background-color: rgba(224, 224, 224, 0.5);
        border-radius: 5px;
        /* background: transparent; */
        /* border-radius: 10px; */
      }

      ::-webkit-scrollbar-button:start:decrement,::-webkit-scrollbar-button:end:increment {
          width:0px;
          height: 0px;
          /* background-color: rgb(14, 221, 24); */
          /* border-radius: 50%; */
      }
    </style>
    
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>11장 케라스를 사용한 인공 신경망 소개(1) | Seojin</title>
<meta name="description" content="그레이디언트/전이학습/비지도학습">


  <meta name="author" content="Seojin">
  
  <meta property="article:author" content="Seojin">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="ko_KR">
<meta property="og:site_name" content="Seojin Devlog">
<meta property="og:title" content="11장 케라스를 사용한 인공 신경망 소개(1)">
<meta property="og:url" content="http://localhost:4000/hands-on/DNN-1/">


  <meta property="og:description" content="그레이디언트/전이학습/비지도학습">







  <meta property="article:published_time" content="2025-03-07T00:00:00+09:00">



  <meta property="article:modified_time" content="2025-03-07T00:00:00+09:00">



  

  


<link rel="canonical" href="http://localhost:4000/hands-on/DNN-1/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Seojin",
      "url": "http://localhost:4000/"
    
  }
</script>






<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Seojin Devlog Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      processEscapes: true
    }
  });
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->


    <link rel="apple-touch-icon" sizes="180x180" href="https://Parkseojin2001.github.io/assets/images/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://Parkseojin2001.github.io/assets/images/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://Parkseojin2001.github.io/assets/images/favicon/favicon-16x16.png">
    <link rel="manifest" href="https://Parkseojin2001.github.io/assets/images/favicon/site.webmanifest">
    <link rel="mask-icon" href="https://Parkseojin2001.github.io/assets/images/favicon/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#ffc40d">
    <meta name="theme-color" content="#ffffff">
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Seojin Devlog
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="https://Parkseojin2001.github.io/">Home</a>
            </li><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="https://github.com/Parkseojin2001">GitHub</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="/assets/images/meee.png" alt="Seojin" itemprop="image">
      
    </div>
  

  <!-- 2022.02.17 author content hidden -->
  <!-- <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Seojin</h3>
    
    
  </div> -->

  <div class="author__urls-wrapper">
    <!-- <button class="btn btn--inverse">Follow</button> -->
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle menu</label>
  <ul class="nav__items">
    <!-- <li>
      <span class="nav__total">🌴 Total Posts: 15</span>
    </li> -->
    
    
      <li>
        
          <!-- title -->
              <span class="nav__sub-title">COMPUTER SCIENCE</span>
              <hr>
        

        
        <ul>
          
            <!-- sub-title -->
            
              
            
              
                <li><a href="/categories/data-structure/">Data Structure (4)</a></li>
              
            
              
            
              
            
              
            
              
            
              
            
          
            <!-- sub-title -->
            
              
            
              
            
              
            
              
            
              
                <li><a href="/categories/algorithm/">Algorithm (1)</a></li>
              
            
              
            
              
            
          
            <!-- sub-title -->
            
              
                <li><a href="/categories/os/">Operating System (1)</a></li>
              
            
              
            
              
            
              
            
              
            
              
            
              
            
          
        </ul>
        
      </li>
    
      <li>
        
          <!-- title -->
              <span class="nav__sub-title">AI</span>
              <hr>
        

        
        <ul>
          
            <!-- sub-title -->
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
          
            <!-- sub-title -->
            
              
            
              
            
              
                <li><a href="/categories/hands-on/">핸즈온 머신러닝 (5)</a></li>
              
            
              
            
              
            
              
            
              
            
          
        </ul>
        
      </li>
    
      <li>
        
          <!-- title -->
              <span class="nav__sub-title">PROGRAMMING</span>
              <hr>
        

        
        <ul>
          
            <!-- sub-title -->
            
              
            
              
            
              
            
              
                <li><a href="/categories/python/">Python (2)</a></li>
              
            
              
            
              
            
              
            
          
        </ul>
        
      </li>
    
      <li>
        
          <!-- title -->
              <span class="nav__sub-title">PROJECT</span>
              <hr>
        

        
        <ul>
          
            <!-- sub-title -->
            
              
            
              
            
              
            
              
            
              
            
              
            
              
                <li><a href="/categories/capstone-design/">Capstone Design (1)</a></li>
              
            
          
        </ul>
        
      </li>
    
      <li>
        
          <!-- title -->
              <span class="nav__sub-title">GIT</span>
              <hr>
        

        
        <ul>
          
            <!-- sub-title -->
            
              
            
              
            
              
            
              
            
              
            
              
                <li><a href="/categories/git/">Git (1)</a></li>
              
            
              
            
          
            <!-- sub-title -->
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
          
        </ul>
        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="11장 케라스를 사용한 인공 신경망 소개(1)">
    <meta itemprop="description" content="그레이디언트/전이학습/비지도학습">
    <meta itemprop="datePublished" content="2025-03-07T00:00:00+09:00">
    <meta itemprop="dateModified" content="2025-03-07T00:00:00+09:00">

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">11장 케라스를 사용한 인공 신경망 소개(1)
</h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        <time datetime="2025-03-07T00:00:00+09:00">March 7, 2025</time>
      </span>
    

    

    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#111-그레이디언트-소실과-폭주-문제">11.1 그레이디언트 소실과 폭주 문제</a><ul><li><a href="#1111-글로럿과-he-초기화">11.1.1 글로럿과 He 초기화</a><ul><li><a href="#활성화-함수와-초기화-방식">활성화 함수와 초기화 방식</a></li></ul></li></ul></li><li><a href="#1112-수렴하지-않는-활성화-함수">11.1.2 수렴하지 않는 활성화 함수</a><ul><li><a href="#활성화-함수-쓰는-방법">활성화 함수 쓰는 방법</a></li></ul></li></ul></li><li><a href="#1113-배치-정규화">11.1.3 배치 정규화</a></li><li><a href="#1114-그레이디언트-클리핑">11.1.4 그레이디언트 클리핑</a></li></ul></li><li><a href="#112-사전훈련된-층-재사용하기">11.2 사전훈련된 층 재사용하기</a><ul><li><a href="#1121-케라스를-사용한-전이-학습">11.2.1 케라스를 사용한 전이 학습</a></li><li><a href="#1122-비지도-사전훈련">11.2.2 비지도 사전훈련</a></li><li><a href="#1123-보조-작업에서-사전훈련">11.2.3 보조 작업에서 사전훈련</a></li></ul></li></ul>

            </nav>
          </aside>
        
        <p>데이터에 따라 깊은 심층 신경망을 훈련해야 한다. 심층 신경망을 훈련하는 도중에 다음과 같은 문제를 마주할 수 있다.</p>

<ul>
  <li><strong>그레이디언트 소실</strong> 또는 <strong>그레이디언트 폭주</strong> 문제에 직면할 수 있다. 심층 신경망의 아래쪽으로 갈수록 그레이디언트가 점점 더 작아지거나 커지는 현상이다. 두 현상 모두 하위층을 훈련하기 매우 어렵게 만든다.</li>
  <li>대규모 신경망을 위한 훈련 데이터가 충분하지 않거나 레이블을 만드는 작업에 비용이 너무 많이 들 수 있다.</li>
  <li>훈련이 극단적으로 느려질 수 있다.</li>
  <li>수백만 개의 파라미터를 가진 모델은 훈련 세트에 과대적합될 위험이 매우 크며 특히 훈련 샘플이 충분하지 않거나 잡음이 많은 경우 발생한다.</li>
</ul>

<h1 id="111-그레이디언트-소실과-폭주-문제">11.1 그레이디언트 소실과 폭주 문제</h1>

<p><strong>그레이디언트 소실</strong><br />
알고리즘이 하위층으로 진행될수록 그레이디언트가 점점 작아지는 경우가 많으며 이는 하위층의 연결 가중치를 변경되지 않은 채로 두게되며 훈련이 좋은 솔루션으로 수렴되지 않는 현상</p>

<p><strong>그레이디언트 폭주</strong><br />
그레이디언트가 점점 커져서 여러 층이 비정상적으로 큰 가중치로 갱신되어 알고리즘이 발산할 수 있다. 주로 순환 신경망에서 나타난다.</p>

<p>원인은 로지스틱 시그모이드 활성화 함수와 가중치 초기화 방법의 조합이었다.</p>
<ul>
  <li>각 층에서 출력의 분산이 입력의 분산보다 더 크다.</li>
  <li>신경망의 위쪽으로 갈수록 층을 지날 때마다 분산이 계속 커져 가장 높은 층에서는 활성화 함수가 0이나 1로 수렴한다.</li>
  <li>로지스틱 함수의 평균이 0이 아니고 0.5라는 사실 때문에 더 나빠진다.</li>
</ul>

<p><img src="https://user-images.githubusercontent.com/78655692/148024675-70b17a10-cba9-480a-ab91-189d4722c19b.png" height="400px" width="500px" /></p>

<ul>
  <li>입력이 0이나 1로 수렴해서 기울기가 0에 매우 가까워진다.</li>
  <li>역전파가 될 때 전파할 그레이디언트가 거의 없고 조금 있는 그레이디언트는 최상위층에서부터 역전파가 진행되면서 점차 약해져서 실제로 아래쪽 층에는 아무것도 도달하지 않게 된다.</li>
</ul>

<h2 id="1111-글로럿과-he-초기화">11.1.1 글로럿과 He 초기화</h2>
<ul>
  <li>층에 사용되는 활성화 함수의 종류에 따라 세 가지 초기화 방식 중 하나를 선택
    <ul>
      <li>글로럿(Glorot) 초기화</li>
      <li>르쿤(LeCun) 초기화</li>
      <li>헤(He) 초기화</li>
    </ul>
  </li>
  <li>예측을 할 때는 정방향으로, 그레이디언트를 역전파할 때는 역방향으로 양방향 신호가 적절하게 흘러야 한다.</li>
  <li>글로럿과 벤지오는 적절한 신호가 흐르기 위해서는 각 충의 출력에 대한 분산이 입력에 대한 분산과 같아야 한다고 주장했다. 그리고 역방향에서 층을 통과하기 전과 후의 그레이디언트 분산이 동일해야 한다.</li>
</ul>

<p><strong>세이비어 초기화</strong> or <strong>글로럿 초기화</strong><br />
\(fan_{avg} = \frac{fan_{in} + fan_{out}}{2}\)</p>
<ul>
  <li>$fan_{in}$(팬-인) : 층에 들어오는 입력 수</li>
  <li>$fan_{out}$(팬-아웃) : 층에 들어오는 입력 수</li>
  <li>평균($\mu$)이 0이고 분산($\sigma^2$)이 $\sigma^2 = \frac{1}{fan_{avg}}$ 인 정규분포</li>
  <li>$r = \sqrt{\frac{3}{fan_{avg}}}$ 일 때 $-r$과 $+r$ 사이의 균등분포</li>
</ul>

<p><strong>르쿤 초기화</strong><br /></p>
<ul>
  <li>글로럿 초기화 정의에서 $fan_{avg}$를 $fan_{in}$으로 변경</li>
</ul>

<p><strong>He 초기화</strong><br /></p>
<ul>
  <li>ReLU와 ReLU의 변종 활성화 함수에 대한 초기화 전략</li>
</ul>

<h4 id="활성화-함수와-초기화-방식">활성화 함수와 초기화 방식</h4>

<table>
  <thead>
    <tr>
      <th>초기화 전략</th>
      <th>활성화 함수</th>
      <th>$\sigma^2$(정규분포)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>글로럿</td>
      <td>활성화 함수 없음, 하이퍼볼릭 탄젠트, 로지스틱, 소프트맥스</td>
      <td>$1/fan_{avg}$</td>
    </tr>
    <tr>
      <td>He</td>
      <td>ReLU 함수와 그 변종들</td>
      <td>$2/fan_{in}$</td>
    </tr>
    <tr>
      <td>르쿤</td>
      <td>SELU</td>
      <td>$1/fan_{in}$</td>
    </tr>
  </tbody>
</table>

<p>케라스는 기본적으로 균등분포의 글로럿 초기화를 사용한다. 다음과 같이 층을 만들 때 <code class="language-plaintext highlighter-rouge">kernel_initializer="he_uniform"</code> 이나 <code class="language-plaintext highlighter-rouge">kernel_initializer="he_normal"</code>로 바꾸어 He 초기화를 사용할 수 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>

<span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">"he_normal"</span><span class="p">)</span>
</code></pre></div></div>

<p>$fan_{in}$ 대신 $fan_{out}$ 기반의 균등분포 He 초기화를 사용하는 경우</p>
<ul>
  <li>Variance Scaling 사용</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow.keras.initializers</span> <span class="kn">import</span> <span class="n">VarianceScaling</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>

<span class="n">he_avg_init</span> <span class="o">=</span> <span class="n">VarianceScaling</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">2.</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'fan_avg'</span><span class="p">,</span>
                              <span class="n">distribution</span><span class="o">=</span><span class="s">'uniform'</span><span class="p">)</span>
<span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">he_avg_init</span><span class="p">)</span>
</code></pre></div></div>
<h2 id="1112-수렴하지-않는-활성화-함수">11.1.2 수렴하지 않는 활성화 함수</h2>

<p>그전에는 대부분 시그모이드 활성화 함수가 최선의 선택일 것이라고 생각했다. 하지만 ReLU 함수는 특정 양수값에 수렴하지 않으며 계산이 빠르다는 큰 장점이 있다.<br />
하지만 dying ReLU로 알려진 문제점이 있다.</p>
<ul>
  <li>훈련하는 동안 일부 뉴런이 0 이외의 값을 출력하지 않는다라는 의미</li>
</ul>

<p>가중치 합이 음수이면 ReLU 함수의 그레이디언트가 0이 되므로 경사하강법이 더는 작동하지 않는다.</p>

<p>해결책: <code class="language-plaintext highlighter-rouge">LeakyReLU</code> 함수</p>
<ul>
  <li>$LeakyReLU_{\alpha}(z) = max(\alpha z, z)$</li>
  <li>하이퍼파라미터 $\alpha$가 이 함수가 ‘새는’ 정도를 결정한다.
    <ul>
      <li>새는 정도란 $z &lt; 0$ 일 때 이 함수의 기울기이며, 일반적으로 0.01로 설정한다. 이 작은 기울기가 LeakyReLU를 절대 죽지 않게 만들어준다.</li>
    </ul>
  </li>
  <li>ReLU보다 좋은 성능 발휘(default = $\alpha = 0.1$)
    <ul>
      <li>$\alpha = 0.2$로 할 때 좀 더 성능이 좋아짐</li>
    </ul>
  </li>
</ul>

<p><img src="https://user-images.githubusercontent.com/78655692/148028052-8b6c9ff4-9e5b-44bc-9676-f317fe533aab.png" height="400px" width="500px" /></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">RReLU</code>(randomized leaky ReLU) : 훈련하는 동안 주어진 범위에서 $\alpha$를 무작위로 선택하고 테스트시에는 평균을 사용
    <ul>
      <li>과대적합을 줄이는 규제역할도 수행</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">PReLU</code>(parametric leaky ReLU) : $\alpha$가 훈련하는 동안 학습(하이퍼파라미터가 아니고 다른 모델 파라미터와 마찬가지로 역전파에 의해 변경)
    <ul>
      <li>대규모 이미지 데이터셋에서 ReLU보다 성능이 좋음</li>
      <li>소규모 데이터셋에서는 과대적합 위험성 존재</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">ELU</code>(exponential linear unit): 앞에서 언급된 ReLU 변종들보다 성능이 좋음
    <ul>
      <li>훈련 시간이 줄고 신경망의 테스트 세트 성능도 더 높음</li>
    </ul>
  </li>
</ul>

\[ELU_{\alpha}(z)=
\begin{cases}
\alpha(exp(z)-1) \; if\;z&lt;0\\
z \; \; \; \; \; \; \; \; \; \; \; \; \; \; \; \; if\;z\geq0
\end{cases}\]

<p><img src="https://user-images.githubusercontent.com/78655692/148224276-da25c5c6-1bf5-469c-93f7-ae6a1e3226bc.png" height="400px" width="500px" /></p>

<ul>
  <li>$z &lt; 0$일 때 음수값이 들어오므로 활성화 함수의 평균 출력이 0에 더 가꿔워진다. 이는 그레이디언트 소실 문제를 완화해준다.</li>
  <li>하이퍼파라미터 $\alpha$는 z가 큰 음수값일 때 ELU가 수렴할 값을 정의한다.</li>
  <li>$z &lt; 0$이어도 그레이디언트가 0이 아니므로 죽은 뉴런을 만들지 않는다.</li>
  <li>$\alpha=1$이면 이 함수는 $z=0$에서 급격히 변동하지 않으므로 $z=0$을 포함해 모든 구간에서 매끄러워 경사 하강법의 속도를 높여준다.</li>
</ul>

<p><strong>장단점</strong><br /></p>
<ul>
  <li>수렴 속도가 빠르다.</li>
  <li>지수 함수를 사용하므로 ReLU나 그 변종들보다 계산이 느리다.</li>
  <li>
    <p>훈련 시에는 수렴 속도가 빨라서 느린 계산이 상쇄되지만 테스트 시에는 ELU를 사용한 네트워크기 ReLU를 사용한 네트워크보다 느릴 것이다.</p>
  </li>
  <li><code class="language-plaintext highlighter-rouge">SELU</code>(Scaled ELU) : ELU 활성화 함수의 변종
    <ul>
      <li>완전 연결 층만 쌓아서 신경망을 만들고 모든 은닉층이 SELU 활성화 함수를 사용한다면 네트워크가 자기 정규화(self-normalized)된다고 주장</li>
      <li>훈련하는 동안 각 층의 출력이 평균 0과 표준편차 1을 유지하는 경향이 있다.
        <ul>
          <li>그레이디언트 소실과 폭주 문제를 막아준다.</li>
        </ul>
      </li>
      <li>다른 활성화 함수보다 뛰어난 성능을 종종 보이지만 자기 정규화가 일어나기 위한 몇 가지 조건이 있다.
1) 입력 특성이 반드시 표준화(평균 0, 표준편차 1)되어야 한다.
2) 모든 은닉층의 가중치는 르쿤 정규분포 초기화로 초기화되어야 한다. 케라스에서는 <code class="language-plaintext highlighter-rouge">kernel_initializer="lecun_normal</code>로 설정
3) 네트워크는 일렬로 쌓은 층으로 구성되어야 한다. 순환 신경망이나 스킵 연결과 같이 순차적이지 않은 구조에서 사용하면 자기 정규화되는 것을 보장하지 않는다.
4) 모든 층이 완전연결층이어야 한다.</li>
    </ul>
  </li>
</ul>

<h4 id="활성화-함수-쓰는-방법">활성화 함수 쓰는 방법</h4>
<ul>
  <li>일반적으로 SELU &gt; ELU &gt; LeakyReLU(그리고 변종들) &gt; ReLU &gt; tanh &gt; sigmoid 순</li>
  <li>네트워크가 자기 정규화되지 못하는 구조라면 SELU 보단 <code class="language-plaintext highlighter-rouge">ELU</code></li>
  <li>실행 속도가 중요하다면 <code class="language-plaintext highlighter-rouge">LeakyReLU</code>(하이퍼파라미터를 더 추가하고 싶지 않다면 케라스에서 사용하는 기본값 
$\alpha$ 사용)</li>
  <li>시간과 컴퓨팅 파워가 충분하다면 교차 검증을 사용해 여러 활성화 함수를 평가</li>
  <li>신경망이 과대적합되었다면 <code class="language-plaintext highlighter-rouge">RReLU</code></li>
  <li>훈련세트가 아주 크다면 <code class="language-plaintext highlighter-rouge">PReLU</code></li>
  <li>ReLU가 가장 널리 사용되는 활성화 함수이므로 많은 라이브러리와 하드웨어 가속기들이 ReLU에 특화되어 최적화.
따라서 속도가 중요하다면 <code class="language-plaintext highlighter-rouge">ReLU</code>가 가장 좋은 선택</li>
</ul>

<p><strong><code class="language-plaintext highlighter-rouge">LeakyReLU</code> 활성화 함수 사용</strong><br /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">LeakyReLU</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
  <span class="p">[...]</span>
  <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">"he_normal"</span><span class="p">),</span>
  <span class="n">LeakyReLU</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
  <span class="p">[...]</span>
<span class="p">])</span>
</code></pre></div></div>

<p><strong><code class="language-plaintext highlighter-rouge">PReLU</code> 활성화 함수 사용</strong><br /></p>
<ul>
  <li>PReLU층을 만들고 모델에서 적용하려는 층 뒤에 추가</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">PReLU</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
  <span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]),</span>
  <span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_normal'</span><span class="p">),</span>
  <span class="n">PReLU</span><span class="p">(),</span>
  <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'he_normal'</span><span class="p">),</span>
  <span class="n">PReLU</span><span class="p">(),</span>
  <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">)</span>
<span class="p">])</span>
</code></pre></div></div>

<p><strong><code class="language-plaintext highlighter-rouge">SELU</code> 활성화 함수 사용</strong><br /></p>
<ul>
  <li>층을 만들 때 <code class="language-plaintext highlighter-rouge">activation='selu'</code> 와 <code class="language-plaintext highlighter-rouge">kernel_initializer='lecun_normal</code> 지정</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">]))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'selu'</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'lecun_normal'</span><span class="p">))</span>

<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">99</span><span class="p">):</span>
  <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'selu'</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s">'lecun_normal'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="1113-배치-정규화">11.1.3 배치 정규화</h2>

<h2 id="1114-그레이디언트-클리핑">11.1.4 그레이디언트 클리핑</h2>

<h1 id="112-사전훈련된-층-재사용하기">11.2 사전훈련된 층 재사용하기</h1>

<h2 id="1121-케라스를-사용한-전이-학습">11.2.1 케라스를 사용한 전이 학습</h2>

<h2 id="1122-비지도-사전훈련">11.2.2 비지도 사전훈련</h2>

<h2 id="1123-보조-작업에서-사전훈련">11.2.3 보조 작업에서 사전훈련</h2>


        
      </section>

      <footer class="page__meta">
        
        


  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#%ED%95%B8%EC%A6%88%EC%98%A8-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D" class="page__taxonomy-item" rel="tag">핸즈온 머신러닝</a>
    
    </span>
  </p>


        
  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2025-03-07">March 7, 2025</time></p>


      </footer>

      

      
  <nav class="pagination">
    
      <a href="/hands-on/ANN-3/" class="pagination--pager" title="10장 케라스를 사용한 인공 신경망 소개(3)
">Prev</a>
    
    
      <a href="/hands-on/DNN-2/" class="pagination--pager" title="11장 케라스를 사용한 인공 신경망 소개(2)
">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You may also enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/hands-on/DNN-2/" rel="permalink">11장 케라스를 사용한 인공 신경망 소개(2)
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        <time datetime="2025-03-07T00:00:00+09:00">March 7, 2025</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">옵티마이저/과대적합
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/hands-on/ANN-3/" rel="permalink">10장 케라스를 사용한 인공 신경망 소개(3)
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        <time datetime="2025-03-06T00:00:00+09:00">March 6, 2025</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">하이퍼파라미터 튜닝
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/capstone-design/firebase/" rel="permalink">Firebase
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        <time datetime="2025-03-04T00:00:00+09:00">March 4, 2025</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Firebase를 이용한 모델 배포
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/python/grammar/" rel="permalink">Python 문법
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        <time datetime="2025-02-26T00:00:00+09:00">February 26, 2025</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">zip( ) / 아스테리스크(*) / itertools
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 Seojin. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
