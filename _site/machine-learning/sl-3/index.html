<!doctype html>














<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="en" >
  <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  ><!-- Setup Open Graph image -->

  

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="지도학습(3)" />
<meta property="og:locale" content="en" />
<meta name="description" content="파이썬 라이브러리를 활용한 머신러닝 책 내용 정리 포스트" />
<meta property="og:description" content="파이썬 라이브러리를 활용한 머신러닝 책 내용 정리 포스트" />
<link rel="canonical" href="http://localhost:4000/machine-learning/sl-3/" />
<meta property="og:url" content="http://localhost:4000/machine-learning/sl-3/" />
<meta property="og:site_name" content="Seojin Devlog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-09-14T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="지도학습(3)" />
<meta name="twitter:site" content="@twitter_username" />
<meta name="google-site-verification" content="WfkV1-iar8_v-Mbi-ytl5RBJhiNOfpUEWrLuOCyThLQ" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-09-15T00:00:00+09:00","datePublished":"2022-09-14T00:00:00+09:00","description":"파이썬 라이브러리를 활용한 머신러닝 책 내용 정리 포스트","headline":"지도학습(3)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/machine-learning/sl-3/"},"url":"http://localhost:4000/machine-learning/sl-3/"}</script>
<!-- End Jekyll SEO tag -->


  <title>지도학습(3) | Seojin Devlog
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">

  <link rel="manifest" href="/assets/img/favicons/site.webmanifest">

<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="Seojin Devlog">
<meta name="application-name" content="Seojin Devlog">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  <!-- Resource Hints -->
  
    
      
        <link rel="preconnect" href="https://fonts.googleapis.com" >
      
        <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
      
    
      
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      
        <link rel="dns-prefetch" href="https://fonts.gstatic.com" >
      
    
      
        <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      
        <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
      
    
  

  <!-- Bootstrap -->
  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.6/dist/css/bootstrap.min.css">
  

  <!-- Theme style -->
  <link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css">

  <!-- Web Font -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">

  <!-- Font Awesome Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.1/css/all.min.css">

  <!-- 3rd-party Dependencies -->

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.32.2/dist/tocbot.min.css">
  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css">
  

  
    <!-- Image Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.0/dist/css/glightbox.min.css">
  

  <!-- Scripts -->

  <script src="/assets/js/dist/theme.min.js"></script>

  <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  



  <script defer src="https://cdn.jsdelivr.net/combine/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/glightbox@3.3.0/dist/js/glightbox.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.13/dayjs.min.js,npm/dayjs@1.11.13/locale/en.js,npm/dayjs@1.11.13/plugin/relativeTime.js,npm/dayjs@1.11.13/plugin/localizedFormat.js,npm/tocbot@4.32.2/dist/tocbot.min.js,npm/mermaid@11.4.0/dist/mermaid.min.js"></script>







<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script src="/assets/js/data/mathjax.js"></script>
  <script async src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script>


<!-- Pageviews -->

  

  



  

  <!-- A placeholder to allow defining custom metadata -->

</head>


  <body>
    <!-- The Side Bar -->

<aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end">
  <header class="profile-wrapper">
    <a href="/" id="avatar" class="rounded-circle"><img src="/assets/img/avatar.jpg" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a>

    <a class="site-title d-block" href="/">Seojin Devlog</a>
    <p class="site-subtitle fst-italic mb-0">AI 기술을 배우고 코드로 기록하는 학생 개발자입니다</p>
  </header>
  <!-- .profile-wrapper -->

  <nav class="flex-column flex-grow-1 w-100 ps-0">
    <ul class="nav">
      <!-- home -->
      <li class="nav-item">
        <a href="/" class="nav-link">
          <i class="fa-fw fas fa-home"></i>
          <span>HOME</span>
        </a>
      </li>
      <!-- the real tabs -->
      
        <li class="nav-item">
          <a href="/categories/" class="nav-link">
            <i class="fa-fw fas fa-stream"></i>
            

            <span>CATEGORIES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/tags/" class="nav-link">
            <i class="fa-fw fas fa-tags"></i>
            

            <span>TAGS</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/archives/" class="nav-link">
            <i class="fa-fw fas fa-archive"></i>
            

            <span>ARCHIVES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/about/" class="nav-link">
            <i class="fa-fw fas fa-info-circle"></i>
            

            <span>ABOUT</span>
          </a>
        </li>
        <!-- .nav-item -->
      
    </ul>
  </nav>

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    
      <button type="button" class="btn btn-link nav-link" aria-label="Switch Mode" id="mode-toggle">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
        <a
          href="https://github.com/Parkseojin2001"
          aria-label="github"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-github"></i>
        </a>
      
    
      

      
        <a
          href="javascript:location.href = 'mailto:' + ['seojin0510612','gmail.com'].join('@')"
          aria-label="email"
          

          

          

          
        >
          <i class="fas fa-envelope"></i>
        </a>
      
    
      

      
        <a
          href="/feed.xml"
          aria-label="rss"
          

          

          

          
        >
          <i class="fas fa-rss"></i>
        </a>
      
    
      

      
        <a
          href="https://www.linkedin.com/in/seojin-park-793a15287/"
          aria-label="linkedin"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-linkedin"></i>
        </a>
      
    
  </div>
  <!-- .sidebar-bottom -->
</aside>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div class="container d-flex flex-column px-xxl-5">
        <!-- The Top Bar -->

<header id="topbar-wrapper" class="flex-shrink-0" aria-label="Top Bar">
  <div
    id="topbar"
    class="d-flex align-items-center justify-content-between px-lg-3 h-100"
  >
    <nav id="breadcrumb" aria-label="Breadcrumb">
      

      
        
          
            <span>
              <a href="/">Home</a>
            </span>

          
        
          
        
          
            
              <span>지도학습(3)</span>
            

          
        
      
    </nav>
    <!-- endof #breadcrumb -->

    <button type="button" id="sidebar-trigger" class="btn btn-link" aria-label="Sidebar">
      <i class="fas fa-bars fa-fw"></i>
    </button>

    <div id="topbar-title">
      Post
    </div>

    <button type="button" id="search-trigger" class="btn btn-link" aria-label="Search">
      <i class="fas fa-search fa-fw"></i>
    </button>

    <search id="search" class="align-items-center ms-3 ms-lg-0">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="Search..."
      >
    </search>
    <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button>
  </div>
</header>


        <div class="row flex-grow-1">
          <main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->



<!-- Handle images -->




  
  

  
    
      
      
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    

    <!-- take out classes -->
    

    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  

  


<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    

    
  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  




<!-- return -->










<article class="px-1" data-toc="true">
  <header>
    <h1 data-toc-skip>지도학습(3)</h1>
    
      <p class="post-desc fw-light mb-4">파이썬 라이브러리를 활용한 머신러닝 책 내용 정리 포스트</p>
    

    <div class="post-meta text-muted">
      <!-- published date -->
      <span>
        Posted
        <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1663081200"
  data-df="ll"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  Sep 14, 2022
</time>

      </span>

      <!-- lastmod date -->
      
        <span>
          Updated
          <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1663200000"
  data-df="ll"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  Sep 15, 2022
</time>

        </span>
      

      

      <div class="d-flex justify-content-between">
        <!-- author(s) -->
        <span>
          

          By

          <em>
            
              <a href="https://twitter.com/username">Seojin Park</a>
            
          </em>
        </span>

        <div>
          <!-- pageviews -->
          

          <!-- read time -->
          <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="7994 words"
>
  <em>44 min</em> read</span>

        </div>
      </div>
    </div>
  </header>

  
    <div id="toc-bar" class="d-flex align-items-center justify-content-between invisible">
      <span class="label text-truncate">지도학습(3)</span>
      <button type="button" class="toc-trigger btn me-1">
        <i class="fa-solid fa-list-ul fa-fw"></i>
      </button>
    </div>

    <button id="toc-solo-trigger" type="button" class="toc-trigger btn btn-outline-secondary btn-sm">
      <span class="label ps-2 pe-1">Contents</span>
      <i class="fa-solid fa-angle-right fa-fw"></i>
    </button>

    <dialog id="toc-popup" class="p-0">
      <div class="header d-flex flex-row align-items-center justify-content-between">
        <div class="label text-truncate py-2 ms-4">지도학습(3)</div>
        <button id="toc-popup-close" type="button" class="btn mx-1 my-1 opacity-75">
          <i class="fas fa-close"></i>
        </button>
      </div>
      <div id="toc-popup-content" class="px-4 py-3 pb-4"></div>
    </dialog>
  

  <div class="content">
    <h2 id="23-지도-학습-알고리즘"><span class="me-2">2.3 지도 학습 알고리즘</span><a href="#23-지도-학습-알고리즘" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<hr />

<h3 id="234-나이브-베이즈-분류기"><span class="me-2">2.3.4 나이브 베이즈 분류기</span><a href="#234-나이브-베이즈-분류기" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<ul>
  <li><code class="language-plaintext highlighter-rouge">LogisticRegression</code> or <code class="language-plaintext highlighter-rouge">LinearSVC</code> 같은 선형 분류기보다 훈련 속도가 빠르지만 일반화 성능은 떨어진다.</li>
  <li>효과적인 이유 : 각 특성을 개별로 취급해 파라미터를 학습하고 각 특성에서 클래스별 통계를 단순하게 취합하기 때문이다.</li>
</ul>

<div class="table-wrapper"><table>
  <thead>
    <tr>
      <th><center>종류<center></center></center></th>
      <th><center>특징<center></center></center></th>
      <th><center>사용<center></center></center></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><center>GaussianNB<center></center></center></td>
      <td><center>연속적인 데이터<cetner></cetner></center></td>
      <td> </td>
    </tr>
    <tr>
      <td><center>BernoulliNB<center></center></center></td>
      <td><center>이진 데이터<center></center></center></td>
      <td><center>텍스트 분류<center></center></center></td>
    </tr>
    <tr>
      <td><center>MultinomialNB<center></center></center></td>
      <td><center>카운트 데이터(ex. 문장 속 단어의 횟수)<center></center></center></td>
      <td><center>텍스트 분류<center></center></center></td>
    </tr>
  </tbody>
</table></div>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre></td><td class="rouge-code"><pre><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
              <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">counts</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
  <span class="c1"># 각 클래스에 대해 반복
</span>  <span class="c1"># 특성마다 1이 나타난 횟수를 센다.
</span>  <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">y:</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">label: </span><span class="sh">"</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">X:</span><span class="sh">"</span><span class="p">,</span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="n">label</span><span class="p">])</span>
  <span class="n">counts</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">label</span><span class="p">].</span><span class="nf">sum</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">feature count: </span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">counts</span><span class="p">)</span>

<span class="sh">"""</span><span class="s">
y: [0 1 0 1]
label:  0
X: [[0 1 0 1]
  [0 0 0 1]]
y: [0 1 0 1]
label:  1
X: [[1 0 1 1]
  [1 0 1 0]]
feature count: 
 {0: array([0, 1, 0, 2]), 1: array([2, 0, 2, 1])}
</span><span class="sh">"""</span>
</pre></td></tr></tbody></table></code></div></div>

<p><strong>MultinomianlNB와 GaussianNB의 차이점</strong></p>

<ul>
  <li>MultinomialNB : 클래스별로 특성의 평균을 계산</li>
  <li>GaussianNB : 클래스별로 각 특성의 분산과 평균을 저장</li>
</ul>

<p>MultinomialNB와 BernoulliNB의 매개변수로는 모델의 복잡도를 조절하는 <code class="language-plaintext highlighter-rouge">alpha</code> 매개변수 하나를 가지고 있다.</p>

<ul>
  <li>모든 특성에 양의 값을 가진 가상의 데이터 포인트를 <code class="language-plaintext highlighter-rouge">alpha</code> 개수만큼 추가한다.
    <ul>
      <li>통계 데이터를 완만하게 만들어줌.</li>
    </ul>
  </li>
</ul>

<p><code class="language-plaintext highlighter-rouge">alpha</code> 클수록 완만해져 모델의 복잡도는 낮아진다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">alpha</code>에 따른 알고리즘 성능 변동은 크지않아 성능 향상에 크게 기여X
    <ul>
      <li>조정하면 어느 정도 정확도를 높일 수 있음</li>
    </ul>
  </li>
</ul>

<p><code class="language-plaintext highlighter-rouge">GaussianNB</code> 는 고차원 데이터셋에 사용하고 <code class="language-plaintext highlighter-rouge">MultinomialNB</code> 또는 <code class="language-plaintext highlighter-rouge">BernoulliNB</code>는 희소한 데이터 카운트에 이용한다. <code class="language-plaintext highlighter-rouge">MultinomialNB</code>가  <code class="language-plaintext highlighter-rouge">BernoulliNB</code>보다 성능은 더 좋다.</p>

<ul>
  <li>선형 모델과 장단점이 비슷</li>
  <li>훈련과 예측 속도가 빠르며 훈련 과정을 이해하기가 쉽다.</li>
  <li>희소한 고차원 데이터에서 잘 작동하며 비교적 매개변수에 민감하지 않음</li>
  <li>선형 모델로는 학습 시간이 오래 걸리는 매우 큰 데이터셋이 시도해볼만한 알고리즘</li>
</ul>

<h3 id="235-결정-트리"><span class="me-2">2.3.5 결정 트리</span><a href="#235-결정-트리" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p><code class="language-plaintext highlighter-rouge">결정 트리(decision tree)</code> : 분류와 회귀 문제에 사용되며 결정에 다다르기 위해 예/아니오 질문을 이어 나가면서 학습하는 모델</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">mglearn</span><span class="p">.</span><span class="n">plots</span><span class="p">.</span><span class="nf">plot_animal_tree</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_105_0.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_105_0.png" loading="lazy"></a></p>

<ul>
  <li>노드(node): 질문이나 정답을 담은 네모 상자</li>
  <li>리프(leaf): 마지막 노드</li>
  <li>에지(edge): 질문의 답과 다음 질문을 연결</li>
</ul>

<p><strong>결정 트리 만들기</strong></p>

<p>결정 트리를 학습한다는 것은 정답에 가장 빨리 도달하는 예/아니오 질문 목록(=테스트)을 학습한다는 뜻이다.<br /></p>

<ul>
  <li>데이터 형태 : 2차원 데이터셋과 같은 연속된 특성으로 구성</li>
  <li>테스트 형태 : 특성 i는 값 a보다 큰가?</li>
</ul>

<p>알고리즘은 가능한 모든 테스트에서 타깃 값에 대해 가장 많은 정보를 가진 것을 고른다.</p>

<p>데이터셋이 x[1] = 0.06에서 수평으로 나누는 것이 가장 많은 정보를 포함하며 클래스 0에 속한 포인트와 클래스 1에 속한 포인트를 가장 잘 나누고 있음.</p>

<p><a href="https://user-images.githubusercontent.com/53929665/99183175-5081a100-277d-11eb-8d35-674bab6589f3.PNG" class="popup img-link shimmer"><img src="https://user-images.githubusercontent.com/53929665/99183175-5081a100-277d-11eb-8d35-674bab6589f3.PNG" loading="lazy"></a></p>

<p><code class="language-plaintext highlighter-rouge">루트 노드(root node)</code> : 맨 위 노드로 클래스 0에 속한 포인트 50개와 클래스 1에 속한 포인트 50개를 모두 포함한 전체 데이터 셋을 나타냄.</p>

<ol>
  <li>직선이 의미하는 (x[1] &lt;= 0.06) 분기가 일어남.</li>
  <li>왼쪽 노드 (x[1] &lt;= 0.06 인 경우) 에는 클래스 0에 속한 포인트 2개, 클래스 1에 속하는 포인트 32개가 할당</li>
  <li>오른쪽 노드 (x[1] &gt; 0.06 인 경우) 에는 클래스 0에 속한 포인트 48개, 클래스 1에 속하는 포인트 18개가 할당</li>
</ol>

<p>하지만, 완벽하게 분류하지 못함(왼쪽 노드 클래스 0에 속하는 포인트 2개, 오른쪽 노드 클래스 1에 속하는 포인트 18개)</p>

<p><a href="https://user-images.githubusercontent.com/53929665/99183177-511a3780-277d-11eb-8503-083ffd211d71.PNG" class="popup img-link shimmer"><img src="https://user-images.githubusercontent.com/53929665/99183177-511a3780-277d-11eb-8503-083ffd211d71.PNG" loading="lazy"></a></p>

<p>x[0] 값을 기준으로 왼쪽과 오른쪽 영역으로 나누고 있다.</p>

<p>데이터를 분할하는 것 : 각 분할된 영역이 (결정 트리의 리프) 한 개의 타깃 값(하나의 클래스나 하나의 회귀 분석 결과)를 가질 때까지 반복</p>

<p><code class="language-plaintext highlighter-rouge">순수 노드(pure node)</code> : 타깃 하나로만 이뤄진 리프 노드</p>

<p><a href="https://user-images.githubusercontent.com/53929665/99183179-51b2ce00-277d-11eb-9ca0-585063802e89.PNG" class="popup img-link shimmer"><img src="https://user-images.githubusercontent.com/53929665/99183179-51b2ce00-277d-11eb-9ca0-585063802e89.PNG" loading="lazy"></a></p>

<p><strong>새로운 데이터 포인트에 대한 예측</strong><br /></p>

<ul>
  <li>주어진 데이터 포인트가 특성을 분할한 영역들 중 어디에 놓이는지를 확인 → 그 영역의 타깃 값 중 다수 (순수 노드라면 하나)인 것을 예측 결과로 함.</li>
  <li>루트 노드에서 시작해 테스트의 결과에 따라 왼쪽 또는 오른쪽으로 트리를 탐색해나가는 식으로 영역을 찾음.</li>
  <li>회귀 문제에도 트리를 이용할 수 있음.</li>
  <li>각 노드의 테스트 결과에 따라 트리를 탐색하고 새로운 데이터 포인트에 해당되는 리프 노드를 찾는다. 그 후, 찾은 리프 노드의 훈련 데이터 평균값이 이 데이터 포인트의 출력이 됨.</li>
</ul>

<p><strong>결정 트리의 복잡도 제어하기</strong></p>

<p>모든 리프 노드가 순수 노드가 될 때까지 진행하면 모델이 매우 복잡해지고 훈련 데이터에 과대적합됨.</p>
<ul>
  <li>클래스 0으로 결정된 영역이 클래스 1로 결정된 영역에 둘러쌓인 경우 &amp; 클래스 1로 결정된 영역이 클래스 0으로 결정된 영역에 둘러쌓인 경우
    <ul>
      <li>결정 경계가 클래스의 포인트들에서 멀리 떨어진 이상치(outlier)하나에 너무 민감.</li>
    </ul>
  </li>
</ul>

<p><strong>과대적합을 막는 전략</strong></p>

<ol>
  <li>사전 가지치기(pre-pruning) : 트리 생성을 일찍 중단하는 전략
    <ul>
      <li>트리의 최대 깊이나 리프의 최대 개수를 제한</li>
      <li>노드가 분할하기 위한 포인트의 최소 개수를 지정</li>
    </ul>
  </li>
  <li>사후 가지치기(post-pruning) or 가지치기(pruning) : 트리를 만든 후 데이터 포인트가 적은 노드를 삭제하거나 병합하는 전략</li>
</ol>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="c1"># 가지치기를 하지 않은 트리
</span><span class="n">cancer</span> <span class="o">=</span> <span class="nf">load_breast_cancer</span><span class="p">()</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="p">.</span><span class="n">target</span><span class="p">,</span> <span class="n">stratify</span> <span class="o">=</span> <span class="n">cancer</span><span class="p">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
<span class="n">tree</span> <span class="o">=</span> <span class="nc">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">tree</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Training set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">tree</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Test set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">tree</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>

<span class="sh">"""</span><span class="s">
Training set accuracy : 1.000
Test set accuracy : 0.937
</span><span class="sh">"""</span>
</pre></td></tr></tbody></table></code></div></div>

<ul>
  <li>리프노드 → 순수노드 → 훈련세트의 정확도 : 100%</li>
  <li>결정트리의 깊이 제한(가지치기하지 않음)하지 않으면 복잡도가 높아지고 과대적합되기 쉬워 새로운 데이터에 일반화된 모델을 구축하지 못한다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="c1"># 가지치기를 한 트리
</span><span class="n">tree</span> <span class="o">=</span> <span class="nc">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">tree</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Training set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">tree</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Test set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span> <span class="nf">format</span><span class="p">(</span><span class="n">tree</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>

<span class="sh">"""</span><span class="s">
Training set accuracy : 0.988
Test set accuracy : 0.951
</span><span class="sh">"""</span>
</pre></td></tr></tbody></table></code></div></div>

<p>결정트리의 깊이 제한(가지치기를 함)를 하면 복잡도 떨어지며 과대적합이 줄어든다.</p>

<ul>
  <li>훈련세트의 정확도는 낮아짐(가지치기를 하지않는 트리와 비교)</li>
  <li>테스트세트의 정확도는 높아짐
    <ul>
      <li>새로운 데이터에 일반화가 되었다고 할 수 있음</li>
    </ul>
  </li>
</ul>

<p><strong>결정트리 분석</strong></p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_graphviz</span>
<span class="nf">export_graphviz</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">out_file</span> <span class="o">=</span> <span class="sh">"</span><span class="s">tree.dot</span><span class="sh">"</span><span class="p">,</span> <span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">악성</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">양성</span><span class="sh">"</span><span class="p">],</span> <span class="n">feature_names</span> <span class="o">=</span> <span class="n">cancer</span><span class="p">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">impurity</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">filled</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

<span class="kn">import</span> <span class="n">graphviz</span>
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">tree.dot</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="n">dot_graph</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="nf">read</span><span class="p">()</span>
<span class="nf">display</span><span class="p">(</span><span class="n">graphviz</span><span class="p">.</span><span class="nc">Source</span><span class="p">(</span><span class="n">dot_graph</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_116_0.svg" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_116_0.svg" loading="lazy"></a></p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="c1"># scikit-learn 0.21 version .dot 파일을 만들지 않고 트리를 시각화
</span><span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">plot_tree</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="nf">plot_tree</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">malignant</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">benign</span><span class="sh">"</span><span class="p">],</span> <span class="n">feature_names</span> <span class="o">=</span> <span class="n">cancer</span><span class="p">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">impurity</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">filled</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">rounded</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_117_0.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_117_0.png" loading="lazy"></a></p>

<p><strong>트리의 특성 중요도</strong></p>

<ul>
  <li>특성 중요도(feature importance): 트리를 만드는 결정에 각 특성이 얼마나 중요한지를 평가
    <ul>
      <li>0 &lt;= 특성 중요도 &lt;= 1</li>
      <li>특성 중요도가 0에 가까울수록 사용정도가 작으며, 1에 가까울수록 사용정도가 크다.</li>
      <li>0은 전혀 사용X, 1은 완벽하게 타깃 클래스를 예측</li>
      <li>특정중요도의 전체 합은 1이다.</li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">특성 중요도:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">tree</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">)</span>

<span class="sh">"""</span><span class="s">
특성 중요도:
[0.         0.         0.         0.         0.         0.
0.         0.         0.         0.         0.01019737 0.04839825
0.         0.         0.0024156  0.         0.         0.
0.         0.         0.72682851 0.0458159  0.         0.
0.0141577  0.         0.018188   0.1221132  0.01188548 0.        ]
</span><span class="sh">"""</span>

<span class="c1"># 특성 중요도를 시각화
</span><span class="k">def</span> <span class="nf">plot_feature_importance_cancer</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
  <span class="n">n_features</span> <span class="o">=</span> <span class="n">cancer</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">barh</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">n_features</span><span class="p">),</span> <span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">align</span> <span class="o">=</span> <span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">yticks</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">n_features</span><span class="p">),</span> <span class="n">cancer</span><span class="p">.</span><span class="n">feature_names</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">feature importance</span><span class="sh">"</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">feature</span><span class="sh">"</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>

<span class="nf">plot_feature_importance_cancer</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_120_0.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_120_0.png" loading="lazy"></a></p>

<ul>
  <li>첫 번째 노드에서 사용한 특성(worst radius)이  가장 중요한 특성으로 나타남</li>
  <li>어떤 특성의 feature_importance_ 값이 낮다고 해서 이 특성이 유용하지 않다는 뜻은 아님.</li>
</ul>

<p><strong>선형 모델의 계수 vs 결정 트리의 특성 중요도</strong></p>

<ul>
  <li>선형모델의 계수는 음수도 존재하지만, 특성 중요도는 항상 양수이며 어떤 클래스를 지지하는지 알 수 없음.
    <ul>
      <li>특성 중요도의 값은 “worst raidus”가 중요하다고 알려주지만 높은 반지름이 양성을 의미하는지 악성을 의미하는지는 알 수 없음.</li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="n">mglearn</span><span class="p">.</span><span class="n">plots</span><span class="p">.</span><span class="nf">plot_tree_not_monotone</span><span class="p">()</span>

<span class="c1"># Feature importances: [0. 1.]
</span></pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_122_1.svg" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_122_1.svg" loading="lazy"></a></p>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_122_2.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_122_2.png" loading="lazy"></a></p>

<p>위의 결정 트리를 통해 특성과 클래스 사이의 관계가 단순하지 않음을 알 수 있다.</p>

<p><code class="language-plaintext highlighter-rouge">회귀 결정 트리</code>는 다음과 같은 특징을 가지고 있다.</p>

<ul>
  <li>회귀 결정 트리의 사용법과 분석은 분류 트리와 매우 유사함.</li>
  <li>회귀를 위한 트리 기반의 모델에는 특별한 속성이 존재</li>
  <li>입력 공간을 훈련 데이터 범위 내에서만 분할하여 예측값을 할당하기 때문에 외삽을 잘 못한다는 단점이 있다.</li>
</ul>

<blockquote>
  <p>외삽(extrapolation) : 훈련 데이터의 범위 밖의 포인트에 대해 예측을 할 수 없음.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">os</span>
<span class="n">ram_prices</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">mglearn</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">DATA_PATH</span><span class="p">,</span> <span class="sh">"</span><span class="s">ram_price.csv</span><span class="sh">"</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">yticks</span><span class="p">(</span><span class="n">fontname</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Arial</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">semilogy</span><span class="p">(</span><span class="n">ram_prices</span><span class="p">.</span><span class="n">date</span><span class="p">,</span> <span class="n">ram_prices</span><span class="p">.</span><span class="n">price</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Year</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Price($/Mbyte</span><span class="sh">"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_125_2.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_125_2.png" loading="lazy"></a></p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="c1"># 2000년 이전을 훈련 데이터로, 2000년 이후를 테스트 데이터로 저장
</span><span class="n">data_train</span> <span class="o">=</span> <span class="n">ram_prices</span><span class="p">[</span><span class="n">ram_prices</span><span class="p">.</span><span class="n">date</span> <span class="o">&lt;</span> <span class="mi">2000</span><span class="p">]</span>
<span class="n">data_test</span> <span class="o">=</span> <span class="n">ram_prices</span><span class="p">[</span><span class="n">ram_prices</span><span class="p">.</span><span class="n">date</span> <span class="o">&gt;=</span> <span class="mi">2000</span><span class="p">]</span>

<span class="c1"># 가격 예측을 위해 날짜 특성만을 이용
</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">data_train</span><span class="p">.</span><span class="n">date</span><span class="p">.</span><span class="nf">to_numpy</span><span class="p">()[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="c1"># 데이터와 타깃 사이의 관계를 간단하게 만들기 위해 로그 스케일로 변환
</span><span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">data_train</span><span class="p">.</span><span class="n">price</span><span class="p">)</span>
<span class="n">tree</span> <span class="o">=</span> <span class="nc">DecisionTreeRegressor</span><span class="p">().</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">linear_reg</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">().</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># 예측은 전체 기간에 대해서 수행
</span><span class="n">X_all</span> <span class="o">=</span> <span class="n">ram_prices</span><span class="p">.</span><span class="n">date</span><span class="p">.</span><span class="nf">to_numpy</span><span class="p">()[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>

<span class="n">pred_tree</span> <span class="o">=</span> <span class="n">tree</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_all</span><span class="p">)</span>
<span class="n">pred_lr</span> <span class="o">=</span> <span class="n">linear_reg</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_all</span><span class="p">)</span>

<span class="c1"># 예측한 값의 로그 스케일을 되돌림
</span><span class="n">price_tree</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">pred_tree</span><span class="p">)</span>
<span class="n">price_lr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">pred_lr</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">semilogy</span><span class="p">(</span><span class="n">data_train</span><span class="p">.</span><span class="n">date</span><span class="p">,</span> <span class="n">data_train</span><span class="p">.</span><span class="n">price</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">"</span><span class="s">train data</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">semilogy</span><span class="p">(</span><span class="n">data_test</span><span class="p">.</span><span class="n">date</span><span class="p">,</span> <span class="n">data_test</span><span class="p">.</span><span class="n">price</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">"</span><span class="s">test data</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">semilogy</span><span class="p">(</span><span class="n">ram_prices</span><span class="p">.</span><span class="n">date</span><span class="p">,</span> <span class="n">price_tree</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">"</span><span class="s">tree prediction</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">semilogy</span><span class="p">(</span><span class="n">ram_prices</span><span class="p">.</span><span class="n">date</span><span class="p">,</span> <span class="n">price_lr</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Linear regression prediction</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_127_0.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_127_0.png" loading="lazy"></a></p>

<ul>
  <li>선형 모델은 직선으로 데이터를 근사하여 테스트 데이터(2000년 이후)를 꽤 정확히 예측</li>
  <li>트리 모델은 훈련 데이터를 완벽하게 예측(트리의 복잡도에 제한 X = 가지치기 X)</li>
  <li>트리 모델은 데이터 범위 밖으로 나가면 단순히 마지막 포인트를 이용해 예측</li>
</ul>

<p>하지만, 트리 모델은 훈련 데이터 밖의 새로운 데이터를 예측할 능력이 없다.</p>

<p><strong>매개변수</strong></p>

<ul>
  <li>모델 복잡도를 조절하는 매개변수는 사전 가지치기 매개변수가 있다.</li>
  <li>max_depth, max_leaf_nodes, min_samples_leaf 중 하나만 지정해도 과대적합을 막는데 충분함.</li>
</ul>

<p><strong>장점</strong></p>

<ul>
  <li>모델을 쉽게 시각화할 수 있으며 데이터의 스케일에 구애를 받지않음</li>
  <li>특성의 정규화난 표준화 같은 전처리 과정이 필요 X</li>
  <li>특성의 스케일이 서로 다르거나 이진 특성과 연속적인 특성이 혼합되어 있을 때도 잘 작동</li>
</ul>

<p><strong>단점</strong></p>

<ul>
  <li>사전 가지치기를 사용해도 과대적합되는 경향이 있어 일반화 성능이 좋지 않음.</li>
</ul>

<p>주로 앙상블 방법을 단일 결정 트리의 대안으로 사용한다.</p>

<h3 id="236-결정-트리의-앙상블"><span class="me-2">2.3.6 결정 트리의 앙상블</span><a href="#236-결정-트리의-앙상블" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p><code class="language-plaintext highlighter-rouge">앙상블(ensemble)</code>이란 여러 머신러닝 모델을 연결하여 더 강력한 모델을 연결하여 더 강력한 모델을 만드는 기법이다. 그 중 두 앙상블 모델이 분류와 회귀 문제의 다양한 데이터셋에서 효과적이라고 입증되었으며 이 두가지 모델을 구성하는 기본 요소로 결정 트리를 사용한다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">랜덤포레스트(random foreset)</code></li>
  <li><code class="language-plaintext highlighter-rouge">그레이티언트 부스팅(gradient boosting)</code></li>
</ul>

<h4 id="랜덤-포레스트"><span class="me-2">랜덤 포레스트</span><a href="#랜덤-포레스트" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<ul>
  <li>랜덤 포레스트는 결정 트리의 주요 단점인 훈련 데이터에 과대적합되는 문제를 회피할 수 있는 방법이다.</li>
  <li>랜덤 포레스트는 조금씩 다는 여러 결정 트리의 묶음</li>
  <li>서로 다른 방향으로 과대적합된 트리를 많이 만들어 그 결과를 평균냄으로써 과대적합된 양을 줄일 수 있다.</li>
</ul>

<p><strong>구현 방법</strong></p>

<p>결정 트리를 무작위성을 주입시켜 많이 만든다. 이 때, 트리를 랜덤하게 만드는 방법은 다음과 같다.</p>
<ul>
  <li>데이터 포인트를 무작위로 선택</li>
  <li>분할 데이터에서 특성을 무작위로 선택</li>
</ul>

<p><strong>랜덤 포레스트 구축</strong></p>

<ul>
  <li>트리의 개수를 정하기(매개변수 : n_estimators)<br /></li>
  <li>부트스트랩 샘플(bootstrap sample)을 생성 = n_samplesrodml 데이터 포인트 중에서 무작위로(중복o) 데이터를 n_samples 횟수만큼 반복 추출(독립적으로 만들기 위해 무작위한 선택이 필요)<br /></li>
  <li>데이터셋으로 결정 트리를 만들기 : 후보 특성을 무작위호 선택한 후 최선의 테스트를 찾는다.
몇 개의 특성을 고를지는 max_features 매개변수로 조정, 후보 특성은 트리를 만들 때마다 새로 뽑음.<br /></li>
  <li>예측을 할 때는 알고리즘이 모델이 있는 모든 트리의 예측을 만듦.<br />
    <ul>
      <li>회귀의 경우, 예측들을 평균하여 최종 예측을 만듦.</li>
      <li>분류의 경우, 약한 투표 전략을 사용</li>
    </ul>
  </li>
</ul>

<p>이를 통해 가능성 있는 출력 레이블의 확률을 제공함으로써 간접적인 예측을 한다.</p>

<p><code class="language-plaintext highlighter-rouge">max_features</code>: 핵심 매개변수로 값이 커지면 랜덤 포레스트의 트리들은 매우 비슷해지고 가장 두드러진 특성을 이용해 데이터에 잘 맞춰지며 값이 작아지면 랜텀 포레스트의 트리들은 많이 달라지고 각 트리는 데이터에 맞추기 위해 깊이가 갚어짐.</p>

<p><strong>랜텀 포레스트 분석</strong></p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nf">make_moons</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>

<span class="n">forest</span> <span class="o">=</span> <span class="nc">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">forest</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># RandomForestClassifier(n_estimators=5, random_state=2)
</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">tree</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">forest</span><span class="p">.</span><span class="n">estimators_</span><span class="p">)):</span>
  <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">Tree{}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
  <span class="n">mglearn</span><span class="p">.</span><span class="n">plots</span><span class="p">.</span><span class="nf">plot_tree_partition</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">tree</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">)</span>

<span class="n">mglearn</span><span class="p">.</span><span class="n">plots</span><span class="p">.</span><span class="nf">plot_2d_separator</span><span class="p">(</span><span class="n">forest</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">fill</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="p">.</span><span class="mi">4</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">Random Forest</span><span class="sh">"</span><span class="p">)</span>
<span class="n">mglearn</span><span class="p">.</span><span class="nf">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_135_0.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_135_0.png" loading="lazy"></a></p>

<ul>
  <li>다섯 개의 트리가 만든 결정 경계가 모두 다름</li>
  <li>한쪽 트리에 나타나는 훈련 포인트가 다른 트리에는 포함되지 않을 수 있어 각 트리가 불완전함.</li>
</ul>

<p>즉, 랜덤 포레스트는 각각의 트리보다 덜 과대적합되고 훨씬 좋은 결정 경계를 만들어준다.</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="c1"># 유방암 데이터셋 &amp; 100개의 트리로 만들어진 랜덤 포레스트
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="p">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">forest</span> <span class="o">=</span> <span class="nc">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">forest</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Traing set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">forest</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Test set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">forest</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>

<span class="sh">"""</span><span class="s">
Traing set accuracy : 1.000
Test set accuracy : 0.972
</span><span class="sh">"""</span>

<span class="c1"># 특성 중요도(각 트리의 특성 중요도를 취합한 결과)
</span><span class="nf">plot_feature_importance_cancer</span><span class="p">(</span><span class="n">forest</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_138_0.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_138_0.png" loading="lazy"></a></p>

<ul>
  <li>단일 트리의 경우보다 훨씬 많은 특성이 0이상의 중요도 값을 갖고 있음.</li>
  <li>랜덤 포레스트가 뽑은 가장 중요한 특성 : worst perimeter (단일 트리 : worst radius)</li>
  <li>단일 트리보다 더 넓은 시각으로 데이터를 바라볼 수 있다.</li>
</ul>

<p>주의할 점은 <code class="language-plaintext highlighter-rouge">random_state</code>에 따라 전혀 다른 모델이 만들어진다. 트리가 많을수록, <code class="language-plaintext highlighter-rouge">random_state</code> 값의 변화에 따른 변동이 적으며 같은 결과를 만들기 위해서는 <code class="language-plaintext highlighter-rouge">random_state</code> 값을 고정해야한다.</p>

<p>장점으로는 매우 큰 데이터셋에도 잘 작동하며 훈련은 여러 CPU코어롤 간단하게 병렬화할 수 있다. 하지만, 매우 차원이 높고 희소한 데이터(ex. 텍스트)에는 잘 작동하지 않는다(선형모델이 더 적합). 또한, 훈련과 예측이 느리다는 단점이 있다(속도와 메모리 사용에 제약 o → 선형 모델이 더 적합).</p>

<p>중요 매개변수로는 <code class="language-plaintext highlighter-rouge">n_estimators</code>, <code class="language-plaintext highlighter-rouge">max_features</code>기 있으며 추가적으로 <code class="language-plaintext highlighter-rouge">max_depth</code> 같은 사전 가지치기 매개변수, <code class="language-plaintext highlighter-rouge">n_jobs</code>(사용할 코어 수을 지정)가 있다.</p>

<ul>
  <li>n_estimators가 클수록 더 많은 트리를 평균하면 과대적합이 줄어 안정적인 모델을 만들 수 있음(단, 메모리와 긴 훈련 시간이 요구됨)</li>
  <li>max_features의 값이 작을수록 과대적합을 줄여줌, 기본적으로 기본값을 씀
    <ul>
      <li>분류 : max_features = sqrt(n_features)</li>
      <li>회귀 : max_features = n_features</li>
    </ul>
  </li>
  <li>max_features나 max_leaf_nodes 매개변수를 추가하면 성능이 향상 &amp; 메모리와 시간 ↓</li>
  <li>n_jobs ↑ → 훈련 속도가 빨라짐(n_jobs = -1로 지정하면 모든 코어를 사용)</li>
</ul>

<h4 id="그레이디언트-부스팅-회귀-트리"><span class="me-2">그레이디언트 부스팅 회귀 트리</span><a href="#그레이디언트-부스팅-회귀-트리" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<ul>
  <li>여러 개의 결정 트리를 묶어 강력한 모델을 만듦</li>
  <li>분류와 회귀에 모두 사용</li>
  <li>이전 트리의 오차를 보완하는 방식으로 순차적</li>
  <li>랜덤 포레스트와 달리 무작위성이 없으며 대신 강력한 사전 가지치기를 사용</li>
  <li>간단한 모델(약한 학습기 = weak learner)을 많이 연결 → 각각의 트리는 데이터의 일부에 대해서만 예측을 잘 수행(트리가 많을수록 예측 성능이 좋아짐.)</li>
  <li>랜덤 포레스트에 비해 매개변수 설정에 민감함(잘 조정하면 더 높은 정확도를 제공)</li>
</ul>

<p><strong>구축 방법</strong></p>

<ul>
  <li>하나에서 다섯 정도의 깊지 않은 트리를 사용 → 메모리를 적게 사용 &amp; 예측도 빠름</li>
</ul>

<p>중요 매개변수로 사전 가지치기와 트리 개수(<code class="language-plaintext highlighter-rouge">n_estimators</code>), <code class="language-plaintext highlighter-rouge">learning_rate</code>가 있다.</p>

<ul>
  <li>n_estimators 클수록 모델의 복잡도가 커지고 훈련 세트에서의 실수를 바로잡을 기회가 많아짐</li>
  <li>learning_rate : 이전 트리의 오차를 얼마나 강하게 보정할 것인지를 제어
    <ul>
      <li>학습률이 커지면 보정이 강해져 복잡한 모델을 만든다.</li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="c1"># 기본값 : 깊이 = 3, 트리 개수 = 100, 학습률 = 0.1
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="p">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">gbrt</span> <span class="o">=</span> <span class="nc">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">gbrt</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Training set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">gbrt</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Test set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">gbrt</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>

<span class="sh">"""</span><span class="s">
Training set accuracy : 1.000
Test set accuracy : 0.965
</span><span class="sh">"""</span>

<span class="c1"># 최대 깊이를 낯추기 : 깊이 = 1
</span><span class="n">gbrt</span> <span class="o">=</span> <span class="nc">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">gbrt</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Training set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">gbrt</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Test set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">gbrt</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>

<span class="sh">"""</span><span class="s">
Training set accuracy : 0.991
Test set accuracy : 0.972
</span><span class="sh">"""</span>

<span class="c1"># 학습률 낮추기 : 학습률 = 0.01
</span><span class="n">gbrt</span> <span class="o">=</span> <span class="nc">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">gbrt</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Training set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">gbrt</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Test set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">gbrt</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>

<span class="sh">"""</span><span class="s">
Training set accuracy : 0.988
Test set accuracy : 0.965
</span><span class="sh">"""</span>

<span class="c1"># 특성 중요도
</span><span class="n">gbrt</span> <span class="o">=</span> <span class="nc">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">gbrt</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nf">plot_feature_importance_cancer</span><span class="p">(</span><span class="n">gbrt</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_145_0.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_145_0.png" loading="lazy"></a></p>

<ul>
  <li>랜덤 포레스트와 달리 일부 특성을 강조</li>
  <li>보통 안정적인 랜덤 포레스트를 사용하지만 예측 시간이 중요하거나 머신러닝 모델에서 마지막 성능까지 쥐어짜야 할 때 그레이디언트 부스팅을 사용하면 도움이 됨</li>
  <li>대규모 머신러닝 문제 : xgboost패키지 또는 파이썬 인터페이스를 권장(그레이디언트 부스팅 구현보다 빨랐음 &amp; 튜닝이 쉬움)</li>
</ul>

<p>장점은 특성의 스케일을 조정할 필요가 없고 이진 특성이나 연속적인 특성에도 잘 작동한다. 하지만, 매개변수를 잘 조정해야 하며 훈련 시간이 길다. 또한, 트리 기반 모델의 특성을 가지고 있어 희소한 고차원 데이터에는 잘 작동하지 않는다는 단점이 있다.</p>

<p>중요 매개변수로는 다음과 같다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">n_estimators</code> : 트리의 개수를 지정하며 값이 클수록 모델이 복잡해져 과대적합될 가능성이 높아진다.</li>
  <li><code class="language-plaintext highlighter-rouge">learning_rate</code> : 이진 트리의 오차를 보정하는 정도를 조절할 수 있으며 값이 낮을수록 더 많은 트리를 추가
    <ul>
      <li>일반적으로 가용된 시간과 메모리 한도에서 n_estimators를 맞추고 나서 적절한 learning_rate를 찾음.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">max_depth</code>(or max_leaf_nodes) : 트리의 복잡도를 낮춤
    <ul>
      <li>max_depth를 매우 작게 설정 : max_depth &lt;= 5</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>scikit-learn 0.20 version</strong><br /></p>
  <ul>
    <li>n_iter_no_change &amp; validation_fraction : 조기 종료를 위한 매개변수</li>
    <li>훈련 데이터에서 validation_fraction(기본값 0.1)비율만큼 검증 데이터로 사용
      <ul>
        <li>n_iter_no_change 반복 동안 검증 점수가 향상되지 않으면 훈련이 종료(n_iter_no_change 기본값 = None → 조기 종료 X)</li>
      </ul>
    </li>
  </ul>
</blockquote>

<h3 id="237-그-외-다른-앙상블"><span class="me-2">2.3.7 그 외 다른 앙상블</span><a href="#237-그-외-다른-앙상블" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<ul>
  <li>배깅(bagging)</li>
  <li>에이다부스트(AdaBoost)</li>
  <li>엑스트라 트리(Extra-Tree)</li>
  <li>히스토그램 기반 그레이디언트 부스팅(Histogram-based Gradient Boosting)</li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span>
<span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>

<span class="n">Xm</span><span class="p">,</span> <span class="n">ym</span> <span class="o">=</span> <span class="nf">make_moons</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">noise</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">Xm_train</span><span class="p">,</span> <span class="n">Xm_test</span><span class="p">,</span> <span class="n">ym_train</span><span class="p">,</span> <span class="n">ym_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">Xm</span><span class="p">,</span> <span class="n">ym</span><span class="p">,</span> <span class="n">stratify</span> <span class="o">=</span> <span class="n">ym</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>

<span class="n">cancer</span> <span class="o">=</span> <span class="nf">load_breast_cancer</span><span class="p">()</span>
<span class="n">Xc_train</span><span class="p">,</span> <span class="n">Xc_test</span><span class="p">,</span> <span class="n">yc_train</span><span class="p">,</span> <span class="n">yc_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="p">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div></div>

<h4 id="배깅"><span class="me-2">배깅</span><a href="#배깅" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p><code class="language-plaintext highlighter-rouge">배깅(Bagging)</code> : Boosting aggregatingdml 줄임말로 중복을 허용한 랜덤 샘플링으로 만든 훈련 세트를 사용하여 분류기를 각기 다르게 학습시킴</p>

<ul>
  <li>부트스트랩 샘플을 만드는 것은 랜덤 포레스트의 특징과 동일</li>
  <li>분류기가 predict_proba() 메서드를 지원하는 경우는 확률값을 평균하여 예측하며 그렇지 않으면 가장 빈도가 높은 클래스 레이블이 예측 결과임.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="c1"># 훈련할 분류기 개수 = 100(기본값 : 10) oob_score = True
</span><span class="n">bagging</span> <span class="o">=</span> <span class="nc">BaggingClassifier</span><span class="p">(</span><span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">solver</span> <span class="o">=</span> <span class="sh">'</span><span class="s">liblinear</span><span class="sh">'</span><span class="p">),</span> <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">oob_score</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
<span class="n">bagging</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">Xc_train</span><span class="p">,</span> <span class="n">yc_train</span><span class="p">)</span>

<span class="sh">"""</span><span class="s">
BaggingClassifier(base_estimator=LogisticRegression(solver=</span><span class="sh">'</span><span class="s">liblinear</span><span class="sh">'</span><span class="s">),
                  n_estimators=100, n_jobs=-1, oob_score=True, random_state=42)
</span><span class="sh">"""</span>
</pre></td></tr></tbody></table></code></div></div>

<blockquote>
  <p><code class="language-plaintext highlighter-rouge">oob_score = True</code><br /></p>
  <ul>
    <li>부트스트래핑에 포함되지 않은 샘플을 기반으로 훈련된 모델을 평가
      <ul>
        <li>이 값을 OOB(out of bag)오차라고 함</li>
      </ul>
    </li>
    <li>oob_score을 통해 테스트 세트의 성능을 짐작할 수 있음.</li>
    <li>RandomForestClassifier도 oob_score 매개변수를 지원(기본값 : False)</li>
  </ul>
</blockquote>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Training set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">bagging</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">Xc_train</span><span class="p">,</span> <span class="n">yc_train</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Test set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">bagging</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">Xc_test</span><span class="p">,</span> <span class="n">yc_test</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">OOB sample accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">bagging</span><span class="p">.</span><span class="n">oob_score_</span><span class="p">))</span>

<span class="sh">"""</span><span class="s">
Training set accuracy : 0.962
Test set accuracy : 0.958
OOB sample accuracy : 0.948
</span><span class="sh">"""</span>
</pre></td></tr></tbody></table></code></div></div>

<p>랜덤 포래스트를 사용하여 배깅을 수행하는 것이 결정 트리로 수행하는 것보다 더 편리함(아래의 코드에서는 결정 트리로 배깅)</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="n">bagging</span> <span class="o">=</span> <span class="nc">BaggingClassifier</span><span class="p">(</span><span class="nc">DecisionTreeClassifier</span><span class="p">(),</span> <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
<span class="n">bagging</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">Xm_train</span><span class="p">,</span> <span class="n">ym_train</span><span class="p">)</span>

<span class="sh">"""</span><span class="s">
BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=5,
                      n_jobs=-1, random_state=42)
</span><span class="sh">"""</span>

<span class="c1"># 시각화
</span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">tree</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">bagging</span><span class="p">.</span><span class="n">estimators_</span><span class="p">)):</span>
  <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">Tree{}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
  <span class="n">mglearn</span><span class="p">.</span><span class="n">plots</span><span class="p">.</span><span class="nf">plot_tree_partition</span><span class="p">(</span><span class="n">Xm</span><span class="p">,</span> <span class="n">ym</span><span class="p">,</span> <span class="n">tree</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">)</span>

<span class="n">mglearn</span><span class="p">.</span><span class="n">plots</span><span class="p">.</span><span class="nf">plot_2d_separator</span><span class="p">(</span><span class="n">bagging</span><span class="p">,</span> <span class="n">Xm</span><span class="p">,</span> <span class="n">fill</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="p">.</span><span class="mi">4</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">Bagging</span><span class="sh">"</span><span class="p">)</span>
<span class="n">mglearn</span><span class="p">.</span><span class="nf">discrete_scatter</span><span class="p">(</span><span class="n">Xm</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xm</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">ym</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_156_0.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_156_0.png" loading="lazy"></a></p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="rouge-code"><pre><span class="c1"># n_estimators = 100
</span><span class="n">bagging</span> <span class="o">=</span> <span class="nc">BaggingClassifier</span><span class="p">(</span><span class="nc">DecisionTreeClassifier</span><span class="p">(),</span> <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">oob_score</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
<span class="n">bagging</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">Xc_train</span><span class="p">,</span> <span class="n">yc_train</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Training set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">bagging</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">Xc_train</span><span class="p">,</span> <span class="n">yc_train</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Test set accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">bagging</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">Xc_test</span><span class="p">,</span> <span class="n">yc_test</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">OOB sample accuracy : {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">bagging</span><span class="p">.</span><span class="n">oob_score_</span><span class="p">))</span>

<span class="sh">"""</span><span class="s">
Training set accuracy : 1.000
Test set accuracy : 0.965
OOB sample accuracy : 0.948
</span><span class="sh">"""</span>
</pre></td></tr></tbody></table></code></div></div>

<p>매개변수는 다음과 같다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">max_samples</code>: 부트스트랩 샘플의 크기를 지정(기본값 : 1.0, 훈련 샘플 개수만큼 추출)하며 샘플 개수를 지정하거나 훈련 샘플 개수의 비율을 지정</li>
  <li><code class="language-plaintext highlighter-rouge">booststrap</code>: 기본값은 True로 False로 지정하면 중복을 허용하지 않는 샘플링을 수행</li>
  <li><code class="language-plaintext highlighter-rouge">max_features</code>: 각 분류기 훈련에 사용할 특성 개수를 지정할 수 있으며 랜덤 포레스트와 달리 가본값은 1.0으로 전체 특성을 사용한다. 또한, 사용할 특성 개수를 지정하거나 특성의 비율를 지정</li>
  <li><code class="language-plaintext highlighter-rouge">boost_features</code>: 기본값은 False로 True로 지정하면 중복을 허용하여 특성을 선택</li>
</ul>

<h4 id="엑스트라-트리"><span class="me-2">엑스트라 트리</span><a href="#엑스트라-트리" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p><code class="language-plaintext highlighter-rouge">엑스트라 트리(Extra-Tree)</code>: 랜덤 포레스트와 비슷하지만 후보 특성을 무작위로 분할한 다음 최적의 분할을 찾음.</p>

<div class="table-wrapper"><table>
  <thead>
    <tr>
      <th>특징</th>
      <th>엑스트라 트리</th>
      <th>랜덤 포레스트</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><cneter>splitter<center></center></cneter></td>
      <td><center>random으로 지정<center></center></center></td>
      <td>best로 지정</td>
    </tr>
    <tr>
      <td>bootstrap</td>
      <td>기본적으로 사용X(사용가능)</td>
      <td><center>사용함<center></center></center></td>
    </tr>
  </tbody>
</table></div>

<ul>
  <li>무작위성커지면 편향(bias)커지고 분산(variance)은 작아진다.</li>
  <li>예측 방식은 각 트리가 만든 확률값을 평균이다.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="n">xtree</span> <span class="o">=</span> <span class="nc">ExtraTreesClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">xtree</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">Xm_train</span><span class="p">,</span> <span class="n">ym_train</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">tree</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">xtree</span><span class="p">.</span><span class="n">estimators_</span><span class="p">)):</span>
  <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">Tree{}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
  <span class="n">mglearn</span><span class="p">.</span><span class="n">plots</span><span class="p">.</span><span class="nf">plot_tree_partition</span><span class="p">(</span><span class="n">Xm</span><span class="p">,</span> <span class="n">ym</span><span class="p">,</span> <span class="n">tree</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">)</span>

<span class="n">mglearn</span><span class="p">.</span><span class="n">plots</span><span class="p">.</span><span class="nf">plot_2d_separator</span><span class="p">(</span><span class="n">xtree</span><span class="p">,</span> <span class="n">Xm</span><span class="p">,</span> <span class="n">fill</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="p">.</span><span class="mi">4</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">Extra Tree</span><span class="sh">"</span><span class="p">)</span>
<span class="n">mglearn</span><span class="p">.</span><span class="nf">discrete_scatter</span><span class="p">(</span><span class="n">Xm</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Xm</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">ym</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_160_0.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_160_0.png" loading="lazy"></a></p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="c1"># 트리 개수 = 100
</span><span class="n">xtree</span> <span class="o">=</span> <span class="nc">ExtraTreesClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">xtree</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">Xc_train</span><span class="p">,</span> <span class="n">yc_train</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Training set accuracy: {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">xtree</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">Xc_train</span><span class="p">,</span> <span class="n">yc_train</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Test set accuracy: {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">xtree</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">Xc_test</span><span class="p">,</span> <span class="n">yc_test</span><span class="p">)))</span>

<span class="sh">"""</span><span class="s">
Training set accuracy: 1.000
Test set accuracy: 0.972
</span><span class="sh">"""</span>
</pre></td></tr></tbody></table></code></div></div>

<p>엑스트라 트리가 랜덤 포레스트보다 계산 비용이 비교적 적지만 무작위 분할 때문에 일반화 성능을 높이려면 종종 많은 트리를 만들어야하는 단점이 있어 랜덤 포레스트를 더 선호한다.</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="c1"># 특성 중요도 시각화
</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="n">cancer</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">barh</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">),</span> <span class="n">xtree</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">align</span> <span class="o">=</span> <span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">yticks</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">n_features</span><span class="p">),</span> <span class="n">cancer</span><span class="p">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Feature importance</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Feature</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_163_0.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_163_0.png" loading="lazy"></a></p>

<h4 id="에이다부스트"><span class="me-2">에이다부스트</span><a href="#에이다부스트" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<p><code class="language-plaintext highlighter-rouge">에이다부스트(AdaBoost)</code> : Adaptive Boosting의 줄임말로 그레이디언트 부스팅처럼 약한 학습기를 사용한다.</p>

<ul>
  <li>이전의 모델이 잘못 분류한 샘플에 가중치를 높여서 다음 모델을 훈련</li>
  <li>모델의 가중치를 합산하여 가장 높은 값을 가진 레이블을 선택</li>
  <li>그레이디언트 부스팅과 동일하게 순차적으로 학습</li>
  <li>기본값으로 max_depth = 3를 사용</li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
<span class="c1"># max_depth = 1
</span><span class="n">ada</span> <span class="o">=</span> <span class="nc">AdaBoostClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
<span class="n">ada</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">Xm_train</span><span class="p">,</span> <span class="n">ym_train</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">tree</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(),</span> <span class="n">ada</span><span class="p">.</span><span class="n">estimators_</span><span class="p">)):</span>
  <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">Tree{}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
  <span class="n">mglearn</span><span class="p">.</span><span class="n">plots</span><span class="p">.</span><span class="nf">plot_tree_partition</span><span class="p">(</span><span class="n">Xm</span><span class="p">,</span> <span class="n">ym</span><span class="p">,</span> <span class="n">tree</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">)</span>

<span class="n">mglearn</span><span class="p">.</span><span class="n">plots</span><span class="p">.</span><span class="nf">plot_2d_separator</span><span class="p">(</span><span class="n">ada</span><span class="p">,</span> <span class="n">Xm</span><span class="p">,</span> <span class="n">fill</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span> <span class="o">=</span> <span class="p">.</span><span class="mi">4</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">"</span><span class="s">AdaBoost</span><span class="sh">"</span><span class="p">)</span>
<span class="n">mglearn</span><span class="p">.</span><span class="nf">discrete_scatter</span><span class="p">(</span><span class="n">Xm</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Xm</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">ym</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_165_0.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_165_0.png" loading="lazy"></a></p>

<p>깊이가 1인 결정 트리를 사용하여 각 트리의 결정 경계가 직선 하나가 생긴다.</p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="rouge-code"><pre><span class="n">ada</span> <span class="o">=</span> <span class="nc">AdaBoostClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
<span class="n">ada</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">Xc_train</span><span class="p">,</span> <span class="n">yc_train</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Training set accuracy: {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">ada</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">Xc_train</span><span class="p">,</span> <span class="n">yc_train</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Test set accuracy: {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">ada</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">Xc_test</span><span class="p">,</span> <span class="n">yc_test</span><span class="p">)))</span>

<span class="sh">"""</span><span class="s">
Training set accuracy: 1.000
Test set accuracy: 0.986
</span><span class="sh">"""</span>

<span class="c1"># 특성 중요도 시각화
</span><span class="n">plt</span><span class="p">.</span><span class="nf">barh</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">),</span> <span class="n">ada</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">align</span> <span class="o">=</span> <span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">yticks</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">n_features</span><span class="p">),</span> <span class="n">cancer</span><span class="p">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Feature importance</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Feature</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_168_0.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_168_0.png" loading="lazy"></a></p>

<ul>
  <li>다른 모델에서 부각되지 않았던 ‘area error’의 특성을 크게 강조하고 있음.</li>
</ul>

<h4 id="히스토그램-기반-부스팅"><span class="me-2">히스토그램 기반 부스팅</span><a href="#히스토그램-기반-부스팅" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<ul>
  <li>입력 특성을 256개의 구간으로 나눔 → 노드를 분할할 때 최적의 분할을 빠르게 찾을 수 있음</li>
  <li>256개의 구간 중 하나가 누락된 값을 위해 사용 → 누락된 값을 위한 전처리 필요 X</li>
  <li>샘플 개수가 1만 개 이상인 경우 그레이디언트 부스팅보다 훨씬 빠름</li>
  <li>기본 매개변수에서도 좋은 성능을 제공</li>
  <li>부스팅 횟수를 지정하는 max_iter 매개변수(기본값 100)값↑ → 성능↑</li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">HistGradientBoostingClassifier</span>
<span class="n">hgb</span> <span class="o">=</span> <span class="nc">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
<span class="n">hgb</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">Xm_train</span><span class="p">,</span> <span class="n">ym_train</span><span class="p">)</span>

<span class="n">mglearn</span><span class="p">.</span><span class="n">plots</span><span class="p">.</span><span class="nf">plot_2d_separator</span><span class="p">(</span><span class="n">hgb</span><span class="p">,</span> <span class="n">Xm</span><span class="p">,</span> <span class="n">fill</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="p">.</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">HistGradientBoosting</span><span class="sh">"</span><span class="p">)</span>
<span class="n">mglearn</span><span class="p">.</span><span class="nf">discrete_scatter</span><span class="p">(</span><span class="n">Xm</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Xm</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">ym</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_171_0.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_171_0.png" loading="lazy"></a></p>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="n">hgb</span> <span class="o">=</span> <span class="nc">HistGradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
<span class="n">hgb</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">Xc_train</span><span class="p">,</span> <span class="n">yc_train</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Training set accracy: {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">hgb</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">Xc_train</span><span class="p">,</span> <span class="n">yc_train</span><span class="p">)))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Test set accracy: {:.3f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">hgb</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">Xc_test</span><span class="p">,</span> <span class="n">yc_test</span><span class="p">)))</span>

<span class="sh">"""</span><span class="s">
Training set accracy: 1.000
Test set accracy: 0.979
</span><span class="sh">"""</span>
</pre></td></tr></tbody></table></code></div></div>

<p>히스토그램 기반 부스팅은 특성 중요도를 제공하지 않지만 permutation_importance 함수를 사용하여 특성 중요도를 계산할 수 있다.</p>

<blockquote>
  <p>permutation_importance 함수 : 특성 값을 차례대로 섞은 후 모델의 성능을 평가하여 어떤 특성이 중요한 역할을 하는지를 계산, 다른 모델에도 사용 가능</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">sklearn.inspection</span> <span class="kn">import</span> <span class="n">permutation_importance</span>

<span class="n">result</span> <span class="o">=</span> <span class="nf">permutation_importance</span><span class="p">(</span><span class="n">hgb</span><span class="p">,</span> <span class="n">Xc_train</span><span class="p">,</span> <span class="n">yc_train</span><span class="p">,</span> <span class="n">n_repeats</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">barh</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">),</span> <span class="n">result</span><span class="p">.</span><span class="n">importances_mean</span><span class="p">,</span> <span class="n">align</span> <span class="o">=</span> <span class="sh">'</span><span class="s">center</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">yticks</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">n_features</span><span class="p">),</span> <span class="n">cancer</span><span class="p">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Feature Importance</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Features</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></div></div>

<p><a href="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_174_0.png" class="popup img-link shimmer"><img src="/../assets/img/post/ml_post/Chapter2_Supervised_Learning_files/Chapter2_Supervised_Learning_174_0.png" loading="lazy"></a></p>

<ul>
  <li>그레이디언트 부스팅과 비슷하게 일부 특성에 크게 의존</li>
  <li>‘worst perimeter’가 가장 중요한 특성으로 나타남</li>
</ul>

<h4 id="트리-기반-앙상블-모델의-매개변수-기본값-비교"><span class="me-2">트리 기반 앙상블 모델의 매개변수 기본값 비교</span><a href="#트리-기반-앙상블-모델의-매개변수-기본값-비교" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<div class="table-wrapper"><table>
  <thead>
    <tr>
      <th> </th>
      <th><center>랜덤 포레스트<center></center></center></th>
      <th><center>그레이디언트 부스팅<center></center></center></th>
      <th><center>엑스트라 트리<center></center></center></th>
      <th><center>히스토그램 기반 부스팅<center></center></center></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><center>트리 개수<center></center></center></td>
      <td><center>n_estimators = 100<center></center></center></td>
      <td><center>n_estimators = 100<center></center></center></td>
      <td><center>n_estimators = 100<center></center></center></td>
      <td><center>max_iter = 100<center></center></center></td>
    </tr>
    <tr>
      <td><center>학습률<center></center></center></td>
      <td><center>없음<center></center></center></td>
      <td><center>learning_rate = 0.1<center></center></center></td>
      <td><center>없음<center></center></center></td>
      <td><center>learning_rate = 0.1<center></center></center></td>
    </tr>
    <tr>
      <td><center>노드 분할 기준<center></center></center></td>
      <td><center>분류: criterion = 'gini'<br />회귀: criterion = 'squared_error'<center></center></center></td>
      <td><center>criterion = 'friedman_mse'<center></center></center></td>
      <td><center>분류: criterion = 'gini'<br />회귀: criterion = 'squared_error'<center></center></center></td>
      <td><center>없음<center></center></center></td>
    </tr>
    <tr>
      <td><center>손실 함수<center></center></center></td>
      <td><center>없음<center></center></center></td>
      <td><center>분류: loss = 'deviance'(로지스틱 회귀)<br />회귀: loss = 'squared_error'<center></center></center></td>
      <td><center>없음<center></center></center></td>
      <td><center>분류: loss = 'auto'(이진 분류는 'binary_crossentropy',<br /> 다중 분류는 'categorical_crossentropy')<br />회귀: loss = 'squared_error'<center></center></center></td>
    </tr>
    <tr>
      <td><center>샘플 부트스 트래핑<center></center></center></td>
      <td><center>bootstrap = True<center></center></center></td>
      <td><center>없음<center></center></center></td>
      <td><center>bootstrap = False<center></center></center></td>
      <td><center>없음<center></center></center></td>
    </tr>
    <tr>
      <td><center>샘플 개수<center></center></center></td>
      <td><center>max_samples = None(샘플 전체)<center></center></center></td>
      <td><center>subsample = 1.0<center></center></center></td>
      <td><center>max_samples = None(샘플 전체)<center></center></center></td>
      <td><center>없음<center></center></center></td>
    </tr>
    <tr>
      <td><center>특성 개수<center></center></center></td>
      <td><center>max_features = 'auto'<br />(분류는 특성 개수의 제곱근, 회귀는 전체 특성)</center></td>
      <td>max_features = None(특성 전체)<center></center></td>
      <td><center>max_features = 'auto'<br />(분류는 특성 개수의 제곱근, 회귀는 전체 특성)<center></center></center></td>
      <td><center>없음<center></center></center></td>
    </tr>
    <tr>
      <td><center>OOB 점수<center></center></center></td>
      <td><center>oob_score = False<center></center></center></td>
      <td><center>subsample = 1.0<br />(subsample &lt; 1일 때 OOB 점수 계산)<center></center></center></td>
      <td><center>oob_score = False<center></center></center></td>
      <td><center>없음<center></center></center></td>
    </tr>
    <tr>
      <td><center>가지치기<center></center></center></td>
      <td><center>max_depth = None<br />min_samples_split = 2<br />min_samples_leaf = 1<br />max_leaf_nodes = None<br />min_impurity_decrease =0.0<br />ccp_alpha = 0.0<center></center></center></td>
      <td><center>max_depth = 3<br />min_samples_split = 2<br />min_samples_leaf = 1<br />max_leaf_nodes = None<br />min_impurity_decrease =0.0<br />ccp_alpha = 0.0<center></center></center></td>
      <td><center>max_depth = None<br />min_samples_split = 2<br />min_samples_leaf = 1<br />max_leaf_nodes = None<br />min_impurity_decrease =0.0<br />ccp_alpha = 0.0<center></center></center></td>
      <td><center>max_depth = None<br />min_samples_leaf = 20<br />max_leaf_nodes = 31<center></center></center></td>
    </tr>
    <tr>
      <td><center>조기 종료<center></center></center></td>
      <td><center>없음<center></center></center></td>
      <td><center>n_iter_no_change = None<br />validation_fraction = 0.1<br />tol = 1e-4<center></center></center></td>
      <td><center>없음<center></center></center></td>
      <td><center>early_stopping = 'auto'<br />(샘플 개수가 10,000 이상이면 True)<br />n_iter_no_change = 10<br />validation_fraction = 0.1<br />tol = 1e-7<center></center></center></td>
    </tr>
    <tr>
      <td><center>병렬화<center></center></center></td>
      <td><center>n_jobs = None(1을 의미)<center></center></center></td>
      <td><center>없음<center></center></center></td>
      <td><center>n_jobs = None(1을 의미)<center></center></center></td>
      <td><center>없음<center></center></center></td>
    </tr>
  </tbody>
</table></div>

  </div>

  <div class="post-tail-wrapper text-muted">
    <!-- categories -->
    
      <div class="post-meta mb-3">
        <i class="far fa-folder-open fa-fw me-1"></i>
        
          <a href="/categories/machine-learning/">Machine Learning</a>,
          <a href="/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/">파이썬 라이브러리를 활용한 머신러닝</a>
      </div>
    

    <!-- tags -->
    
      <div class="post-tags">
        <i class="fa fa-tags fa-fw me-1"></i>
        
          <a
            href="/tags/ml/"
            class="post-tag no-text-decoration"
          >ml</a>
        
          <a
            href="/tags/python/"
            class="post-tag no-text-decoration"
          >python</a>
        
          <a
            href="/tags/scikit-learn/"
            class="post-tag no-text-decoration"
          >scikit-learn</a>
        
          <a
            href="/tags/supervised-learning/"
            class="post-tag no-text-decoration"
          >supervised-learning</a>
        
      </div>
    

    <div
      class="
        post-tail-bottom
        d-flex justify-content-between align-items-center mt-5 pb-2
      "
    >
      <div class="license-wrapper">
        
          

          This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.
        
      </div>

      <!-- Post sharing snippet -->

<div class="share-wrapper d-flex align-items-center">
  <span class="share-label text-muted">Share</span>
  <span class="share-icons">
    
    
    

    

      

      <a href="https://twitter.com/intent/tweet?text=%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5(3)%20-%20Seojin%20Devlog&url=http%3A%2F%2Flocalhost%3A4000%2Fmachine-learning%2Fsl-3%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter">
        <i class="fa-fw fa-brands fa-square-x-twitter"></i>
      </a>
    

      

      <a href="https://www.facebook.com/sharer/sharer.php?title=%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5(3)%20-%20Seojin%20Devlog&u=http%3A%2F%2Flocalhost%3A4000%2Fmachine-learning%2Fsl-3%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook">
        <i class="fa-fw fab fa-facebook-square"></i>
      </a>
    

      

      <a href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fmachine-learning%2Fsl-3%2F&text=%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5(3)%20-%20Seojin%20Devlog" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram">
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    

    <button
      id="copy-link"
      aria-label="Copy link"
      class="btn small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="Copy link"
      data-title-succeed="Link copied successfully!"
    >
      <i class="fa-fw fas fa-link pe-none fs-6"></i>
    </button>
  </span>
</div>

    </div>
    <!-- .post-tail-bottom -->
  </div>
  <!-- div.post-tail-wrapper -->
</article>


            
          </main>

          <!-- panel -->
          <aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 text-muted">
            <div class="access">
              <!-- Get 5 last posted/updated posts -->














  <section id="access-lastmod">
    <h2 class="panel-heading">Recently Updated</h2>
    <ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/boostcamp/pre-course/python-4/">Module과 Project</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/boostcamp/pre-course/python-3/">Python Object-Oriented Programming(OOP)</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/paper-review/nlp/textcnn/">[논문 리뷰] Convolutional Neural Networks for Sentence Classification</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/boostcamp/pre-course/cnn-basic/">CNN의 원리</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/boostcamp/pre-course/rnn-basic/">RNN의 원리</a>
        </li>
      
    </ul>
  </section>
  <!-- #access-lastmod -->


              <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/ml/">ml</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/scikit-learn/">scikit-learn</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/naver-boostcamp/">Naver-Boostcamp</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/pre-course/">Pre-Course</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/nlp/">NLP</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/pytorch/">pytorch</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/algorithm/">algorithm</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/supervised-learning/">supervised-learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/data-structure/">data-structure</a>
      
    </div>
  </section>


            </div>

            
              
              






  <div class="toc-border-cover z-3"></div>
  <section id="toc-wrapper" class="invisible position-sticky ps-0 pe-4 pb-4">
    <h2 class="panel-heading ps-3 pb-2 mb-0">Contents</h2>
    <nav id="toc"></nav>
  </section>


            
          </aside>
        </div>

        <div class="row">
          <!-- tail -->
          <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              
              <!-- Recommend the other 3 posts according to the tags and categories of the current post. -->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->















  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
    
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  











  <aside id="related-posts" aria-labelledby="related-label">
    <h3 class="mb-4" id="related-label">Further Reading</h3>
    <nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        <article class="col">
          <a href="/machine-learning/sl-2/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1662994800"
  data-df="ll"
  
>
  Sep 13, 2022
</time>

              <h4 class="pt-0 my-2">지도학습(2)</h4>
              <div class="text-muted">
                <p>파이썬 라이브러리를 활용한 머신러닝 책 내용 정리 포스트</p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/machine-learning/sl-1/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1662994800"
  data-df="ll"
  
>
  Sep 13, 2022
</time>

              <h4 class="pt-0 my-2">지도학습(1)</h4>
              <div class="text-muted">
                <p>파이썬 라이브러리를 활용한 머신러닝 책 내용 정리 포스트</p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/machine-learning/sl-5/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1663858800"
  data-df="ll"
  
>
  Sep 23, 2022
</time>

              <h4 class="pt-0 my-2">지도학습(5)</h4>
              <div class="text-muted">
                <p>파이썬 라이브러리를 활용한 머신러닝 책 내용 정리 포스트</p>
              </div>
            </div>
          </a>
        </article>
      
    </nav>
  </aside>
  <!-- #related-posts -->


            
              
              <!-- Navigation buttons at the bottom of the post. -->

<nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation">
  
  

  
    <a
      href="/machine-learning/sl-2/"
      class="btn btn-outline-primary"
      aria-label="Older"
    >
      <p>지도학습(2)</p>
    </a>
  

  
    <a
      href="/machine-learning/sl-4/"
      class="btn btn-outline-primary"
      aria-label="Newer"
    >
      <p>지도학습(4)</p>
    </a>
  
</nav>

            

            <!-- The Footer -->

<footer
  aria-label="Site Info"
  class="
    d-flex flex-column justify-content-center text-muted
    flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3
  "
>
  <p>©
    <time>2025</time>

    
      <a href="https://twitter.com/username">Seojin Park</a>.
    

    
      <span
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."
      >Some rights reserved.</span>
    
  </p>

  <p>Using the <a
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="v7.3.0"
        href="https://github.com/cotes2020/jekyll-theme-chirpy"
        target="_blank"
        rel="noopener"
      >Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.
  </p>
</footer>

          </div>
        </div>

        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center d-none">
  <div class="col-11 content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/python/">python</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/ml/">ml</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/scikit-learn/">scikit-learn</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/naver-boostcamp/">Naver-Boostcamp</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/pre-course/">Pre-Course</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/nlp/">NLP</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/pytorch/">pytorch</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/algorithm/">algorithm</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/supervised-learning/">supervised-learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/data-structure/">data-structure</a>
      
    </div>
  </section>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>

      <aside aria-label="Scroll to Top">
        <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow">
          <i class="fas fa-angle-up"></i>
        </button>
      </aside>
    </div>

    <div id="mask" class="d-none position-fixed w-100 h-100 z-1"></div>

    
      <aside
  id="notification"
  class="toast"
  role="alert"
  aria-live="assertive"
  aria-atomic="true"
  data-bs-animation="true"
  data-bs-autohide="false"
>
  <div class="toast-header">
    <button
      type="button"
      class="btn-close ms-auto"
      data-bs-dismiss="toast"
      aria-label="Close"
    ></button>
  </div>
  <div class="toast-body text-center pt-0">
    <p class="px-2 mb-3">A new version of content is available.</p>
    <button type="button" class="btn btn-primary" aria-label="Update">
      Update
    </button>
  </div>
</aside>

    

    <!-- Embedded scripts -->

    
      
      <!-- The comments switcher -->

  
  <!-- https://utteranc.es/ -->
<script>
  (function () {
    const origin = 'https://utteranc.es';
    const themeMapper = Theme.getThemeMapper('github-light', 'github-dark');
    const initTheme = themeMapper[Theme.visualState];

    let script = document.createElement('script');
    script.src = 'https://utteranc.es/client.js';
    script.setAttribute('repo', 'Parkseojin2001/Parkseojin2001.github.io');
    script.setAttribute('issue-term', 'pathname');
    script.setAttribute('theme', initTheme);
    script.crossOrigin = 'anonymous';
    script.async = true;

    const $footer = document.querySelector('footer');
    $footer.insertAdjacentElement('beforebegin', script);

    addEventListener('message', (event) => {
      let newTheme;if (event.source === window && event.data && event.data.id === Theme.ID) {
        newTheme = themeMapper[Theme.visualState];

        const message = {
          type: 'set-theme',
          theme: newTheme
        };

        const utterances = document.querySelector('.utterances-frame').contentWindow;
        utterances.postMessage(message, origin);
      }
    });
  })();
</script>



    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  
  document.addEventListener('DOMContentLoaded', () => {
    SimpleJekyllSearch({
      searchInput: document.getElementById('search-input'),
      resultsContainer: document.getElementById('search-results'),
      json: '/assets/js/data/search.json',
      searchResultTemplate: '  <article class="px-1 px-sm-2 px-lg-4 px-xl-0">    <header>      <h2><a href="{url}">{title}</a></h2>      <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">        {categories}        {tags}      </div>    </header>    <p>{content}</p>  </article>',
      noResultsText: '<p class="mt-5">Oops! No results found.</p>',
      templateMiddleware: function(prop, value, template) {
        if (prop === 'categories') {
          if (value === '') {
            return `${value}`;
          } else {
            return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
          }
        }

        if (prop === 'tags') {
          if (value === '') {
            return `${value}`;
          } else {
            return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
          }
        }
      }
    });
  });
</script>

  </body>
</html>

