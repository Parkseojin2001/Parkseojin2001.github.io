

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>http://localhost:4000/</id>
  <title>Seojin Devlog</title>
  <subtitle>"A blog about AI, ML, coding, and personal projects."</subtitle>
  <updated>2025-09-26T00:36:15+09:00</updated>
  <author>
    <name>Seojin Park</name>
    <uri>http://localhost:4000/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="http://localhost:4000/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="en"
    href="http://localhost:4000/"/>
  <generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator>
  <rights> © 2025 Seojin Park </rights>
  <icon>/assets/img/favicons/favicon.ico</icon>
  <logo>/assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>Segmentation &amp; Detection</title>
    <link href="http://localhost:4000/naver-boostcamp/computer-vision/03" rel="alternate" type="text/html" title="Segmentation &amp;amp; Detection" />
    <published>2025-09-24T00:00:00+09:00</published>
  
    <updated>2025-09-24T00:00:00+09:00</updated>
  
    <id>http://localhost:4000/naver-boostcamp/computer-vision/03</id>
    <content type="text/html" src="http://localhost:4000/naver-boostcamp/computer-vision/03" />
    <author>
      <name>Seojin Park</name>
    </author>

  
    
    <category term="Deep Learning" />
    
    <category term="CV" />
    
  

  <summary>CNN 모델의 내부 동작을 가시화하는 방법과 데이터 증강 기법에 대해 정리한 포스트입니다.</summary>

  </entry>

  
  <entry>
    <title>CNN 시각화와 데이터 증강</title>
    <link href="http://localhost:4000/naver-boostcamp/computer-vision/02" rel="alternate" type="text/html" title="CNN 시각화와 데이터 증강" />
    <published>2025-09-23T00:00:00+09:00</published>
  
    <updated>2025-09-23T00:00:00+09:00</updated>
  
    <id>http://localhost:4000/naver-boostcamp/computer-vision/02</id>
    <content type="text/html" src="http://localhost:4000/naver-boostcamp/computer-vision/02" />
    <author>
      <name>Seojin Park</name>
    </author>

  
    
    <category term="Deep Learning" />
    
    <category term="CV" />
    
  

  <summary>CNN 모델의 내부 동작을 가시화하는 방법과 데이터 증강 기법에 대해 정리한 포스트입니다.</summary>

  </entry>

  
  <entry>
    <title>CNN to ViT</title>
    <link href="http://localhost:4000/naver-boostcamp/computer-vision/01" rel="alternate" type="text/html" title="CNN to ViT" />
    <published>2025-09-22T00:00:00+09:00</published>
  
    <updated>2025-09-25T00:00:00+09:00</updated>
  
    <id>http://localhost:4000/naver-boostcamp/computer-vision/01</id>
    <content type="text/html" src="http://localhost:4000/naver-boostcamp/computer-vision/01" />
    <author>
      <name>Seojin Park</name>
    </author>

  
    
    <category term="Deep Learning" />
    
    <category term="CV" />
    
  

  <summary>CNN 모델과 ViT 모델의 등장과 구조에 대한 내용에서 더 나아가 ViT를 이용한 self-supervised 학습 방법을 정리한 포스트입니다.</summary>

  </entry>

  
  <entry>
    <title>Transformer2: Attention</title>
    <link href="http://localhost:4000/naver-boostcamp/ml-life-cycle/09" rel="alternate" type="text/html" title="Transformer2: Attention" />
    <published>2025-09-21T00:00:00+09:00</published>
  
    <updated>2025-09-21T00:00:00+09:00</updated>
  
    <id>http://localhost:4000/naver-boostcamp/ml-life-cycle/09</id>
    <content type="text/html" src="http://localhost:4000/naver-boostcamp/ml-life-cycle/09" />
    <author>
      <name>Seojin Park</name>
    </author>

  
    
    <category term="Deep Learning" />
    
    <category term="NLP" />
    
  

  <summary>Attention의 개념 및 방법론 그리고 Transformer의 개념과 학습 과정에 대해 정리한 포스트입니다.</summary>

  </entry>

  
  <entry>
    <title>Transformer1: RNN-based Seq2seq model</title>
    <link href="http://localhost:4000/naver-boostcamp/ml-life-cycle/08" rel="alternate" type="text/html" title="Transformer1: RNN-based Seq2seq model" />
    <published>2025-09-16T00:00:00+09:00</published>
  
    <updated>2025-09-16T00:00:00+09:00</updated>
  
    <id>http://localhost:4000/naver-boostcamp/ml-life-cycle/08</id>
    <content type="text/html" src="http://localhost:4000/naver-boostcamp/ml-life-cycle/08" />
    <author>
      <name>Seojin Park</name>
    </author>

  
    
    <category term="Deep Learning" />
    
    <category term="NLP" />
    
  

  <summary>RNN 모델의 장단점과 해결방법 그리고 LSTM 그리고 seq2seq 모델이 무엇인지, seq2seq 모델의 작동원리를 정리한 포스트입니다.</summary>

  </entry>

</feed>


