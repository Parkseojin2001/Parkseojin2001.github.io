

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>http://localhost:4000/</id>
  <title>Seojin Devlog</title>
  <subtitle>"A blog about AI, ML, coding, and personal projects."</subtitle>
  <updated>2025-09-22T20:25:36+09:00</updated>
  <author>
    <name>Seojin Park</name>
    <uri>http://localhost:4000/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="http://localhost:4000/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="en"
    href="http://localhost:4000/"/>
  <generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator>
  <rights> © 2025 Seojin Park </rights>
  <icon>/assets/img/favicons/favicon.ico</icon>
  <logo>/assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>CNN to ViT</title>
    <link href="http://localhost:4000/naver-boostcamp/computer-vision/01" rel="alternate" type="text/html" title="CNN to ViT" />
    <published>2025-09-22T00:00:00+09:00</published>
  
    <updated>2025-09-22T00:00:00+09:00</updated>
  
    <id>http://localhost:4000/naver-boostcamp/computer-vision/01</id>
    <content type="text/html" src="http://localhost:4000/naver-boostcamp/computer-vision/01" />
    <author>
      <name>Seojin Park</name>
    </author>

  
    
    <category term="Deep Learning" />
    
    <category term="CV" />
    
  

  <summary>CNN 모델과 ViT 모델의 등장과 구조에 대한 내용에서 더 나아가 ViT를 이용한 self-supervised 학습 방법을 정리한 포스트입니다.</summary>

  </entry>

  
  <entry>
    <title>Transformer2: Attention</title>
    <link href="http://localhost:4000/naver-boostcamp/ml-life-cycle/09" rel="alternate" type="text/html" title="Transformer2: Attention" />
    <published>2025-09-21T00:00:00+09:00</published>
  
    <updated>2025-09-21T00:00:00+09:00</updated>
  
    <id>http://localhost:4000/naver-boostcamp/ml-life-cycle/09</id>
    <content type="text/html" src="http://localhost:4000/naver-boostcamp/ml-life-cycle/09" />
    <author>
      <name>Seojin Park</name>
    </author>

  
    
    <category term="Deep Learning" />
    
    <category term="NLP" />
    
  

  <summary>Attention의 개념 및 방법론 그리고 Transformer의 개념과 학습 과정에 대해 정리한 포스트입니다.</summary>

  </entry>

  
  <entry>
    <title>Transformer1: RNN-based Seq2seq model</title>
    <link href="http://localhost:4000/naver-boostcamp/ml-life-cycle/08" rel="alternate" type="text/html" title="Transformer1: RNN-based Seq2seq model" />
    <published>2025-09-16T00:00:00+09:00</published>
  
    <updated>2025-09-16T00:00:00+09:00</updated>
  
    <id>http://localhost:4000/naver-boostcamp/ml-life-cycle/08</id>
    <content type="text/html" src="http://localhost:4000/naver-boostcamp/ml-life-cycle/08" />
    <author>
      <name>Seojin Park</name>
    </author>

  
    
    <category term="Deep Learning" />
    
    <category term="NLP" />
    
  

  <summary>RNN 모델의 장단점과 해결방법 그리고 LSTM 그리고 seq2seq 모델이 무엇인지, seq2seq 모델의 작동원리를 정리한 포스트입니다.</summary>

  </entry>

  
  <entry>
    <title>기초 신경망 이론 4: Trainig Neural Networks</title>
    <link href="http://localhost:4000/naver-boostcamp/ml-life-cycle/07" rel="alternate" type="text/html" title="기초 신경망 이론 4: Trainig Neural Networks" />
    <published>2025-09-16T00:00:00+09:00</published>
  
    <updated>2025-09-16T00:00:00+09:00</updated>
  
    <id>http://localhost:4000/naver-boostcamp/ml-life-cycle/07</id>
    <content type="text/html" src="http://localhost:4000/naver-boostcamp/ml-life-cycle/07" />
    <author>
      <name>Seojin Park</name>
    </author>

  
    
    <category term="Deep Learning" />
    
    <category term="PyTorch" />
    
  

  <summary>Data를 처리하는 방법, Data Augmentation의 구체적인 방법론을 정리한 포스트입니다.</summary>

  </entry>

  
  <entry>
    <title>기초 신경망 이론 3: Trainig Neural Networks</title>
    <link href="http://localhost:4000/naver-boostcamp/ml-life-cycle/06" rel="alternate" type="text/html" title="기초 신경망 이론 3: Trainig Neural Networks" />
    <published>2025-09-16T00:00:00+09:00</published>
  
    <updated>2025-09-16T00:00:00+09:00</updated>
  
    <id>http://localhost:4000/naver-boostcamp/ml-life-cycle/06</id>
    <content type="text/html" src="http://localhost:4000/naver-boostcamp/ml-life-cycle/06" />
    <author>
      <name>Seojin Park</name>
    </author>

  
    
    <category term="Deep Learning" />
    
    <category term="PyTorch" />
    
  

  <summary>Activation Function의 종류와 문제점, Weight Initialization과 Xaiver 무엇인지 그리고 적절한 Learning Rate를 설정하는 방법을 정리한 포스트입니다.</summary>

  </entry>

</feed>


