

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>http://localhost:4000/</id>
  <title>Seojin Devlog</title>
  <subtitle>"A blog about AI, ML, coding, and personal projects."</subtitle>
  <updated>2026-01-09T18:41:32+09:00</updated>
  <author>
    <name>Seojin Park</name>
    <uri>http://localhost:4000/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="http://localhost:4000/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="en"
    href="http://localhost:4000/"/>
  <generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator>
  <rights> © 2026 Seojin Park </rights>
  <icon>/assets/img/favicons/favicon.ico</icon>
  <logo>/assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>Batch Serving과 Airflow</title>
    <link href="http://localhost:4000/naver-boostcamp/model-serving/02" rel="alternate" type="text/html" title="Batch Serving과 Airflow" />
    <published>2026-01-09T00:00:00+09:00</published>
  
    <updated>2026-01-09T00:00:00+09:00</updated>
  
    <id>http://localhost:4000/naver-boostcamp/model-serving/02</id>
    <content type="text/html" src="http://localhost:4000/naver-boostcamp/model-serving/02" />
    <author>
      <name>Seojin Park</name>
    </author>

  
    
    <category term="Naver-Boostcamp" />
    
    <category term="Model Serving" />
    
  

  <summary>Batch Serving 개념과 이를 구현하기 위한 핵심 워크플로우 관리 도구 Apache Airflow에 대한 내용을 정리한 포스트입니다.</summary>

  </entry>

  
  <entry>
    <title>Serving의 종류와 다양한 패턴</title>
    <link href="http://localhost:4000/naver-boostcamp/model-serving/01" rel="alternate" type="text/html" title="Serving의 종류와 다양한 패턴" />
    <published>2026-01-08T00:00:00+09:00</published>
  
    <updated>2026-01-08T00:00:00+09:00</updated>
  
    <id>http://localhost:4000/naver-boostcamp/model-serving/01</id>
    <content type="text/html" src="http://localhost:4000/naver-boostcamp/model-serving/01" />
    <author>
      <name>Seojin Park</name>
    </author>

  
    
    <category term="Naver-Boostcamp" />
    
    <category term="Model Serving" />
    
  

  <summary>머신러닝 모델을 실제 환경에 적용하는 다양한 Serving 방식에 대한 내용을 정리한 포스트입니다.</summary>

  </entry>

  
  <entry>
    <title>LangChain을 활용한 RAG 구성</title>
    <link href="http://localhost:4000/ai-agent/inflearn/langchain-03" rel="alternate" type="text/html" title="LangChain을 활용한 RAG 구성" />
    <published>2026-01-04T00:00:00+09:00</published>
  
    <updated>2026-01-04T00:00:00+09:00</updated>
  
    <id>http://localhost:4000/ai-agent/inflearn/langchain-03</id>
    <content type="text/html" src="http://localhost:4000/ai-agent/inflearn/langchain-03" />
    <author>
      <name>Seojin Park</name>
    </author>

  
    
    <category term="AI Agent" />
    
    <category term="LangChain" />
    
  

  <summary>LangChain을 활용한 Retrieval Augmented Generation(RAG) 구성하는 과정과 코드를 정리한 포스트입니다.</summary>

  </entry>

  
  <entry>
    <title>Self-supervised Pre-training Model: BERT</title>
    <link href="http://localhost:4000/naver-boostcamp/nlp/09" rel="alternate" type="text/html" title="Self-supervised Pre-training Model: BERT" />
    <published>2026-01-03T00:00:00+09:00</published>
  
    <updated>2026-01-03T00:00:00+09:00</updated>
  
    <id>http://localhost:4000/naver-boostcamp/nlp/09</id>
    <content type="text/html" src="http://localhost:4000/naver-boostcamp/nlp/09" />
    <author>
      <name>Seojin Park</name>
    </author>

  
    
    <category term="Naver-Boostcamp" />
    
    <category term="NLP 이론" />
    
  

  <summary>Transformer 기반의 자연어 처리 성능을 혁신한 모델 BERT에 대한 내용을 정리한 포스트입니다.</summary>

  </entry>

  
  <entry>
    <title>Transformer 2</title>
    <link href="http://localhost:4000/naver-boostcamp/nlp/08" rel="alternate" type="text/html" title="Transformer 2" />
    <published>2025-11-27T00:00:00+09:00</published>
  
    <updated>2025-12-25T00:00:00+09:00</updated>
  
    <id>http://localhost:4000/naver-boostcamp/nlp/08</id>
    <content type="text/html" src="http://localhost:4000/naver-boostcamp/nlp/08" />
    <author>
      <name>Seojin Park</name>
    </author>

  
    
    <category term="Naver-Boostcamp" />
    
    <category term="NLP 이론" />
    
  

  <summary>Transformer의 주요 구성요소와 Masked Self-Attention에 관한 내용을 정리한 포스트입니다.</summary>

  </entry>

</feed>


