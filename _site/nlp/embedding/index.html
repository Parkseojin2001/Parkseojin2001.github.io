<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.22.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="ko" class="no-js">
  <head>
    <style> 
      ::-webkit-scrollbar{ 
        width: 10px;
        height: 10px;
      }

      ::-webkit-scrollbar-track {
        width: 0px;
        background-color: rgba(224, 224, 224, 0.2);
        /* border-radius: 5px; */
      }

      ::-webkit-scrollbar-thumb {
        width: 0px;
        background-color: rgba(220, 219, 218, 0.6);
        border-radius: 5px;
      }

      ::-webkit-scrollbar-thumb:hover {
        width: 10px;
        height: 20px;
        /* background-color: rgba(190, 190, 190, 0.2); */
        background-color: rgba(193, 192, 191, 0.7);
        border-radius: 5px;
      }

      ::-webkit-scrollbar-track:hover {
        width: 10px;
        /* background-color: rgba(150, 150, 150, 0.1); */
        background-color: rgba(224, 224, 224, 0.5);
        border-radius: 5px;
        /* background: transparent; */
        /* border-radius: 10px; */
      }

      ::-webkit-scrollbar-button:start:decrement,::-webkit-scrollbar-button:end:increment {
          width:0px;
          height: 0px;
          /* background-color: rgb(14, 221, 24); */
          /* border-radius: 50%; */
      }
    </style>
    
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>임베딩 | Seojin</title>
<meta name="description" content="언어 모델 / N-gram / TF-IDF">


  <meta name="author" content="Seojin">
  
  <meta property="article:author" content="Seojin">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="ko_KR">
<meta property="og:site_name" content="Seojin Devlog">
<meta property="og:title" content="임베딩">
<meta property="og:url" content="http://localhost:4000/nlp/embedding/">


  <meta property="og:description" content="언어 모델 / N-gram / TF-IDF">







  <meta property="article:published_time" content="2025-04-01T00:00:00+09:00">



  <meta property="article:modified_time" content="2025-04-01T00:00:00+09:00">



  

  


<link rel="canonical" href="http://localhost:4000/nlp/embedding/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Seojin",
      "url": "http://localhost:4000/"
    
  }
</script>






<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Seojin Devlog Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      processEscapes: true
    }
  });
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->


    <link rel="apple-touch-icon" sizes="180x180" href="https://Parkseojin2001.github.io/assets/images/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://Parkseojin2001.github.io/assets/images/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://Parkseojin2001.github.io/assets/images/favicon/favicon-16x16.png">
    <link rel="manifest" href="https://Parkseojin2001.github.io/assets/images/favicon/site.webmanifest">
    <link rel="mask-icon" href="https://Parkseojin2001.github.io/assets/images/favicon/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#ffc40d">
    <meta name="theme-color" content="#ffffff">
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Seojin Devlog
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="https://Parkseojin2001.github.io/">Home</a>
            </li><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="https://github.com/Parkseojin2001">GitHub</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="/assets/images/meee.png" alt="Seojin" itemprop="image">
      
    </div>
  

  <!-- 2022.02.17 author content hidden -->
  <!-- <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Seojin</h3>
    
    
  </div> -->

  <div class="author__urls-wrapper">
    <!-- <button class="btn btn--inverse">Follow</button> -->
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle menu</label>
  <ul class="nav__items">
    <!-- <li>
      <span class="nav__total">🌴 Total Posts: 21</span>
    </li> -->
    
    
      <li>
        
          <!-- title -->
              <span class="nav__sub-title">COMPUTER SCIENCE</span>
              <hr>
        

        
        <ul>
          
            <!-- sub-title -->
            
              
            
              
                <li><a href="/categories/data-structure/">Data Structure (4)</a></li>
              
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
          
            <!-- sub-title -->
            
              
            
              
            
              
            
              
            
              
                <li><a href="/categories/algorithm/">Algorithm (1)</a></li>
              
            
              
            
              
            
              
            
              
            
          
            <!-- sub-title -->
            
              
                <li><a href="/categories/os/">Operating System (1)</a></li>
              
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
          
        </ul>
        
      </li>
    
      <li>
        
          <!-- title -->
              <span class="nav__sub-title">AI</span>
              <hr>
        

        
        <ul>
          
            <!-- sub-title -->
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
              
                <li><a href="/categories/pytorch/">Pytorch (2)</a></li>
              
            
          
            <!-- sub-title -->
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
          
            <!-- sub-title -->
            
              
            
              
            
              
                <li><a href="/categories/hands-on/">핸즈온 머신러닝 (7)</a></li>
              
            
              
            
              
            
              
            
              
            
              
            
              
            
          
            <!-- sub-title -->
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
              
                <li><a href="/categories/nlp/">NLP (2)</a></li>
              
            
              
            
          
            <!-- sub-title -->
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
          
        </ul>
        
      </li>
    
      <li>
        
          <!-- title -->
              <span class="nav__sub-title">PROGRAMMING</span>
              <hr>
        

        
        <ul>
          
            <!-- sub-title -->
            
              
            
              
            
              
            
              
                <li><a href="/categories/python/">Python (2)</a></li>
              
            
              
            
              
            
              
            
              
            
              
            
          
        </ul>
        
      </li>
    
      <li>
        
          <!-- title -->
              <span class="nav__sub-title">PROJECT</span>
              <hr>
        

        
        <ul>
          
            <!-- sub-title -->
            
              
            
              
            
              
            
              
            
              
            
              
            
              
                <li><a href="/categories/capstone-design/">Capstone Design (1)</a></li>
              
            
              
            
              
            
          
        </ul>
        
      </li>
    
      <li>
        
          <!-- title -->
              <span class="nav__sub-title">GIT</span>
              <hr>
        

        
        <ul>
          
            <!-- sub-title -->
            
              
            
              
            
              
            
              
            
              
            
              
                <li><a href="/categories/git/">Git (1)</a></li>
              
            
              
            
              
            
              
            
          
            <!-- sub-title -->
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
              
            
          
        </ul>
        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="임베딩">
    <meta itemprop="description" content="언어 모델 / N-gram / TF-IDF">
    <meta itemprop="datePublished" content="2025-04-01T00:00:00+09:00">
    <meta itemprop="dateModified" content="2025-04-01T00:00:00+09:00">

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">임베딩
</h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        <time datetime="2025-04-01T00:00:00+09:00">April 1, 2025</time>
      </span>
    

    

    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#-언어-모델">🦥 언어 모델</a><ul><li><a href="#자기회귀-언어-모델">자기회귀 언어 모델</a></li><li><a href="#통계적-언어-모델">통계적 언어 모델</a></li></ul></li><li><a href="#-n-gram">🦥 N-gram</a></li><li><a href="#-tf-idf">🦥 TF-IDF</a><ul><li><a href="#단어-빈도">단어 빈도</a></li><li><a href="#문서-빈도">문서 빈도</a></li><li><a href="#역문서-빈도">역문서 빈도</a></li><li><a href="#tf-idf">TF-IDF</a></li></ul></li></ul>

            </nav>
          </aside>
        
        <p>컴퓨터는 텍스트 자체를 이해할 수 없으므로 텍스트를 숫자로 변환하는 <strong>텍스트 벡터화(Text Vectorization)</strong> 과정이 필요하다.</p>

<p>텍스트 벡터화란 텍스트를 숫자로 변환하는 과정을 의미한다. 기초적인 텍스트 벡터화로는 <strong>원-핫 인코딩(One-Hot Encoding)</strong>, <strong>빈도 벡터화(Count Vectorization)</strong> 등이 있다.</p>
<ul>
  <li>원-핫 인코딩: 문서에 등장하는 각 단어를 고유한 색인 값으로 매핑한 후, 해당 색인 위치를 1로 표시하고 나머지 위치를 모두 0으로 표시하는 방식이다.
    <ul>
      <li>‘I like apples’ 문장과 ‘I like bananas’ 문장을 원-핫 인코딩으로 표현
        <ul>
          <li>I like apples: [1, 1, 1, 0]</li>
          <li>I like bananas: [1, 1, 0, 1]</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>빈도 벡터화: 문서에서 단어의 빈도수를 세어 해당 단어의 빈도를 벡터로 표현하는 방식이다.
    <ul>
      <li>apples라는 단어가 총 4번 등장 → apples의 백터값 = 4</li>
    </ul>
  </li>
</ul>

<p>이러한 방법은 단어나 문장을 벡터 형태로 변환하기 쉽고 간단하다는 장점이 있지만, 벡터의 <strong>희소성(Sparsity)</strong>이 크다는 단점이 있다. 또한, 텍스트의 벡터가 입력 텍스트의 의미를 내포하고 있지 않아 두 문장이 의미론적으로 유사해도 벡터가 유사하게 나타나지 않을 수 있다.</p>

<p>이를 해결하는 방법으로 단어의 의미를 학습해 표현하는 <strong>워드 임베딩(Word Embedding)</strong> 기법을 사용한다.</p>
<ul>
  <li>Word2Vec</li>
  <li>fastText</li>
</ul>

<p>워드 임베딩은 고정된 임베딩을 학습하기 때문에 다의어나 문맥 정보를 다루기 어렵다는 단점이 있어 인공 신경망을 활용해 <strong>동적 임베딩(Dynamic Embedding)</strong> 기법을 사용한다.</p>

<h2 id="-언어-모델">🦥 언어 모델</h2>

<p><strong>언어 모델(Language Model)</strong>이란 입력된 문장으로 각 문장을 생성할 수 있는 확률을 계산하는 모델을 의미한다. 이를 위해 주어진 문장을 바탕으로 문맥을 이해하고, 문장 구성에 대한 예측을 수행한다.</p>

<p>언어모델은 다양한 자연어 처리 분야에서 활용된다.</p>
<ul>
  <li>자동 번역</li>
  <li>음성 인식</li>
  <li>텍스트 요약</li>
</ul>

<p>주어진 문장 뒤에 나올 수 있는 문장은 매우 다양하기 때문에 완성된 문장 단위로 확룔을 계산하는 것은 매우 어렵다. 이 문제를 해결하기 위해 하나의 토큰 단위로 예측하는 방법인 자기회귀 언어 모델이 고안됐다.</p>

<h3 id="자기회귀-언어-모델">자기회귀 언어 모델</h3>

<p><strong>자기회귀 언어 모델(Autoregressive Language Model)</strong>은 입력된 문장들의 조건부 확률을 이용해 다음에 올 단어를 예측한다. 즉, 언어 모델에서 조건부 확률은 이전 단어들의 시퀀스가 주어졌을 때, 다음 단어의 확률을 계산하는 것을 의미한다.</p>

<p>이전에 등장한 모든 토큰의 정보와 문장의 문맥 정보를 파악하여 다음 단어를 생성한다. 다음 단어는 다시 이전 단어를 기반으로 예측이 이루어지며, 이 과정이 반복된다.</p>

\[P(w_t|w_1, w_2, ...,w_{t-1}) = \frac{P(w_1, w_2, w_3, ..., w_t)}{P(w_1, w_2, ..., w_{t-1})}\]

<p>언어 모델에서 조건부 확률을 계산하기 위해 이전에 등장한 시퀀스($w_1, w_2, … , w_{t-1}$)를 기반으로 다음 단어($w_t$)의 확률을 계산한다. 위의 수식에 <strong>조건부 확률의 연쇄법칙(Chain rule for conditional probability)</strong>을 적용한다면 아래의 수식과 같다.</p>

\[P(w_t|w_1, w_2, ..., w_{t-1}) = P(w_1)P(w_2|w_1)...P(w_t|w_1, w_2, ...,w_{t-1})\]

<p>언어 모델에서 조건부 확률은 연쇄법칙을 이용해 계산된다. 이전 단어들의 시퀀스가 주어졌을 때, 다음에 등장하는 단어의 확률을 이전 단어들의 조건부 확률을 이용해 계산한다.</p>

<p>모델의 출력값이 다음 모델의 입력값으로 사용되는 특징 때문에 자기회귀라는 이름이 붙였다. 자기회귀 언어 모델은 시점별로 다음에 올 토큰을 예측하는 것이므로 토큰 분류 문제로 정의할 수 있다.</p>

<h3 id="통계적-언어-모델">통계적 언어 모델</h3>

<p><strong>통계적 언어 모델(Statistical Language Model)</strong>은 언어의 통계적 구조를 이용해 문장이나 단어의 시퀀스를 생성하거나 분석한다. 시퀀스에 대한 확률 분포를 추정해 문장의 문맥을 파악해 다음에 등장할 단어의 확률을 예측한다.</p>

<p>일반적으로 통계적 언어 모델은 <strong>마르코프 체인(Markov Chain)</strong>을 이용해 구현된다.</p>
<ul>
  <li>마르코프 체인: 빈도 기반의 조건부 확률 모델 중 하나로 이전 상태와 현재 상태 간의 전이 확률을 이용해 다음 상태 예측</li>
</ul>

\[P(A|B) = \frac{P(A \cap B)}{P(B)}\]

<p>이 방법은 단어의 순서와 빈도에만 기초해 문장의 확률을 예측하기 때문에 생기는 문제점이 있다.</p>
<ul>
  <li>문맥을 제대로 파악하지 못하면 불완전하거나 부적절한 결과를 생성</li>
  <li>한 번도 등장한 적이 없는 단어나 문장에 대해서는 정확한 확률을 예측하기가 어려움 → <strong>데이터 희소성(Data sparsity)</strong></li>
</ul>

<p>하지만 통계적 언어 모델은 기존에 학습한 텍스트 데이터에서 패턴을 찾아 확률 분포를 생성하므로, 이를 이용하여 새로운 문장을 생성할 수 있으며, 다양한 종류의 텍스트 데이터를 학습할 수 있다. 이 언어 모델은 대규모 자연어 데이터를 처리하는 데 효과적이며, 딥러닝 등의 인공지능 기술이 발전하면서 더욱 강력한 모델을 구현할 수 있게 됐다.</p>

<p>최근 자연어 처리 기법은 언어 모델을 활용해 가중치를 사전 학습한다.</p>
<ul>
  <li>GPT</li>
  <li>BERT</li>
</ul>

<h2 id="-n-gram">🦥 N-gram</h2>

<p>가장 기초적인 통계적 언어 모델은 <strong>N-gram</strong>모델이다. N-gram 모델은 텍스트에서 N개의 연속된 단어 시퀀스를 하나의 단위로 취급하여 특정 단어 시퀀스가 등장할 확률을 추정한다.</p>
<ul>
  <li>입력 텍스트를 N개의 토큰으로 묶어서 분석하고 연속된 N개의 단어를 하나의 단위로 취급하여 추론하는 모델</li>
  <li>N = 1인 경우: <strong>유니그램(Unigram)</strong></li>
  <li>N = 2인 경우: <strong>바이그램(Bigram)</strong></li>
  <li>N = 3인 경우: <strong>트라이그램(Trigram)</strong></li>
  <li>N &gt; 3인 경우: N-gram</li>
</ul>

<p><img src="https://blog.kakaocdn.net/dn/W7Ssn/btsEOT2GNsb/tb33uY0aQiMQLYkHvlD0PK/img.png" /></p>

<p>N-gram 언어 모델은 모든 토큰을 사용하지 않고 $N-1$개의 토큰만을 고려해 확률을 계산한다.</p>

\[P(w_t|w_{t-1}, w_{t-2}, ... , w_{t-N+1})\]

<ul>
  <li>$w_t$: 예측하려는 단어</li>
  <li>$w_{t-1}, … w_{t-N+1}$: 예측에 사용되는 이전 단어</li>
</ul>

<p>이전 단어들의 개수를 결정하는 $N$의 값을 조정하여 N-gram 모델의 성능을 조정할 수 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># N-gram 구현
</span><span class="kn">import</span> <span class="nn">nltk</span>

<span class="k">def</span> <span class="nf">ngrams</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">ngrams</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">words</span><span class="p">[</span><span class="n">i</span><span class="p">:]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">ngrams</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="s">"안녕하세요 만나서 진심으로 반가워요"</span>
<span class="n">unigram</span> <span class="o">=</span> <span class="n">ngrams</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">bigram</span> <span class="o">=</span> <span class="n">ngrams</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">trigram</span> <span class="o">=</span> <span class="n">ngrams</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># nltk 라이브러리를 이용한 N-gram
</span><span class="n">unigram</span> <span class="o">=</span> <span class="n">nltk</span><span class="p">.</span><span class="n">ngrams</span><span class="p">(</span><span class="n">sentence</span><span class="p">.</span><span class="n">split</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">bigram</span> <span class="o">=</span> <span class="n">nltk</span><span class="p">.</span><span class="n">ngrams</span><span class="p">(</span><span class="n">sentence</span><span class="p">.</span><span class="n">split</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">trigram</span> <span class="o">=</span> <span class="n">nltk</span><span class="p">.</span><span class="n">ngrams</span><span class="p">(</span><span class="n">sentence</span><span class="p">.</span><span class="n">split</span><span class="p">(),</span> <span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<p>N-gram은 작은 규모의 데이터세트에서 연속된 문자열 패턴을 분석하는 데 큰 효과를 보인다. 또한 관용적 표현 분석에도 활용되며 단어의 순서가 중요한 자연어 처리 작업 및 문자열 패턴 분석에 활용된다.</p>

<h2 id="-tf-idf">🦥 TF-IDF</h2>

<p><strong>TF-IDF(Term Frequency-Inverse Document Frequency)</strong>란 텍스트 문서에서 특정 단어의 중요도를 계산하는 방법으로, 문서 내에서 단어의 중요도를 평가하는 데 사용되는 통계적 가중치를 의미한다. 즉, TF-IDF는 <strong>BoW(Bag-of Words)</strong>에 가중치를 부여하는 방법이다.</p>

<ul>
  <li>BoW: 문서나 문장을 단어의 집합으로 표현하는 방법으로, 문서나 문장에 등장하는 단어의 중복을 허용해 빈도를 기록한다.
    <ul>
      <li>BoW를 이용한 벡터화는 모든 단어에 동일한 가중치를 부여한다.</li>
    </ul>
  </li>
</ul>

<p><img src="https://www.askpython.com/wp-content/uploads/2020/12/Bag-of-Words-model-1024x335.jpg.webp" /></p>

<h3 id="단어-빈도">단어 빈도</h3>

<p><strong>단어 빈도(Term Frequency, TF)</strong>란 문서 내에서 특정 단어의 빈도수를 나타내는 값이다.</p>

<p>문서 내에서 단어가 등장한 빈도수를 계산하며, 해당 단어의 상대적인 중요도를 측정하는데 사용된다.</p>
<ul>
  <li>‘movie’라는 단어가 3개의 문서에서 4번 등장: TF = 4</li>
</ul>

\[TF(t, d) = count(t, d)\]

<p>TF 값이 높으면 두 가지 경우로 해석될 수 있다.</p>
<ul>
  <li>해당 단어가 특정 문서에서 중요한 역할을 함</li>
  <li>단어 자체가 특정 문서 내에서 자주 사용되는 단어이므로 전문 용어나 관용어로 간주</li>
</ul>

<p>TF는 단순히 단어의 등장 빈도수를 계산하기 때문에 문서의 길이가 길어질수록 해당 단어의 TF 값도 높아질 수 있다.</p>

<h3 id="문서-빈도">문서 빈도</h3>

<p><strong>문서 빈도(Document Frequency, DF)</strong>란 한 단어가 얼마나 많은 문서에 나타나는지를 의미한다. 특정 단어가 많은 문서에 나타나면 문서 집합에서 단어가 나타나는 횟수를 계산한다.</p>
<ul>
  <li>‘movie’라는 단어가 3개의 문서에서 4번 등장: DF = 3</li>
</ul>

\[DF(t, D) = count(t \in d:d \in D)\]

<p>DF는 단어가 몇 개의 문서에서 등장하는지 계산한다.</p>
<ul>
  <li>DF 값이 높은 경우: 특정 단어가 많은 문서에서 등장하며 그 단어가 일반적으로 널리 사용되므로 사용 중요도가 낮을 수 있다.</li>
  <li>DF 값이 낮은 경우: 특정 단어가 적은 수의 문서에만 등장한다는 뜻이므로 특정한 문맥에서만 사용되는 단어일 가능성이 있으며, 중요도가 높을 수 있다.</li>
</ul>

<h3 id="역문서-빈도">역문서 빈도</h3>

<p><strong>역문서 빈도(Inverse Document Frequency, IDF)</strong>란 전체 문서 수를 문서 빈도로 나눈 다음에 로그를 취한 값을 말한다. 이는 문서 내에서 특정 단어가 얼마나 중요한지를 나타낸다.</p>

<p>문서 빈도가 높을수록 해당 단어가 일반적이고 상대적으로 중요하지 않다는 의미가 된다. 이를 문서 빈도의 역수를 취하면 단어의 빈도수가 적을수록 IDF 값이 커지게 보정하는 역할을 한다.</p>

<p>→ 문서에서 특정 단어의 등장 횟수가 적으면 IDF는 상대적으로 커진다.</p>

\[IDF(t, D) = log \bigg( \frac{count(D)}{1 + DF(t, D)} \bigg)\]

<h3 id="tf-idf">TF-IDF</h3>

<p>TF-IDF는 단어 빈도와 역문서 빈도를 곱한 값을 사용한다.</p>

\[TF-IDF(t, d, D) = TF(t,d) \times IDF(t, d)\]

<p>문서 내에 단어가 자주 등장하지만, 전체 문서 내에서 해당 단어가 적게 등장한다면 TF-IDF 값은 커진다. 이는 전체 문서에서 자주 등장할 확률이 높은 관사나 관용어 등의 가중치가 낮아진다.</p>

<p>TF-IDF 계산은 파이썬의 <strong>사이킷런(Scikit-learn)</strong> 라이브러리를 활용한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># TF-IDF 클래스
</span><span class="n">tfidf_vectorizer</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">feature_extraction</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="n">TfidfVectorizer</span><span class="p">(</span>
    <span class="nb">input</span><span class="o">=</span><span class="s">"content"</span><span class="p">,</span>
    <span class="n">encoding</span><span class="o">=</span><span class="s">"utf-8"</span><span class="p">,</span>
    <span class="n">lowercase</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">stop_words</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">ngram_range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">max_df</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
    <span class="n">min_df</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">vocabulary</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">smooth_idf</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<ul>
  <li><strong>입력값(<code class="language-plaintext highlighter-rouge">input</code>)</strong>: 입력될 데이터의 형태를 의미
    <ul>
      <li>기본값으로 설정된 <code class="language-plaintext highlighter-rouge">content</code>는 문자열 데이터 혹은 바이트 형태의 입력값을 의미한다.</li>
      <li>파일 객체를 사용한다면 <code class="language-plaintext highlighter-rouge">file</code>로 입력하며, 파일 경로를 사용하는 경우 <code class="language-plaintext highlighter-rouge">filename</code>으로 입력한다.</li>
    </ul>
  </li>
  <li><strong>인코딩(<code class="language-plaintext highlighter-rouge">encoding</code>)</strong>: 바이트 혹은 파일을 입력값으로 받을 경우 사용할 텍스트 인코딩 값을 의미</li>
  <li><strong>소문자 변환(<code class="language-plaintext highlighter-rouge">lowercase</code>)</strong>: 입력받은 데이터를 소문자로 변환 여부
    <ul>
      <li><code class="language-plaintext highlighter-rouge">True</code>로 설정하면 모든 입력 텍스트를 소문자로 변환</li>
    </ul>
  </li>
  <li><strong>불용어(<code class="language-plaintext highlighter-rouge">stop_words</code>)</strong>: 분석에 도움이 되지 않는 의미없는 단어들을 의미하며, 입력받은 단어들은 단어 사전에 추가되지 않음</li>
  <li><strong>N-gram 범위(<code class="language-plaintext highlighter-rouge">ngram_range</code>)</strong>: 사용할 N-gram의 범위로 (최솟값, 최댓값) 형태로 입력
    <ul>
      <li><code class="language-plaintext highlighter-rouge">(1, 1)</code>은 유니그램, <code class="language-plaintext highlighter-rouge">(1, 2)</code>는 유니그램과 바이그램을 사용</li>
    </ul>
  </li>
  <li><strong>최댓값 문서 빈도(<code class="language-plaintext highlighter-rouge">max_df</code>)</strong>: 전처 문서 중 일정 횟수 이상 등장한 단어는 불용어로 처리
    <ul>
      <li>정수를 입력하면 해당 등장 횟수를 초과해 등장하는 단어를 불용어 처리</li>
      <li>1 이하의 실수를 입력하면 해당 비율을 초과해 등장한 단어를 불용어 처리</li>
    </ul>
  </li>
  <li><strong>최솟값 문서 빈도(<code class="language-plaintext highlighter-rouge">min_df</code>)</strong>: 전체 문서 중 일정 횟수 미만으로 등장한 단어를 불용어 처리
    <ul>
      <li>최댓값 문서 빈도가 동일 패턴</li>
    </ul>
  </li>
  <li><strong>단어 사전(<code class="language-plaintext highlighter-rouge">vocabulary</code>)</strong>: 미리 구축한 단어사전이 있다면 해당 단어 사전을 사용하지만 입력하지 않는다면 자동으로 TF-IDF학습 시 구축</li>
  <li><strong>IDF 분모처리(<code class="language-plaintext highlighter-rouge">smooth_idf</code>)</strong>: IDF 계산 시 분모에 1을 더함</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># TF-IDF 계산
</span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">"That movie is famous movie"</span><span class="p">,</span>
    <span class="s">"I like that actor"</span><span class="p">,</span>
    <span class="s">"I don't like that actor"</span>
<span class="p">]</span>

<span class="n">tfidf_vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">()</span>
<span class="n">tfidf_vectorizer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">tfidf_matrix</span> <span class="o">=</span> <span class="n">tfidf_vectorizer</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">tfidf_matrix</span><span class="p">.</span><span class="n">toarray</span><span class="p">())</span>   <span class="c1"># (문서 수) * (단어 수)
</span><span class="k">print</span><span class="p">(</span><span class="n">tfidf_vectorizer</span><span class="p">.</span><span class="n">vocabulary_</span><span class="p">)</span>    <span class="c1"># 딕셔너리의 키, 값
</span>
<span class="c1"># [[0.          0.          0.39687454        0.39687454   0.          0.79374908  0.2344005 ]
#  [0.61980538  0.          0.                0.           0.61980538  0.          0.48133417]
#  [0.4804584   0.63174505  0.                0.           0.4804584   0.          0.37311881]]
# {'that': 6, 'movie': 5, 'is':3, 'famous':2, 'like':4, 'actor':0, 'don': 1}
</span></code></pre></div></div>

<ul>
  <li>TF-IDF에서 점수가 가장 높은 값을 세 개만 추려 색인으로 정리: [[2, 3, 5], [0, 4, 6], [0, 1, 4]]</li>
  <li>단어 사전과 매핑하면 [[famous, is, movie], [actor, like, that], [actor, don, like]]가 된다.</li>
</ul>

<p>이를 통해 문서마다 중요한 단어만 추출할 수 있으며, 벡터값을 활용해 문서 내 핵심 단어를 추출할 수 있다.</p>

<p>하지만 빈도 기반 벡터화는 문장의 순서나 문맥을 고려하지 않는다. 그러므로 문장 생성과 같이 순서가 중요한 작업에는 부적합하며 벡터가 해당 문서 내의 중요도를 의미할 뿐, 벡터가 단어의 의미를 담고 있지는 않다.</p>

        
      </section>

      <footer class="page__meta">
        
        


  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#nlp" class="page__taxonomy-item" rel="tag">NLP</a>
    
    </span>
  </p>


        
  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2025-04-01">April 1, 2025</time></p>


      </footer>

      

      
  <nav class="pagination">
    
      <a href="/pytorch/basic-1/" class="pagination--pager" title="파이토치 기초(1)
">Prev</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>


    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You may also enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/pytorch/basic-1/" rel="permalink">파이토치 기초(1)
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        <time datetime="2025-03-31T00:00:00+09:00">March 31, 2025</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">텐서 / 가설 / 손실 함수 / 최적화
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/pytorch/installation/" rel="permalink">파이토치 설치
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        <time datetime="2025-03-30T00:00:00+09:00">March 30, 2025</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">파이토치
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/tokenization/" rel="permalink">토큰화
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        <time datetime="2025-03-29T00:00:00+09:00">March 29, 2025</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">단어 및 글자 토큰화 / 형태소 토큰화 / 하위 단어 토큰화
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/capstone-design/mlflow/" rel="permalink">MLflow 소개 및 Tutorial
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        <time datetime="2025-03-16T00:00:00+09:00">March 16, 2025</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">MLflow
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 Seojin. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
